{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文本生成\n",
    "\n",
    "参照 [官网tutorials](https://www.tensorflow.org/tutorials/text/text_generation#%E4%B8%8B%E8%BD%BD%E8%8E%8E%E5%A3%AB%E6%AF%94%E4%BA%9A%E6%95%B0%E6%8D%AE%E9%9B%86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T10:33:52.610458Z",
     "start_time": "2019-11-26T10:33:52.388230Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "from tqdm.auto import tqdm\n",
    "import concurrent.futures\n",
    "from multiprocessing import Pool\n",
    "import copy,os,sys,psutil\n",
    "from collections import Counter,deque\n",
    "import itertools\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T10:33:54.386712Z",
     "start_time": "2019-11-26T10:33:52.708415Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T10:33:48.911718Z",
     "start_time": "2019-11-26T10:33:48.909767Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T10:33:55.119215Z",
     "start_time": "2019-11-26T10:33:54.949889Z"
    }
   },
   "outputs": [],
   "source": [
    "# 莎士比亚数据集\n",
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "# 读取并为 py2 compat 解码\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "vocab = sorted(set(text))\n",
    "\n",
    "# 创建从非重复字符到索引的映射\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "# 全文映射\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T10:33:56.884016Z",
     "start_time": "2019-11-26T10:33:56.878618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Length of text: 1115394 characters\n",
      ">>> vocab size: 65 unique characters\n",
      ">>> show head 250 characters\n",
      " First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 文本长度是指文本中的字符个数\n",
    "print ('>>> Length of text: {} characters'.format(len(text)))\n",
    "\n",
    "# 文本中的非重复字符\n",
    "print ('>>> vocab size: {} unique characters'.format(len(vocab)))\n",
    "\n",
    "# 看一看文本中的前 250 个字符\n",
    "print(\">>> show head 250 characters\\n\",text[:250])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "向量化文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T09:38:30.443797Z",
     "start_time": "2019-11-26T09:38:30.238322Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> text_as_int: shape (1115394,)\n",
      " [18 47 56 ... 45  8  0]\n",
      ">>> top10 of char2idx:\n",
      "'\\n':' 0'\n",
      "' ' :' 1'\n",
      "'!' :' 2'\n",
      "'$' :' 3'\n",
      "'&' :' 4'\n",
      "\"'\" :' 5'\n",
      "',' :' 6'\n",
      "'-' :' 7'\n",
      "'.' :' 8'\n",
      "'3' :' 9'\n",
      "':' :'10'\n",
      ">>> top10 of idx2char:\n",
      "0 : '\\n'\n",
      "1 : ' '\n",
      "2 : '!'\n",
      "3 : '$'\n",
      "4 : '&'\n",
      "5 : \"'\"\n",
      "6 : ','\n",
      "7 : '-'\n",
      "8 : '.'\n",
      "9 : '3'\n",
      ">>> 显示文本首 13 个字符的整数映射\n",
      "'First Citizen' ---- characters mapped to int ---- > [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
     ]
    }
   ],
   "source": [
    "print(f\">>> text_as_int: shape {text_as_int.shape}\\n\",text_as_int)\n",
    "print(\">>> top10 of char2idx:\")\n",
    "for idx,(k,v) in enumerate(char2idx.items()):\n",
    "    if idx <= 10:\n",
    "        print(f\"{repr(k):4s}:'{v:2d}'\")\n",
    "print(\">>> top10 of idx2char:\")\n",
    "for i in range(10):\n",
    "    print(f\"{i} : {repr(idx2char[i])}\")\n",
    "\n",
    "# 显示文本首 13 个字符的整数映射\n",
    "print(\">>> 显示文本首 13 个字符的整数映射\")\n",
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给定一个字符或者一个字符序列，下一个最可能出现的字符是什么？\n",
    "> 将文本拆分为长度为 seq_length+1 的文本块。例如，假设 seq_length 为 4 而且文本为 “Hello”， 那么输入序列将为 “Hell”，目标序列将为 “ello”。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 直接拷贝手册"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T09:38:34.029155Z",
     "start_time": "2019-11-26T09:38:32.838782Z"
    },
    "code_folding": [
     4
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设定每个输入句子长度的最大值\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//seq_length\n",
    "\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "\n",
    "# 创建训练样本 / 目标\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "sequences_dataset = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "dataset = sequences_dataset.map(split_input_target)\n",
    "\n",
    "\n",
    "# 批大小\n",
    "BATCH_SIZE = 64\n",
    "# 设定缓冲区大小，以重新排列数据集\n",
    "# （TF 数据被设计为可以处理可能是无限的序列，\n",
    "# 所以它不会试图在内存中重新排列整个序列。相反，\n",
    "# 它维持一个缓冲区，在缓冲区重新排列元素。） \n",
    "BUFFER_SIZE = 10000\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意到这里`tf.keras.layers.Embedding`的参数`batch_input_shape=[batch_size, None]`，实际是指定了`batch_size`而省略了`seq_length`，也就是模型支持任意长度的句子，后面在恢复模型时使用`model.build(tf.TensorShape([1, None]))`也是只把`batch_size`指定为1，支持任意长度的句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T10:33:59.584471Z",
     "start_time": "2019-11-26T10:33:59.575990Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "      ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T09:38:44.406374Z",
     "start_time": "2019-11-26T09:38:44.076381Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           16640     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 1024)          3935232   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 65)            66625     \n",
      "=================================================================\n",
      "Total params: 4,018,497\n",
      "Trainable params: 4,018,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(vocab_size = len(vocab),embedding_dim=embedding_dim,rnn_units=rnn_units,batch_size=BATCH_SIZE)\n",
    "model.summary()\n",
    "\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T09:52:37.653854Z",
     "start_time": "2019-11-26T09:52:37.623141Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d282720b8b93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# 检查点保存至的目录\n",
    "checkpoint_dir = './tmp/NLG_ckpt'\n",
    "\n",
    "# 检查点的文件名\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)\n",
    "\n",
    "EPOCHS=40\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "恢复模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T06:45:26.325014Z",
     "start_time": "2019-11-27T06:45:25.358609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> latest ckpt: './tmp/NLG_ckpt/ckpt_30'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f650fe08b38>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            16640     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1024)           3935232   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 65)             66625     \n",
      "=================================================================\n",
      "Total params: 4,018,497\n",
      "Trainable params: 4,018,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size=65\n",
    "embedding_dim=256\n",
    "rnn_units=1024\n",
    "\n",
    "checkpoint_dir = './tmp/NLG_ckpt'\n",
    "latest_ckpt = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "print(f\">>> latest ckpt: '{latest_ckpt}'\")\n",
    "\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(latest_ckpt)\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T10:34:04.683138Z",
     "start_time": "2019-11-26T10:34:04.676382Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7f665ae85eb8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_sess = tf.keras.backend.get_session()\n",
    "k_sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T10:15:34.411282Z",
     "start_time": "2019-11-27T10:15:34.396389Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def pick_from_top_n(preds_, top_n=None, random=False, verbose=False):\n",
    "    if top_n is None:\n",
    "        top_n = len(preds_)\n",
    "    preds = preds_.copy()  # 避免改变原preds\n",
    "    p = np.squeeze(preds)\n",
    "    # 小于0的都置为0\n",
    "    p = np.where(p>=0, p, 0)\n",
    "    # 将除了top_n个预测值的位置都置为0\n",
    "    p[np.argsort(p)[:-top_n]] = 0\n",
    "    # 归一化概率\n",
    "    p = np.exp(p-max(p)) / sum(np.exp(p-max(p)))\n",
    "    # 输出top_N的非0概率分布\n",
    "    if verbose:\n",
    "        # 排序并把索引(idx2char)和值(prob)zip到一起\n",
    "        prob_idx = np.stack([np.sort(p), np.argsort(p)],axis=1)[::-1]\n",
    "        # 去掉0\n",
    "        prob_idx = prob_idx[prob_idx[:,0]>0]\n",
    "        print(prob_idx[:5])\n",
    "    # 随机选取一个字符 / 或者取概率最大的字符\n",
    "    c = np.random.choice(len(preds_), 1, p=p)[0] if random else np.argmax(preds)\n",
    "    return c\n",
    "\n",
    "def generate_text(model, start_string,num_generate = 20,  temperature = 1.0, random=True):\n",
    "    if not random:\n",
    "        print(\"[WARN] without random.choice, 'temperature' will not take effect\")\n",
    "    # 将起始字符串转换为数字（向量化）\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = np.expand_dims(input_eval, 0)\n",
    "\n",
    "    # 空字符串用于存储结果\n",
    "    text_generated = []\n",
    "    # 低温度会生成更可预测的文本\n",
    "    # 较高温度会生成更令人惊讶的文本\n",
    "    # 可以通过试验以找到最好的设定\n",
    "\n",
    "\n",
    "    # 这里批大小为 1\n",
    "    model.reset_states()\n",
    "    for i in tqdm(range(num_generate)):\n",
    "        predictions = model.predict(input_eval)\n",
    "        # 删除批次的维度\n",
    "        predictions = np.squeeze(predictions, 0)\n",
    "        # 用分类分布预测模型返回的字符\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = pick_from_top_n(predictions[-1],top_n=None,random=random,verbose=False)\n",
    "        \n",
    "        # 把预测字符和前面的隐藏状态一起传递给模型作为下一个输入\n",
    "        input_eval = np.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "    return (start_string + ''.join(text_generated))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T10:16:26.600827Z",
     "start_time": "2019-11-27T10:16:25.602916Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f4b844b78f2407dbe00f4b4f17c064c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROMER:\n",
      "So do I too, if it be so, for I must go\n",
      "To keep the man of some strip star her riches standing;\n",
      "B\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "[WARN] without random.choice, 'temperature' will not take effect\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06dcae34e6ec4c8fb0b515c830108d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROMER:\n",
      "So do I too, if it be so, for I must go\n",
      "To keep the prince his son and heir: he is come from him.\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "# print(generate_text(model, start_string=u\"ROME\", num_generate=300, temperature=0.7))\n",
    "print(generate_text(model, start_string=u\"ROME\", num_generate=100, temperature=0.1, random=True))\n",
    "print(\"~\"*20)\n",
    "print(generate_text(model, start_string=u\"ROME\", num_generate=100, temperature=1.0, random=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T10:04:49.658786Z",
     "start_time": "2019-11-26T10:04:49.645246Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# 评估步骤（用学习过的模型生成文本）\n",
    "def generate_text_custom(model, start_string, temperature=1.0, num_generate=1000, verbose=True):\n",
    "\n",
    "    # 将起始字符串转换为数字（向量化）\n",
    "    input_eval_raw = [char2idx[s] for s in start_string]  # (3,)\n",
    "    input_eval = tf.expand_dims(input_eval_raw, 0)  # (1,3)\n",
    "    if verbose:\n",
    "        print(f\">>> 输入是: '{start_string}'\")\n",
    "        print(f\">>> +向量化: {input_eval_raw}\")\n",
    "        print(f\">>> +维度校正: {input_eval}\")\n",
    "    # 空字符串用于存储结果\n",
    "    text_generated = []\n",
    "\n",
    "    # 低温度会生成更可预测的文本\n",
    "    # 较高温度会生成更令人惊讶的文本\n",
    "    # 可以通过试验以找到最好的设定\n",
    "    k_sess = tf.keras.backend.get_session()\n",
    "    # 这里批大小为 1\n",
    "    model.reset_states()  # 清掉stateful layer的隐状态\n",
    "    for i in tqdm(range(num_generate),desc=\"predict next char\"):\n",
    "        predictions = model(input_eval)\n",
    "        # 删除批次的维度\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # 用分类分布预测模型返回的字符\n",
    "        predictions = predictions / temperature\n",
    "        predicted_seq = tf.random.categorical(predictions, num_samples=1)\n",
    "        predicted_seq = k_sess.run(predicted_seq)\n",
    "        # 最后一个字母\n",
    "        predicted_id = predicted_seq[-1,0]\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "        # 把预测字符和前面的隐藏状态一起传递给模型作为下一个输入\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        if verbose:\n",
    "            print(f\">>> 模型prediction结果shape: {model(input_eval).shape} --squeeze at 0--> {predictions.shape}\")\n",
    "            print(f\"    对应输入的预测字符串是: {predicted_seq.ravel()}\")\n",
    "            print(f\"    +decode: {repr(''.join([idx2char[i] for i in predicted_seq.ravel()]))}\")\n",
    "            print(f\"    +取最后一个字母: '{predicted_id}'\")\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T10:30:57.077062Z",
     "start_time": "2019-11-26T10:30:28.161355Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26644d634e1e474eac35d41a54bebfbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='predict next char', max=10, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 最后输出的结果是: 'ROMEO: n IOFLANEN'\n",
      "ROMEO: n IOFLANEN\n"
     ]
    }
   ],
   "source": [
    "res = generate_text_custom(model, start_string=u\"ROMEO: \", temperature=1.0, num_generate=10,verbose=False)\n",
    "print(f\">>> 最后输出的结果是: {repr(res)}\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T02:39:48.952969Z",
     "start_time": "2019-11-26T02:39:47.445740Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Input data: (4, 20) 演示的是字符索引映射回字符并join成字符串\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['ter thought of, a li', ' grant may never\\nBe ',\n",
       "       's was\\nA worthy offic', ' my hands\\nOf this mo'], dtype='<U20')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Target data: (4, 20) 演示的是字符索引映射回字符并join成字符串\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['er thought of, a lit', 'grant may never\\nBe h',\n",
       "       ' was\\nA worthy office', 'my hands\\nOf this mos'], dtype='<U20')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> input: (4, 20)\n",
      " [[58 43 56  1 58 46 53 59 45 46 58  1 53 44  6  1 39  1 50 47]\n",
      " [ 1 45 56 39 52 58  1 51 39 63  1 52 43 60 43 56  0 14 43  1]\n",
      " [57  1 61 39 57  0 13  1 61 53 56 58 46 63  1 53 44 44 47 41]\n",
      " [ 1 51 63  1 46 39 52 42 57  0 27 44  1 58 46 47 57  1 51 53]] \n",
      ">>> output: (4, 20)\n",
      " [[43 56  1 58 46 53 59 45 46 58  1 53 44  6  1 39  1 50 47 58]\n",
      " [45 56 39 52 58  1 51 39 63  1 52 43 60 43 56  0 14 43  1 46]\n",
      " [ 1 61 39 57  0 13  1 61 53 56 58 46 63  1 53 44 44 47 41 43]\n",
      " [51 63  1 46 39 52 42 57  0 27 44  1 58 46 47 57  1 51 53 57]]\n",
      ">>> 模拟训练过程中的输入与label (演示每个batch的前五个)\n",
      "  Step-0 expect:\n",
      " [['t' '--RNN->' 'e']\n",
      " ['e' '--RNN->' 'r']\n",
      " ['r' '--RNN->' ' ']\n",
      " [' ' '--RNN->' 't']\n",
      " ['t' '--RNN->' 'h']]\n",
      "  Step-1 expect:\n",
      " [[' ' '--RNN->' 'g']\n",
      " ['g' '--RNN->' 'r']\n",
      " ['r' '--RNN->' 'a']\n",
      " ['a' '--RNN->' 'n']\n",
      " ['n' '--RNN->' 't']]\n",
      "  Step-2 expect:\n",
      " [['s' '--RNN->' ' ']\n",
      " [' ' '--RNN->' 'w']\n",
      " ['w' '--RNN->' 'a']\n",
      " ['a' '--RNN->' 's']\n",
      " ['s' '--RNN->' '\\n']]\n",
      "  Step-3 expect:\n",
      " [[' ' '--RNN->' 'm']\n",
      " ['m' '--RNN->' 'y']\n",
      " ['y' '--RNN->' ' ']\n",
      " [' ' '--RNN->' 'h']\n",
      " ['h' '--RNN->' 'a']]\n"
     ]
    }
   ],
   "source": [
    "iterator=dataset.make_one_shot_iterator()\n",
    "with tf.Session() as sess:\n",
    "    input_example, target_example = sess.run(iterator.get_next())\n",
    "    print (f'>>> Input data: {input_example.shape} 演示的是字符索引映射回字符并join成字符串\\n')\n",
    "    np.array([\"\".join(i) for i in idx2char[input_example]])\n",
    "    print (f'>>> Target data: {target_example.shape} 演示的是字符索引映射回字符并join成字符串\\n')\n",
    "    np.array([\"\".join(i) for i in idx2char[target_example]])\n",
    "    print(f\">>> input: {input_example.shape}\\n\",input_example,f\"\\n>>> output: {target_example.shape}\\n\",target_example)\n",
    "    \n",
    "\n",
    "print(\">>> 模拟训练过程中的输入与label (演示每个batch的前五个)\")\n",
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:, :5], target_example[:, :5])):\n",
    "    res = np.transpose(np.stack([idx2char[input_idx],np.full(idx2char[input_idx].shape, \"--RNN->\"),idx2char[target_idx]]))\n",
    "    print(f\"  Step-{i} expect:\\n\",res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T07:53:01.106379Z",
     "start_time": "2019-11-25T07:53:00.552758Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (4, None, 256)            16640     \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (4, None, 1024)           3935232   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (4, None, 65)             66625     \n",
      "=================================================================\n",
      "Total params: 4,018,497\n",
      "Trainable params: 4,018,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(4), Dimension(20), Dimension(65)])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 词集的长度\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# 嵌入的维度\n",
    "embedding_dim = 256\n",
    "\n",
    "# RNN 的单元数量\n",
    "rnn_units = 1024\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.GRU(rnn_units, return_sequences=True, stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "      ])\n",
    "model.summary()\n",
    "# 这个loss重点是把 from_logits=True  默认是False\n",
    "def loss(labels, logits):\n",
    "      return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss,metrics=['acc'])\n",
    "example_batch_predictions = model(input_example)\n",
    "example_batch_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T05:42:42.319129Z",
     "start_time": "2019-11-25T05:42:42.314704Z"
    }
   },
   "outputs": [],
   "source": [
    "ckpt_dir = \"./tmp/NLG_ckpt\"\n",
    "ckpt_path = os.path.join(ckpt_dir, \"ckpt_{epoch}\")\n",
    "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_path, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T02:26:53.346585Z",
     "start_time": "2019-11-26T02:26:53.340642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((4, 20), (4, 20)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style='color:red'> 这里获取session必须在模型搭建完之后 </font>\n",
    "否则会报错:\n",
    "> Error while reading resource variable xxx/xxx from Container: localhost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看看随机初始化的模型结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T04:33:38.469469Z",
     "start_time": "2019-11-25T04:33:37.530967Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 模型随机初始化时的predict结果 (只取第一句看效果)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"输入：[idx2char]:'hat, what? let's par' [idx]:'[46 39 58  6  1 61 46 39 58 12  1 50 43 58  5 57  1 54 39 56]'\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\"目标：[idx2char]:'at, what? let's part' [idx]:'[39 58  6  1 61 46 39 58 12  1 50 43 58  5 57  1 54 39 56 58]'\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\"从输出的概率分布取top：[idx2char]:'ccxzHqqzx?HuTFH-H;;;' [idx]:'[41 41 62 64 20 55 55 64 62 12 20 59 32 18 20  7 20 11 11 11]'\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'直接输出：[idx2char]:'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00510419, -0.0116956 , -0.01077805, ...,  0.00211378,\n",
       "         0.00469348,  0.00368046],\n",
       "       [-0.01090839, -0.02199575, -0.00651144, ...,  0.0099673 ,\n",
       "         0.00253165,  0.01090109],\n",
       "       [ 0.00170103, -0.00854962, -0.01383094, ...,  0.01873878,\n",
       "         0.01389195,  0.00728091],\n",
       "       ...,\n",
       "       [-0.00642838,  0.00728031,  0.0063029 , ..., -0.00143693,\n",
       "         0.01254796,  0.00130002],\n",
       "       [-0.01836203, -0.0148465 ,  0.00415995, ...,  0.00432193,\n",
       "         0.01151806,  0.00901371],\n",
       "       [-0.00422909,  0.00253295, -0.00814815, ...,  0.01425106,\n",
       "         0.0067365 ,  0.00757992]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'损失：[CE-loss]:'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([4.160237 , 4.176042 , 4.1832085, 4.1777472, 4.176107 , 4.165276 ,\n",
       "       4.155126 , 4.177448 , 4.1557145, 4.1786823, 4.17679  , 4.1778092,\n",
       "       4.1722336, 4.180721 , 4.175385 , 4.159927 , 4.1801143, 4.1773624,\n",
       "       4.1755776, 4.1700773], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 下面是详细\n",
      "输入: (4, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['h', 'a', 't', ',', ' ', 'w', 'h', 'a', 't', '?', ' ', 'l', 'e',\n",
       "        't', \"'\", 's', ' ', 'p', 'a', 'r'],\n",
       "       ['t', 'e', 'r', 'p', 'r', 'e', 't', 'a', 't', 'i', 'o', 'n', ' ',\n",
       "        'o', 'f', ' ', 't', 'h', 'e', ' '],\n",
       "       ['d', ';', '\\n', 'Y', 'o', 'u', 'r', ' ', 'm', 'o', 's', 't', ' ',\n",
       "        'g', 'r', 'a', 'v', 'e', ' ', 'b'],\n",
       "       [' ', 'm', 'y', ' ', 'f', 'r', 'i', 'e', 'n', 'd', 's', ';', ' ',\n",
       "        'a', 'n', 'd', ',', ' ', 't', 'o']], dtype='<U1')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标注: (4, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['a', 't', ',', ' ', 'w', 'h', 'a', 't', '?', ' ', 'l', 'e', 't',\n",
       "        \"'\", 's', ' ', 'p', 'a', 'r', 't'],\n",
       "       ['e', 'r', 'p', 'r', 'e', 't', 'a', 't', 'i', 'o', 'n', ' ', 'o',\n",
       "        'f', ' ', 't', 'h', 'e', ' ', 't'],\n",
       "       [';', '\\n', 'Y', 'o', 'u', 'r', ' ', 'm', 'o', 's', 't', ' ', 'g',\n",
       "        'r', 'a', 'v', 'e', ' ', 'b', 'e'],\n",
       "       ['m', 'y', ' ', 'f', 'r', 'i', 'e', 'n', 'd', 's', ';', ' ', 'a',\n",
       "        'n', 'd', ',', ' ', 't', 'o', ' ']], dtype='<U1')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型预测: (4, 20, 65) --pick--> (4, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['c', 'c', 'x', 'z', 'H', 'q', 'q', 'z', 'x', '?', 'H', 'u', 'T',\n",
       "        'F', 'H', '-', 'H', ';', ';', ';'],\n",
       "       ['F', 'T', 'b', ';', ';', ';', 'F', 'w', '-', 'J', '-', 'N', ' ',\n",
       "        ' ', 'N', 'y', 'y', 'y', 'J', 'b'],\n",
       "       ['d', 'F', 'n', 'C', ' ', 'S', 'N', ' ', 'a', 'W', 'L', 'W', 'Z',\n",
       "        ' ', 'b', 'L', 'L', 'O', 's', 'H'],\n",
       "       ['H', 'a', 'a', 'a', 'r', 'N', 'J', 'J', 'P', 'J', ' ', 'x', ' ',\n",
       "        'L', 'c', 'd', 'Q', 'Z', 'Z', ' ']], dtype='<U1')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE损失: [shape]:(4, 20)\n",
      " [[4.160237  4.176042  4.1832085 4.1777472 4.176107  4.165276  4.155126\n",
      "  4.177448  4.1557145 4.1786823 4.17679   4.1778092 4.1722336 4.180721\n",
      "  4.175385  4.159927  4.1801143 4.1773624 4.1755776 4.1700773]\n",
      " [4.178322  4.168017  4.181786  4.173589  4.1760755 4.17192   4.1770372\n",
      "  4.174807  4.173535  4.1943154 4.1818757 4.1687164 4.1773987 4.1741657\n",
      "  4.175613  4.1702967 4.1787305 4.187074  4.1721363 4.173623 ]\n",
      " [4.1857905 4.1755123 4.1723166 4.1690807 4.1669025 4.185561  4.160659\n",
      "  4.1786213 4.1834593 4.1792254 4.172516  4.167448  4.1922054 4.175457\n",
      "  4.1713305 4.183974  4.177972  4.1710653 4.161363  4.187027 ]\n",
      " [4.1765637 4.1705246 4.1785254 4.1679688 4.1452475 4.1743045 4.175\n",
      "  4.1660066 4.1787114 4.1779504 4.1827216 4.156034  4.169887  4.187935\n",
      "  4.1734324 4.1669626 4.1684337 4.1737814 4.1864586 4.156705 ]]\n"
     ]
    }
   ],
   "source": [
    "def pick_top_n(preds_, top_n=None, random=False):\n",
    "    if top_n is None:\n",
    "        top_n = len(preds_)\n",
    "    preds = preds_.copy()  # 避免改变原preds\n",
    "    p = np.squeeze(preds)\n",
    "    # 小于0的都置为0\n",
    "    p = np.where(p>=0, p, 0)\n",
    "    # 将除了top_n个预测值的位置都置为0\n",
    "    p[np.argsort(p)[:-top_n]] = 0\n",
    "    # 归一化概率\n",
    "    p = p / np.sum(p)\n",
    "    # 随机选取一个字符 / 或者取概率最大的字符\n",
    "    c = np.random.choice(len(preds_), 1, p=p)[0] if random else np.argmax(preds)\n",
    "    return c\n",
    "k_sess = tf.keras.backend.get_session()\n",
    "pred = k_sess.run(model(input_example))\n",
    "chose = np.array([[pick_top_n(char_probs) for char_probs in sequences] for sequences in pred ])\n",
    "print(\">>> 模型随机初始化时的predict结果 (只取第一句看效果)\")\n",
    "f\"输入：[idx2char]:'{''.join(idx2char[input_example][0]):s}' [idx]:'{input_example[0]}'\"\n",
    "f\"目标：[idx2char]:'{''.join(idx2char[target_example][0]):s}' [idx]:'{target_example[0]}'\"\n",
    "f\"从输出的概率分布取top：[idx2char]:'{''.join(idx2char[chose][0]):s}' [idx]:'{chose[0]}'\"\n",
    "f\"直接输出：[idx2char]:\"\n",
    "pred[0]\n",
    "f\"损失：[CE-loss]:\"\n",
    "k_sess.run(tf.keras.losses.sparse_categorical_crossentropy(target_example[0], pred[0], from_logits=True))\n",
    "\n",
    "print(\">>> 下面是详细\")\n",
    "print(f\"输入: {input_example.shape}\")\n",
    "idx2char[input_example]\n",
    "print(f\"标注: {target_example.shape}\")\n",
    "idx2char[target_example]\n",
    "print(f\"模型预测: {pred.shape} --pick--> {chose.shape}\")\n",
    "idx2char[chose]\n",
    "loss = k_sess.run(tf.keras.losses.sparse_categorical_crossentropy(target_example, pred, from_logits=True))\n",
    "print(f\"CE损失: [shape]:{loss.shape}\\n\",loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个错误的示例 | 输入都用np转成arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"【实际不会用这种输入方式】如果输入是list型的，取的是第0个不管后面的\")\n",
    "model.reset_states()\n",
    "np.squeeze(model.predict([np.array([1,2])]),1)[:,:5]\n",
    "model.reset_states()\n",
    "np.squeeze(model.predict([np.array([1])]),1)[:,:5]\n",
    "np.squeeze(model.predict([np.array([2])]),1)[:,:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:red\"> \n",
    "为什么？？\n",
    "\n",
    "预测`arr([[1,2]])`再预测`arr([[3,4]])` \n",
    "- 等价于直接预测 `arr([[1,2],[3,4]])` ✅\n",
    "- 不等价与直接预测 `arr([[1,2,3,4]])` ❎\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T06:42:26.555002Z",
     "start_time": "2019-11-27T06:42:26.317997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "先预测arr([[1,2]]) 在预测arr([[3,4]]) \n",
      ">>> arr([[1,2]])的shape:(1, 2) --输出->(1, 2, 65)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -8.832616 , -15.162733 ,  -7.911195 ,  -2.1716287,  -2.1839044],\n",
       "       [ 11.909098 ,  10.299256 ,  -8.214893 ,  -8.358577 , -10.036395 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> arr([[3,4]])的shape:(1, 2) --输出->(1, 2, 65)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.35068864,  0.43206474, -4.32421   , -3.1326041 , -2.0293384 ],\n",
       "       [-0.7903478 , -1.5058678 , -7.7205534 , -8.223289  , -2.4436786 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "直接预测arr([[1,2],[3,4]])\n",
      ">>> arr([[1,2],[,34]])的shape:(2, 2) --输出->(2, 2, 65)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ -8.832616  , -15.162733  ,  -7.911195  ,  -2.1716287 ,\n",
       "          -2.1839044 ],\n",
       "        [ 11.909098  ,  10.299256  ,  -8.214893  ,  -8.358577  ,\n",
       "         -10.036395  ]],\n",
       "\n",
       "       [[  0.35068864,   0.43206474,  -4.32421   ,  -3.1326041 ,\n",
       "          -2.0293384 ],\n",
       "        [ -0.7903478 ,  -1.5058678 ,  -7.7205534 ,  -8.223289  ,\n",
       "          -2.4436786 ]]], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "直接预测arr([[1,2,3,4]])\n",
      ">>> arr([[1,2,3,4]])的shape:(1, 4) --输出->(1, 4, 65)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -8.832616  , -15.162731  ,  -7.9111934 ,  -2.171629  ,\n",
       "         -2.1839037 ],\n",
       "       [ 11.909098  ,  10.299255  ,  -8.214894  ,  -8.358576  ,\n",
       "        -10.036394  ],\n",
       "       [  1.7228051 ,  -1.361204  ,  -4.9199667 ,  -9.902154  ,\n",
       "         -2.429722  ],\n",
       "       [ -1.3204055 ,  -0.08819595,  -0.79439396,  -6.6956706 ,\n",
       "          0.5630963 ]], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"先预测arr([[1,2]]) 在预测arr([[3,4]]) \")\n",
    "model.reset_states()\n",
    "p1 = model.predict(np.array([[1,2]]))\n",
    "p2 = model.predict(np.array([[3,4]]))\n",
    "print(f\">>> arr([[1,2]])的shape:{np.array([[1,2]]).shape} --输出->{p1.shape}\")\n",
    "np.squeeze(p1,0)[:,:5]\n",
    "print(f\">>> arr([[3,4]])的shape:{np.array([[3,4]]).shape} --输出->{p2.shape}\")\n",
    "np.squeeze(p2,0)[:,:5]\n",
    "\n",
    "print(\"直接预测arr([[1,2],[3,4]])\")\n",
    "model.reset_states()\n",
    "p1_2 = model.predict(np.array([[1,2],[3,4]]))\n",
    "print(f\">>> arr([[1,2],[,34]])的shape:{np.array([[1,2],[3,4]]).shape} --输出->{p1_2.shape}\")\n",
    "p1_2[:,:,:5]\n",
    "\n",
    "print(\"直接预测arr([[1,2,3,4]])\")\n",
    "model.reset_states()\n",
    "p12=model.predict(np.array([[1,2,3,4]]))\n",
    "print(f\">>> arr([[1,2,3,4]])的shape:{np.array([[1,2,3,4]]).shape} --输出->{p12.shape}\")\n",
    "np.squeeze(p12,0)[:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

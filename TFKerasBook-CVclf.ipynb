{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于Incepiton的迁移学习，用 tf、keras、tfhub 实现\n",
    "\n",
    "参照 [官网tutorials](https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub#download_the_headless_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T11:50:27.043276Z",
     "start_time": "2019-12-13T11:50:26.782992Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "from tqdm.auto import tqdm\n",
    "import concurrent.futures\n",
    "from multiprocessing import Pool\n",
    "import copy,os,sys\n",
    "from collections import Counter,deque\n",
    "import itertools\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T11:50:28.586969Z",
     "start_time": "2019-12-13T11:50:27.044933Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "只能检测到\"XLA_GPU\"，但是不能使用，<font style=\"color:red\">CUDA 和 cuDNN 需要升级</font>\n",
    "- 参考这个issue：https://github.com/tensorflow/tensorflow/issues/30388\n",
    "> Finally, you can get rid of this issue by uninstalling / reinstalling (tested on Ubuntu 18.04):\n",
    ">\n",
    "> Tensorflow 2.0\n",
    ">\n",
    "> CUDA 10.0\n",
    ">\n",
    "> cuDNN 7.6.4 (described as dedicated for CUDA 10.0)\n",
    ">\n",
    "> https://www.tensorflow.org/install/source#tested_build_configurations. You will get xla devices with corresponding non xla devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T11:03:42.236207Z",
     "start_time": "2019-12-13T11:03:42.192155Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T08:53:08.131714Z",
     "start_time": "2019-12-13T08:53:08.114054Z"
    },
    "deletable": false,
    "editable": false,
    "init_cell": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# 【注意】这里 set_log_device_placement 打开了自后后面加载模型都会有很多log\n",
    "tf.config.experimental.list_physical_devices()\n",
    "tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\">>> 验证是否能在GPU上计算\")\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T09:24:23.307152Z",
     "start_time": "2019-12-06T09:24:23.294200Z"
    }
   },
   "outputs": [],
   "source": [
    "sess_conf = tf.ConfigProto()\n",
    "sess_conf.gpu_options.allow_growth = True  # 允许GPU渐进占用\n",
    "sess_conf.allow_soft_placement = True  # 把不适合GPU的放到CPU上跑\n",
    "\n",
    "g_graph = tf.Graph()\n",
    "g_sess = tf.Session(graph=g_graph, config=sess_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正式流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
    "image_data = image_generator.flow_from_directory(root_path, classes=['Taj_Mahal','Qutb_Minar'], target_size=IMAGE_SHAPE)\n",
    "for image_batch, label_batch in image_data:\n",
    "    print(\"Image batch shape: \", image_batch.shape)\n",
    "    print(\"Label batch shape: \", label_batch.shape)\n",
    "    break\n",
    "\n",
    "# 重新加载一下iter\n",
    "image_data = image_generator.flow_from_directory(root_path, classes=['Taj_Mahal','Qutb_Minar'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并多个generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用tf封装的`ImageDataGenerator`从目录里直接读取数据，按子目录来分类别\n",
    "\n",
    "这里尝试了合并多个 generator | 参考 [SO的回答](https://stackoverflow.com/questions/49404993/keras-how-to-use-fit-generator-with-multiple-inputs)\n",
    "- 注意测试了`itertools.chain`是不行的，会一直循环第一个`generator`的结果\n",
    "- `concat` 方法可行但是没有保留`flow_from_directory`得到的类`DirectoryIterator`，一些方法如`next()`, `num_class`不能用了，`batch_size`也需要更新为`n倍`，这些都只能用新的变量单独保存\n",
    "\n",
    "```python\n",
    "def concat(*iterables):\n",
    "    while True:\n",
    "        data = [i.next() for i in iterables]\n",
    "        yield np.concatenate([i[0] for i in data], axis=0), np.concatenate([i[1] for i in data], axis=0)\n",
    "\n",
    "to_merge = [image_data_aug1,image_data_aug2,image_data_normal]\n",
    "train_data = concat(*to_merge)\n",
    "num_classes = image_data_aug1.num_classes\n",
    "batch_size = len(to_merge) * batch_size\n",
    "```\n",
    "- 还有一种方法是继承Keras的`Sequence`类，但是这方法似乎也没有保留`DirectoryIterator`的那些属性，没有尝试 上述的 [SO回答](https://stackoverflow.com/questions/49404993/keras-how-to-use-fit-generator-with-multiple-inputs) 中有这种方案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并三个 generator，各自代表不同的augmentaion —— 水平翻转&缩放、旋转&明暗、正常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T05:31:20.606236Z",
     "start_time": "2019-11-20T05:30:45.518975Z"
    },
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datagen_args1 = dict(horizontal_flip=True,zoom_range=[0.1,0.2])\n",
    "datagen_args2 = dict(rotation_range=90, brightness_range=[0.3,0.5])\n",
    "batch_size = 90\n",
    "image_generator_aug1 = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255,**datagen_args1)\n",
    "image_generator_aug2 = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255,**datagen_args2)\n",
    "image_generator_normal = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
    "image_data_aug1 = image_generator_aug1.flow_from_directory(root_path, classes=['Taj_Mahal','Qutb_Minar'], target_size=IMAGE_SHAPE, batch_size=batch_size)\n",
    "image_data_aug2 = image_generator_aug2.flow_from_directory(root_path, classes=['Taj_Mahal','Qutb_Minar'], target_size=IMAGE_SHAPE, batch_size=batch_size)\n",
    "image_data_normal = image_generator_normal.flow_from_directory(root_path, classes=['Taj_Mahal','Qutb_Minar'], target_size=IMAGE_SHAPE, batch_size=batch_size)\n",
    "\n",
    "def concat(*iterables):\n",
    "    while True:\n",
    "        data = [i.next() for i in iterables]\n",
    "        yield np.concatenate([i[0] for i in data], axis=0), np.concatenate([i[1] for i in data], axis=0)\n",
    "\n",
    "to_merge = [image_data_aug1,image_data_aug2,image_data_normal]\n",
    "train_data = concat(*to_merge)\n",
    "num_classes = image_data_aug1.num_classes\n",
    "batch_size = len(to_merge) * batch_size\n",
    "print(f\">>> merge {len(to_merge)} 个iter后的batch_size为: {batch_size}\")\n",
    "print(\">>> 如下显示加了 [旋转、反转] 等augmentation的训练集（合并了多个generator）\")\n",
    "for i in range(199*3//batch_size+1+1):\n",
    "    pics, label_batch = train_data.__next__()\n",
    "    if i == 0:\n",
    "        print(\" 独立演示train_data里的第一项\")\n",
    "        print(\" Image batch shape: \", pics.shape)\n",
    "        print(\" Label batch shape: \", label_batch.shape)\n",
    "        print(\"~~\"*15)\n",
    "    print(pics.shape)\n",
    "    if i == 199*3//batch_size:\n",
    "        print(\">>> 已经消费完所有数据，后面从头开始从generator里获取数据\")\n",
    "    r = int(len(pics) ** 0.5)\n",
    "    c = len(pics) // r + 1\n",
    "    fig,axes_arr = plt.subplots(r,c)\n",
    "    _ = [ax.set_axis_off() for ax in axes_arr.ravel()]\n",
    "    for idx, pic in enumerate(pics):\n",
    "        axes = axes_arr[idx//c, idx % c]\n",
    "        axes.set_axis_off()\n",
    "        _ = axes.imshow(pic)\n",
    "\n",
    "image_batch, label_batch = train_data.__next__()  # 随便拿一个出来当image_batch给后面测试用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 带有train test/validation 的Generator\n",
    "基本流程是\n",
    "- 初始化`ImageDataGenerator`时提供`validation_split`参数\n",
    "- 然后获取flow时（例如`flow_from_directory`）使用`subset`来标记是取训练集还是测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T10:37:08.780460Z",
     "start_time": "2019-11-20T10:36:23.477781Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 90\n",
    "validation_ratio=0.2\n",
    "ig_aug1 = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255,horizontal_flip=True,zoom_range=[0.1,0.2])\n",
    "ig_aug2 = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255,rotation_range=90, brightness_range=[0.3,0.5])\n",
    "generic_params = dict(directory=root_path, classes=['Taj_Mahal','Qutb_Minar'], target_size=IMAGE_SHAPE, batch_size=batch_size)\n",
    "augflow1 = ig_aug1.flow_from_directory(**generic_params)\n",
    "augflow2 = ig_aug2.flow_from_directory(**generic_params)\n",
    "# 一般用没有augmentation的数据做验证集\n",
    "generic_params = dict(directory=root_path, classes=['Taj_Mahal','Qutb_Minar'], target_size=IMAGE_SHAPE, batch_size=batch_size)\n",
    "ig_normal = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=validation_ratio,rescale=1/255)\n",
    "normal_flow_train = ig_normal.flow_from_directory(subset='training', **generic_params)\n",
    "normal_flow_valid = ig_normal.flow_from_directory(subset='validation', **generic_params)\n",
    "\n",
    "\n",
    "def concat(*iterables):\n",
    "    while True:\n",
    "        data = [i.next() for i in iterables]\n",
    "        yield np.concatenate([i[0] for i in data], axis=0), np.concatenate([i[1] for i in data], axis=0)\n",
    "\n",
    "to_merge = [augflow1,augflow2,normal_flow_train]\n",
    "train_data = concat(*to_merge)\n",
    "num_classes = augflow1.num_classes\n",
    "samples = sum(i.samples for i in to_merge)\n",
    "batch_size = len(to_merge) * batch_size\n",
    "print(f\">>> merge {len(to_merge)} 个iter后的batch_size为: {batch_size}\")\n",
    "print(\">>> 如下显示加了 [旋转、反转] 等augmentation的训练集（合并了多个generator）\")\n",
    "for i in range(samples//batch_size+1+2): # 多循环两轮\n",
    "    pics, label_batch = train_data.__next__()\n",
    "    if i == 0:\n",
    "        print(\" 独立演示train_data里的第一项\")\n",
    "        print(\" 注意后续的shape会比较特别是因为，ig_normal分了20%做验证集，所以会比另外两个没有分validation的提前消耗完\")\n",
    "        print(\" 假设batch_size=90,它在第二次取90个时就消耗完了,只取到了160-90=70个,而另外两个数据集还能取到90个,总计就是70+90*2=250个\")\n",
    "        print(\" Image batch shape: \", pics.shape)\n",
    "        print(\" Label batch shape: \", label_batch.shape)\n",
    "        print(\"~~\"*15)\n",
    "    print(pics.shape)\n",
    "    if i == samples//batch_size:\n",
    "        print(\">>> 已经消费完所有数据，下一次会从头开始从generator里获取数据\")\n",
    "    r = int(len(pics) ** 0.5)\n",
    "    c = len(pics) // r + 1\n",
    "    fig,axes_arr = plt.subplots(r,c)\n",
    "    _ = [ax.set_axis_off() for ax in axes_arr.ravel()]\n",
    "    for idx, pic in enumerate(pics):\n",
    "        axes = axes_arr[idx//c, idx % c]\n",
    "        axes.set_axis_off()\n",
    "        _ = axes.imshow(pic)\n",
    "\n",
    "image_batch, label_batch = train_data.__next__()  # 随便拿一个出来当image_batch给后面测试用\n",
    "print(f\">>> 消费完后从头拿到的数据shape是: {image_batch.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载classification model预测分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T10:37:42.213014Z",
     "start_time": "2019-11-20T10:37:36.315825Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier_url =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2\" #@param {type:\"string\"}\n",
    "clf = tf.keras.Sequential([hub.KerasLayer(classifier_url, input_shape=IMAGE_SHAPE+(3,))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载headless model预测feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T10:37:45.282654Z",
     "start_time": "2019-11-20T10:37:42.336471Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_extractor_url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2\" #@param {type:\"string\"}\n",
    "feat_layer = hub.KerasLayer(feature_extractor_url, input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意:\n",
    "- clf是 `tf.keras.Sequential` 搭起来的\n",
    "- feat_layer是`hub.KerasLayer`直接做的一个`Layer`，所以得到的结果是一个`Tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T10:37:45.410986Z",
     "start_time": "2019-11-20T10:37:45.408141Z"
    }
   },
   "outputs": [],
   "source": [
    "image_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T10:37:50.234170Z",
     "start_time": "2019-11-20T10:37:45.608774Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_batch_part = image_batch[:16]\n",
    "pred_res = clf.predict(image_batch_part)\n",
    "print(f\"clf的结果,shape: {pred_res.shape}, argmax: {np.argmax(pred_res, axis=1)}\\n\",pred_res)\n",
    "feat_layer(image_batch_part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T08:28:05.314495Z",
     "start_time": "2019-11-29T08:28:05.283636Z"
    }
   },
   "outputs": [],
   "source": [
    "feat_layer.trainable = False  # feature_vector的生成就不用训练了\n",
    "model = tf.keras.Sequential([\n",
    "  feat_layer,\n",
    "  tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model.summary()\n",
    "pred = model(image_batch)\n",
    "pred\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=\"categorical_crossentropy\", metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CallBack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T10:37:57.197938Z",
     "start_time": "2019-11-20T10:37:57.191363Z"
    }
   },
   "outputs": [],
   "source": [
    "class CollectBatchStats(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.batch_losses = []\n",
    "        self.batch_acc = []\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.batch_losses.append(logs['loss'])\n",
    "        self.batch_acc.append(logs['acc'])\n",
    "        self.model.reset_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面用`concat`方式的结果，要注意`validation_step`\n",
    "- 如果用`normal_flow_valid.samples // batch_size`注意是否为0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T10:44:30.149874Z",
     "start_time": "2019-11-20T10:43:05.401536Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "steps_per_epoch = np.ceil(samples//batch_size)\n",
    "batch_stats_callback = CollectBatchStats()\n",
    "history = model.fit_generator(normal_flow_train, epochs=4,\n",
    "                              steps_per_epoch = normal_flow_train.samples//40,\n",
    "                              validation_data = normal_flow_valid,\n",
    "                              validation_steps = normal_flow_valid.samples ,\n",
    "                              callbacks = [batch_stats_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "img_width, img_height = 256, 256\n",
    "train_data_dir = \"tf_files/codoon_photos\"\n",
    "validation_data_dir = \"tf_files/codoon_photos\"\n",
    "nb_train_samples = 4125\n",
    "nb_validation_samples = 466 \n",
    "batch_size = 16\n",
    "epochs = 50\n",
    "\n",
    "model = applications.ResNet50(include_top=False, weights='imagenet', input_shape=(img_width, img_height, 3))\n",
    "\n",
    "# Freeze the layers which you don't want to train. Here I am freezing the all layers.\n",
    "for layer in model.layers[:]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Adding custom Layer\n",
    "# We only add\n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "# Adding even more custom layers\n",
    "# x = Dense(1024, activation=\"relu\")(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "# Initiate the train and test generators with data Augumentation \n",
    "train_datagen = ImageDataGenerator(\n",
    "  rescale = 1./255,\n",
    "  horizontal_flip = True,\n",
    "  fill_mode = \"nearest\",\n",
    "  zoom_range = 0.3,\n",
    "  width_shift_range = 0.3,\n",
    "  height_shift_range=0.3,\n",
    "  rotation_range=30)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "  rescale = 1./255,\n",
    "  horizontal_flip = True,\n",
    "  fill_mode = \"nearest\",\n",
    "  zoom_range = 0.3,\n",
    "  width_shift_range = 0.3,\n",
    "  height_shift_range=0.3,\n",
    "  rotation_range=30)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "  train_data_dir,\n",
    "  target_size = (img_height, img_width),\n",
    "  batch_size = batch_size,\n",
    "  class_mode = \"categorical\")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "  validation_data_dir,\n",
    "  target_size = (img_height, img_width),\n",
    "  class_mode = \"categorical\")\n",
    "\n",
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint(\"resnet50_retrain.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "\n",
    "# Train the model \n",
    "model_final.fit_generator(\n",
    "  train_generator,\n",
    "  samples_per_epoch = nb_train_samples,\n",
    "  epochs = epochs,\n",
    "  validation_data = validation_generator,\n",
    "  nb_val_samples = nb_validation_samples,\n",
    "  callbacks = [checkpoint, early])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器打分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:04:43.173876Z",
     "start_time": "2019-12-02T03:04:43.168406Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **准备「train」「validation」数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T05:22:23.464469Z",
     "start_time": "2019-12-02T05:22:22.629390Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"\\n\",\"--\"*15,\"原始数据准备\",\"--\"*15,\"\\n\")\n",
    "df = pd.read_csv(\"/home/zhoutong/res.csv\")\n",
    "df['id'] = df['id'].astype(int)\n",
    "df.count()\n",
    "print(\"去掉na\")\n",
    "df = df.dropna()\n",
    "df.count()\n",
    "df.head(3)\n",
    "\n",
    "print(\"\\n\",\"--\"*15,\"取样本\",\"--\"*15,\"\\n\")\n",
    "ctr = df['ctr'].to_numpy()\n",
    "print(\"各百分位对应的ctr:\")\n",
    "[(i,np.percentile(ctr,i)) for i in [5,15,25,50,75,95]]\n",
    "print(\"取上四分位为正样本，下四分位为负样本\")\n",
    "neg,pos = df.query(\"ctr<0.022\"),df.query(\"ctr>0.068\")\n",
    "print(f\"正样本计数: {pos.shape}, 负样本计数: {neg.shape}\")\n",
    "_ = plt.hist(ctr[np.logical_and(ctr<0.13, ctr>0)],bins=300)\n",
    "plt.show()\n",
    "print(\"去掉极端值后分布如上，中位数:\",np.percentile(ctr[np.logical_and(ctr<0.13, ctr>0)], 50))\n",
    "print(\"均值:\",np.mean(ctr[np.logical_and(ctr<0.13, ctr>0)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **获取「verify」数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T05:22:26.951212Z",
     "start_time": "2019-12-02T05:22:26.868266Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\",\"--\"*15,\"原始数据准备\",\"--\"*15,\"\\n\")\n",
    "df_v = pd.read_csv(\"/home/zhoutong/res_11_25.csv\")\n",
    "df_v['id'] = df_v['id'].astype(int)\n",
    "df_v.count()\n",
    "print(\"去掉na\")\n",
    "df_v = df_v.dropna()\n",
    "df_v.count()\n",
    "df_v['fileName'] = df_v['banner_url'].apply(lambda url:url.split(\"/\")[-1].split(\"?\")[0])\n",
    "df_v.head(3)\n",
    "\n",
    "# print(\"\\n\",\"--\"*15,\"取样本\",\"--\"*15,\"\\n\")\n",
    "# ctr = df['ctr'].to_numpy()\n",
    "# print(\"各百分位对应的ctr:\")\n",
    "# [(i,np.percentile(ctr,i)) for i in [5,15,25,50,75,95]]\n",
    "# print(\"取上四分位为正样本，下四分位为负样本\")\n",
    "# neg,pos = df.query(\"ctr<0.022\"),df.query(\"ctr>0.068\")\n",
    "# print(f\"正样本计数: {pos.shape}, 负样本计数: {neg.shape}\")\n",
    "# _ = plt.hist(ctr[np.logical_and(ctr<0.13, ctr>0)],bins=300)\n",
    "# plt.show()\n",
    "# print(\"去掉极端值后分布如上，中位数:\",np.percentile(ctr[np.logical_and(ctr<0.13, ctr>0)], 50))\n",
    "# print(\"均值:\",np.mean(ctr[np.logical_and(ctr<0.13, ctr>0)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:36:18.813967Z",
     "start_time": "2019-12-02T03:31:30.972472Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_dir=\"./tmp/auto_score\"\n",
    "print(\"下载图片至本地: \", sample_dir)\n",
    "\n",
    "def download(url, subdir):\n",
    "    path = os.path.join(sample_dir, subdir, url.split(\"/\")[-1].split(\"?\")[0])\n",
    "    urllib.request.urlretrieve(url, path)\n",
    "\n",
    "    \n",
    "from functools import partial\n",
    "download_pos = partial(download, subdir=\"pos\")\n",
    "download_neg = partial(download, subdir=\"neg\")\n",
    "download_verify = partial(download, subdir=\"verify\")\n",
    "from multiprocessing import Pool\n",
    "p = Pool(12)\n",
    "iter_to_run = p.imap(download_verify, df_v['banner_url'])\n",
    "_ = list(tqdm(iter_to_run, total=df_v['banner_url'].shape[0], desc=\"download verify_pics:\"))\n",
    "\n",
    "# iter_to_run = p.imap(download_neg, neg['banner_url'])\n",
    "# _ = list(tqdm(iter_to_run,total=neg['banner_url'].size,desc=\"download neg:\"))\n",
    "\n",
    "# iter_to_run = p.imap(download_pos, pos['banner_url'])\n",
    "# _ = list(tqdm(iter_to_run,total=pos['banner_url'].size,desc=\"download pos:\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T02:05:36.109264Z",
     "start_time": "2019-12-02T02:05:34.737627Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (224,224)\n",
    "batch_size = 32\n",
    "validation_ratio=0.1\n",
    "sample_dir=\"./tmp/auto_score\"\n",
    "generic_params = dict(directory=sample_dir, classes=['pos','neg'], target_size=IMAGE_SHAPE, batch_size=batch_size)\n",
    "ig_normal = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=validation_ratio,rescale=1/255)\n",
    "normal_flow_train = ig_normal.flow_from_directory(subset='training', **generic_params)\n",
    "normal_flow_valid = ig_normal.flow_from_directory(subset='validation', **generic_params)\n",
    "\n",
    "for image_batch, label_batch in normal_flow_train:\n",
    "    print(\"Image batch shape: \", image_batch.shape)\n",
    "    print(\"Label batch shape: \", label_batch.shape)\n",
    "    break\n",
    "\n",
    "# 重新加载一下iter\n",
    "normal_flow_train = ig_normal.flow_from_directory(subset='training', **generic_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T02:07:15.962360Z",
     "start_time": "2019-12-02T02:06:44.929978Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_extractor_url = \"https://tfhub.dev/google/imagenet/inception_resnet_v2/feature_vector/4\" #@param {type:\"string\"}\n",
    "feat_layer = hub.KerasLayer(feature_extractor_url, input_shape=(224,224,3))\n",
    "feat_layer.trainable = False  # feature_vector的生成就不用训练了\n",
    "model = tf.keras.Sequential([\n",
    "  feat_layer,\n",
    "  tf.keras.layers.Dense(normal_flow_train.num_classes, activation='softmax')\n",
    "])\n",
    "model.summary()\n",
    "# pred = model(image_batch)\n",
    "# pred\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=\"categorical_crossentropy\", metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T10:29:48.598999Z",
     "start_time": "2019-11-29T10:29:48.592700Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class HistoryCB(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.batch_losses = []\n",
    "        self.batch_acc = []\n",
    "        self.logs_dict={}\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        print(\"cococococco at \",batch)\n",
    "        self.logs_dict.update({batch:logs})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:04:18.966962Z",
     "start_time": "2019-12-02T02:15:44.000229Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tbd_cb=tf.keras.callbacks.TensorBoard(log_dir='./tmp/auto_score/tensorboard_logs',\n",
    "                                      histogram_freq=0,write_graph=False,update_freq='batch',\n",
    "                                      profile_batch=0)\n",
    "\n",
    "checkpoint_path = \"./tmp/auto_score/ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "ckpt_cb=tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, verbose=1, save_best_only=True)\n",
    "\n",
    "es_db = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "# progress_db = tf.keras.callbacks.ProgbarLogger(count_mode='steps')\n",
    "\n",
    "custom_db = HistoryCB()\n",
    "\n",
    "history = model.fit_generator(normal_flow_train, epochs=15,\n",
    "                              steps_per_epoch = normal_flow_train.samples // normal_flow_train.batch_size,\n",
    "                              validation_data = normal_flow_valid,\n",
    "#                               validation_steps = normal_flow_valid.samples,\n",
    "                              verbose=1,\n",
    "                              callbacks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:39:24.142406Z",
     "start_time": "2019-12-02T03:39:24.126511Z"
    }
   },
   "outputs": [],
   "source": [
    "history.params\n",
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 `checkpoint_path` 格式保存权重\n",
    "# checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
    "# model.save_weights(checkpoint_path.format(epoch=0))\n",
    "# model.save(\"mymodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:36:55.421829Z",
     "start_time": "2019-12-02T03:36:38.790142Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"./tmp/auto_score/models/model_bysave.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T07:09:51.584935Z",
     "start_time": "2019-11-29T07:09:46.679591Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(\n",
    "    model=model,\n",
    "    filepath=\"./tmp/auto_score/models/model_1\",\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=\"h5\",\n",
    "    signatures=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T12:00:06.548528Z",
     "start_time": "2019-12-02T12:00:06.539409Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "?requests.get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T12:08:41.645023Z",
     "start_time": "2019-12-02T12:07:26.593524Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pos_path=\"/home/zhoutong/notebook_collection/tmp/CV_auto_score/pos/{}\"\n",
    "neg_path=\"/home/zhoutong/notebook_collection/tmp/CV_auto_score/neg/{}\"\n",
    "verify_path = \"/home/zhoutong/notebook_collection/tmp/CV_auto_score/verify/{}\"\n",
    "r=16\n",
    "total = pd.concat([df_v.head(r),df_v[190:190+r],df_v[500:500+r],df_v.tail(r)])\n",
    "total.head(10)\n",
    "\n",
    "total_res =[]\n",
    "for idx,row in total.iterrows():\n",
    "    total_res.append((row['banner_url'],row['ctr'],np.array(Image.open(verify_path.format(row['fileName'])).resize((224,224)))))\n",
    "fig, axe_list=plt.subplots(8,8,figsize=(15,16))\n",
    "\n",
    "for idx,(url,ctr,img) in enumerate(total_res):\n",
    "    axe = axe_list.flatten()[idx]\n",
    "    axe.set_axis_off()\n",
    "    obj_text=\",\".join([i['obj']+\":\"+str(i['cnt']) for i in json.loads(requests.get(\"http://10.65.34.65:8004/obj\",params={\"img_url\":url,\"id\":-1}).text)['result']])\n",
    "#     obj_text=\"asdf\"\n",
    "    _ = axe.imshow(img)\n",
    "    _ = axe.text(x=0, y=axe.get_ylim()[0]+50, s=\"{:4f}\\n{}\".format(ctr,obj_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:39:24.085823Z",
     "start_time": "2019-12-02T03:38:17.633182Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bysave = tf.keras.models.load_model(\"./tmp/auto_score/models/model_bysave.h5\", custom_objects={'KerasLayer':hub.KerasLayer})\n",
    "bysave.build((None,224,224,3))\n",
    "type(bysave)\n",
    "print(\">>> test: \")\n",
    "type(bysave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:50:19.147848Z",
     "start_time": "2019-12-02T03:49:54.812842Z"
    }
   },
   "outputs": [],
   "source": [
    "bysave.predict(np.array([np.array(img) for img in img_pos]))\n",
    "bysave.predict(np.array([np.array(img) for img in img_neg]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T07:51:26.884212Z",
     "start_time": "2019-11-29T07:50:14.616655Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "bytfkeras = tf.keras.models.load_model(\"./tmp/auto_score/models/model_1\", custom_objects={'KerasLayer':hub.KerasLayer})\n",
    "bytfkeras.build((None,224,224,3))\n",
    "print(\">>> test: \")\n",
    "type(bytfkeras)\n",
    "bytfkeras.predict(np.expand_dims(np.array(img),0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图片分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图片切割出人脸重新存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import dlib\n",
    "dlib_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "def get_face_imgArr(imgArr, enlarge=0.2):\n",
    "    imgArr = imgArr#.astype(np.dtype('|u1'))\n",
    "    img_gray = np.array(Image.fromarray(imgArr).convert(\"L\"))\n",
    "    rect_list = dlib_detector(img_gray, 1)\n",
    "    face_area_list = []\n",
    "    for rect in rect_list:\n",
    "        (h, w) = (rect.height(), rect.width())\n",
    "        (h, w) = (int(h * enlarge), int(w * enlarge))\n",
    "        top = rect.top() - h if rect.top() - h > 0 else 0\n",
    "        bottom = rect.bottom() + h if rect.bottom() + h < imgArr.shape[0] else imgArr.shape[0]\n",
    "        left = rect.left() - h if rect.left() - h > 0 else 0\n",
    "        right = rect.right() + h if rect.right() + h < imgArr.shape[1] else imgArr.shape[1]\n",
    "        face_area_list.append((imgArr[top:bottom, left:right], rect.area()))\n",
    "    face_area_list = sorted(face_area_list, key=lambda x: x[1], reverse=True)\n",
    "    return face_area_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T04:47:33.395028Z",
     "start_time": "2019-12-05T04:46:51.759407Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_dir=\"./tmp/CV_clf/ethnicity\"\n",
    "label = ['Australoid','Negroid','Caucasoid','Mongoloid']\n",
    "targetFormat = ['.jpg']\n",
    "for label_dir in [os.path.join(sample_dir,i) for i in label]:\n",
    "    for root, dirs, files in os.walk(label_dir):\n",
    "        face_root = root.replace(\"ethnicity\",\"ethnicity/face\")\n",
    "        no_face_root = root.replace(\"ethnicity\",\"ethnicity/no_face\")\n",
    "        if not os.path.exists(face_root): os.mkdir(face_root)\n",
    "        if not os.path.exists(no_face_root): os.mkdir(no_face_root)\n",
    "        for name in tqdm(files,desc=root):\n",
    "            if not name.startswith(\".\") and os.path.splitext(name)[-1] in targetFormat:\n",
    "                imgArr = np.array(Image.open(os.path.join(root,name)))\n",
    "                save_name = os.path.splitext(name)[0]+\"_face{}\"+os.path.splitext(name)[-1]\n",
    "                save_path = os.path.join(face_root,save_name)\n",
    "                face_area_list = get_face_imgArr(imgArr)\n",
    "                if len(face_area_list)>0:\n",
    "                    for idx,(faceArr,area) in enumerate(face_area_list):\n",
    "                        Image.fromarray(faceArr).save(save_path.format(idx))\n",
    "                else:\n",
    "                    Image.fromarray(imgArr).save(os.path.join(no_face_root,name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据流"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 公开数据集 | 花草数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T11:50:39.062719Z",
     "start_time": "2019-12-13T11:50:38.591301Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3306 images belonging to 5 classes.\n",
      "Found 364 images belonging to 5 classes.\n",
      "Image batch shape:  (32, 96, 96, 3)\n",
      "Label batch shape:  (32, 5)\n",
      "['roses', 'sunflowers', 'tulips', 'daisy', 'dandelion']\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SHAPE = (96,96)\n",
    "batch_size = 32\n",
    "validation_ratio=0.1\n",
    "data_root = tf.keras.utils.get_file(\n",
    "  'flower_photos','https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "   untar=True)\n",
    "\n",
    "ig_flower = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=validation_ratio,rescale=1/255)\n",
    "label = [i for i in os.listdir(data_root) if os.path.isdir(os.path.join(data_root,i))]\n",
    "generic_params = dict(directory=str(data_root), classes=label, target_size=IMAGE_SHAPE, batch_size=batch_size)\n",
    "# image_data\n",
    "normal_flow_train = ig_flower.flow_from_directory(subset='training', **generic_params)\n",
    "normal_flow_valid = ig_flower.flow_from_directory(subset='validation', **generic_params)\n",
    "\n",
    "for image_batch, label_batch in normal_flow_train:\n",
    "    print(\"Image batch shape: \", image_batch.shape)\n",
    "    print(\"Label batch shape: \", label_batch.shape)\n",
    "    break\n",
    "\n",
    "# 重新加载一下iter\n",
    "normal_flow_train.reset()\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 人种数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-11T14:09:53.768811Z",
     "start_time": "2019-12-11T14:09:53.162702Z"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (96,96)\n",
    "batch_size = 1\n",
    "validation_ratio=0.1\n",
    "sample_dir = \"./tmp/CV_clf/ethnicity/face/mtcn_182\"\n",
    "label = ['Indian','Negroid','Caucasoid','Mongoloid']\n",
    "generic_params = dict(directory=sample_dir, classes=label, target_size=IMAGE_SHAPE, batch_size=batch_size)\n",
    "ig_normal = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=validation_ratio,rescale=1/255)\n",
    "normal_flow_train = ig_normal.flow_from_directory(subset='training', **generic_params)\n",
    "normal_flow_valid = ig_normal.flow_from_directory(subset='validation', **generic_params)\n",
    "\n",
    "for image_batch, label_batch in normal_flow_train:\n",
    "    print(\"Image batch shape: \", image_batch.shape)\n",
    "    print(\"Label batch shape: \", label_batch.shape)\n",
    "    break\n",
    "\n",
    "# 重新加载一下iter\n",
    "normal_flow_train.reset()\n",
    "print(\">>> 训练集分布：\")\n",
    "print(np.vstack(np.unique([i.split(\"/\")[-2] for i in normal_flow_train.filepaths],return_counts=True)).T)\n",
    "print(\">>> 测试集分布：\")\n",
    "print(np.vstack(np.unique([i.split(\"/\")[-2] for i in normal_flow_valid.filepaths],return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 临时 | 用SVM试试\n",
    "多分类SVM还是不好弄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T11:50:31.716998Z",
     "start_time": "2019-12-13T11:50:31.426763Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T11:50:48.513053Z",
     "start_time": "2019-12-13T11:50:42.540739Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_extractor_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_075_96/feature_vector/4\" #@param {type:\"string\"}\n",
    "feat_layer = hub.KerasLayer(feature_extractor_url, input_shape=IMAGE_SHAPE+(3,))\n",
    "feat_layer.trainable = False  # feature_vector的生成就不用训练了\n",
    "featureM = tf.keras.Sequential([feat_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T11:45:49.744472Z",
     "start_time": "2019-12-13T11:45:31.241497Z"
    },
    "code_folding": [
     0,
     4,
     21
    ],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e6bc6b19b343e298d11439b205eeed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='pre', max=103.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474c40ec7bf3438f8cd733cfa2ddb387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='pre', max=11.0, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 得到向量 存起来\n",
    "trainX = []\n",
    "trainY = []\n",
    "total = normal_flow_train.samples//normal_flow_train.batch_size\n",
    "for idx,(img_batch,label_batch) in tqdm(enumerate(normal_flow_train),desc=\"pre\",total=total):\n",
    "    if idx >= total:\n",
    "        break\n",
    "    trainX.append(featureM.predict(img_batch))\n",
    "    trainY.append(label_batch)\n",
    "\n",
    "trainX = np.array(trainX)\n",
    "trainX = np.reshape(trainX, (-1,trainX.shape[-1]))\n",
    "trainY = np.array(trainY)\n",
    "trainY = np.reshape(trainY, (-1,trainY.shape[-1]))\n",
    "\n",
    "np.save(\"./tmp/CV_clf/ethnicity/trainX_feature.npy\",trainX)\n",
    "np.save(\"./tmp/CV_clf/ethnicity/trainY.npy\",trainY)\n",
    "\n",
    "validX = []\n",
    "validY = []\n",
    "total = normal_flow_valid.samples//normal_flow_valid.batch_size\n",
    "for idx,(img_batch,label_batch) in tqdm(enumerate(normal_flow_valid),desc=\"pre\",total=total):\n",
    "    if idx >= total:\n",
    "        break\n",
    "    validX.append(featureM.predict(img_batch))\n",
    "    validY.append(label_batch)\n",
    "\n",
    "validX = np.array(validX)\n",
    "validX = np.reshape(validX, (-1,validX.shape[-1]))\n",
    "validY = np.array(validY)\n",
    "validY = np.reshape(validY, (-1,validY.shape[-1]))\n",
    "\n",
    "\n",
    "np.save(\"./tmp/CV_clf/ethnicity/validX_feature.npy\",validX)\n",
    "np.save(\"./tmp/CV_clf/ethnicity/validY.npy\",validY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T12:05:48.424943Z",
     "start_time": "2019-12-13T12:05:48.395361Z"
    }
   },
   "outputs": [],
   "source": [
    "trainX = np.load(\"./tmp/CV_clf/ethnicity/trainX_feature.npy\")\n",
    "trainY = np.load(\"./tmp/CV_clf/ethnicity/trainY.npy\")\n",
    "validX = np.load(\"./tmp/CV_clf/ethnicity/validX_feature.npy\")\n",
    "validY = np.load(\"./tmp/CV_clf/ethnicity/validY.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T11:57:29.479862Z",
     "start_time": "2019-12-13T11:57:29.313774Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "validY = [1 if np.all(l==[1,0,0,0,0]) else 0 for l in validY]\n",
    "clf.fit(validX, validY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T11:59:02.228247Z",
     "start_time": "2019-12-13T11:59:02.212992Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 5.76509809, 0.        , ..., 2.68946719, 0.48810992,\n",
       "        1.25581551],\n",
       "       [0.        , 1.96322298, 0.        , ..., 0.        , 0.3944521 ,\n",
       "        0.35329315],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        2.00690985],\n",
       "       ...,\n",
       "       [0.77579004, 0.        , 0.        , ..., 0.        , 0.32076067,\n",
       "        0.06278009],\n",
       "       [0.        , 3.66805935, 0.        , ..., 0.70669198, 1.33657658,\n",
       "        0.64278096],\n",
       "       [0.        , 0.04745711, 0.        , ..., 0.02288424, 0.15471037,\n",
       "        3.48126078]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(218, 1280)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([158,  60], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.support_vectors_\n",
    "clf.support_vectors_.shape\n",
    "clf.n_support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subclass + keras.applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-11T12:28:29.578302Z",
     "start_time": "2019-12-11T12:28:29.566842Z"
    },
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "class EthnicityM_KApp(tf.keras.Model):\n",
    "    def __init__(self,num_classes:int, scope:str=\"EthnicityM\", **kwargs):\n",
    "        super().__init__(name=\"EthnicityM\", **kwargs)\n",
    "        # 参考自： https://www.tensorflow.org/tutorials/images/transfer_learning\n",
    "        # MobileNetV2 获得的是 (None, 3, 3, 1280) 的特征block\n",
    "        self.feature_model = tf.keras.applications.MobileNetV2(input_shape=IMAGE_SHAPE+(3,), include_top=False,weights=\"imagenet\")\n",
    "        self.feature_model.trainable=False\n",
    "        # 平均池化 得到 (None, 1280) 的特征\n",
    "        self.global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        # 全连接\n",
    "        self.prediction_layer = tf.keras.layers.Dense(num_classes)\n",
    "        \n",
    "    def call(self, inp, training=False):\n",
    "        x = self.feature_model(inp)\n",
    "        x = self.global_average_layer(x)\n",
    "        x = self.prediction_layer(x)\n",
    "        return x\n",
    "\n",
    "model=EthnicityM_KApp(normal_flow_train.num_classes)\n",
    "model.build((None,96,96,3))\n",
    "model.summary()\n",
    "\n",
    "checkpoint_dir = \"./tmp/CV_clf/ethnicity/ckpt_Subclass_KApp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subclass + Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-11T12:40:27.742658Z",
     "start_time": "2019-12-11T12:40:22.440178Z"
    },
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "class EthnicityM_Hub(tf.keras.Model):\n",
    "    def __init__(self,num_classes:int, scope:str=\"EthnicityM\", **kwargs):\n",
    "        super().__init__(name=\"EthnicityM\", **kwargs)\n",
    "        # 参考自： https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub\n",
    "        feature_extractor_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_075_96/feature_vector/4\"\n",
    "        self.feature_model = hub.KerasLayer(feature_extractor_url, input_shape=IMAGE_SHAPE+(3,))\n",
    "        self.feature_model.trainable=False\n",
    "        # 全连接\n",
    "        self.prediction_layer = tf.keras.layers.Dense(num_classes)\n",
    "        \n",
    "    def call(self, inp, training=False):\n",
    "        x = self.feature_model(inp)\n",
    "        x = self.prediction_layer(x)\n",
    "        return x\n",
    "\n",
    "model=EthnicityM_Hub(normal_flow_train.num_classes)\n",
    "model.build((None,96,96,3))\n",
    "model.summary()\n",
    "\n",
    "checkpoint_dir = \"./tmp/CV_clf/ethnicity/ckpt_Subclass_Hub\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential + Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T12:02:05.532282Z",
     "start_time": "2019-12-13T12:01:44.914548Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer_1 (KerasLayer)   (None, 1536)              54336736  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 7685      \n",
      "=================================================================\n",
      "Total params: 54,344,421\n",
      "Trainable params: 7,685\n",
      "Non-trainable params: 54,336,736\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_sequential_model():\n",
    "    feature_extractor_url = \"https://tfhub.dev/google/imagenet/inception_resnet_v2/feature_vector/4\" #@param {type:\"string\"}\n",
    "    feat_layer = hub.KerasLayer(feature_extractor_url, input_shape=IMAGE_SHAPE+(3,))\n",
    "    feat_layer.trainable = False  # feature_vector的生成就不用训练了\n",
    "    return tf.keras.Sequential([\n",
    "      feat_layer,\n",
    "      tf.keras.layers.Dense(normal_flow_train.num_classes, activation='softmax')\n",
    "    ])\n",
    "model = get_sequential_model()\n",
    "model.summary()\n",
    "\n",
    "checkpoint_dir = \"./tmp/CV_clf/ethnicity/ckpt_Sequential_Hub\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自己写循环"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T12:53:43.132929Z",
     "start_time": "2019-12-10T12:53:43.110306Z"
    }
   },
   "outputs": [],
   "source": [
    "# tensorboard写入第一组图片\n",
    "summary_writer = tf.summary.create_file_writer(\"./tmp/CV_clf/ethnicity/tensorboard\")\n",
    "with summary_writer.as_default():\n",
    "    _=tf.summary.image(\"Trainning Data\", normal_flow_train[0][0], max_outputs=4, step=0)\n",
    "\n",
    "# 为了写入计算图\n",
    "# @tf.function\n",
    "# def traceme(x):\n",
    "#     return model(x)\n",
    "# tf.summary.trace_on(graph=True, profiler=True)\n",
    "# traceme(tf.zeros((1,)+normal_flow_train.image_shape))\n",
    "# with summary_writer.as_default():\n",
    "#     tf.summary.trace_export(name=\"model_trace\", step=0, profiler_outdir=\"./tmp/CV_clf/ethnicity/tensorboard\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T12:53:44.204605Z",
     "start_time": "2019-12-10T12:53:44.197895Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "ce_loss_fn = tf.keras.losses.categorical_crossentropy\n",
    "# mean_calc = tf.keras.metrics.Mean()  # 这个Mean是累积的，也就是说到了第100batch它计算的实际上是0~100batch的均值\n",
    "acc_fn = tf.keras.metrics.categorical_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ckpt\n",
    "- ckpt还需要知道opt和model? （推测应该是不指定无法resotre）\n",
    "\n",
    "看看官方手册\n",
    "- [完整ckpt & ckpt-manager 的示例](https://www.tensorflow.org/guide/checkpoint)\n",
    "- [checkpoint类](https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T12:53:46.071337Z",
     "start_time": "2019-12-10T12:53:46.060356Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(checkpoint_dir,\"ckpt_{epoch}\")\n",
    "# ckpt = tf.train.Checkpoint(opt=opt,model=model)\n",
    "# status = checkpoint.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "# checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "ckpt = tf.train.Checkpoint(step=tf.Variable(1))\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_dir, max_to_keep=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T15:40:49.074804Z",
     "start_time": "2019-12-10T12:54:10.379738Z"
    },
    "code_folding": [
     3
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "normal_flow_train.reset()\n",
    "step_per_epoch = normal_flow_train.samples // normal_flow_train.batch_size\n",
    "best_valid_acc = 0.0\n",
    "for e in range(15):\n",
    "    for step, (image_batch, label_batch) in tqdm(enumerate(normal_flow_train), desc=f\"Epoch: {e}\", total=step_per_epoch):\n",
    "        if step>= step_per_epoch:\n",
    "            break\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred_batch = model(image_batch)\n",
    "            loss_batch = ce_loss_fn(label_batch,pred_batch)\n",
    "            acc_batch = acc_fn(label_batch,pred_batch)\n",
    "        gradients = tape.gradient(loss_batch, model.trainable_variables)\n",
    "        _ = opt.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        loss,acc = np.mean(loss_batch),np.mean(acc_batch)\n",
    "        with summary_writer.as_default(): \n",
    "            _ = tf.summary.scalar('train_loss', loss, step=step+e*step_per_epoch)\n",
    "            _ = tf.summary.scalar('train_acc', acc, step=step+e*step_per_epoch)\n",
    "        \n",
    "    _ = ckpt.step.assign_add(1)\n",
    "    val_pred = model.predict_generator(normal_flow_valid)\n",
    "    val_label = tf.one_hot(normal_flow_valid.labels,depth=normal_flow_valid.num_classes)\n",
    "    val_loss = np.mean(ce_loss_fn(val_label, val_pred).numpy())\n",
    "    val_acc = np.mean(acc_fn(val_label, val_pred).numpy())\n",
    "    with summary_writer.as_default(): \n",
    "        _ = tf.summary.scalar('val_loss', val_loss, step=step+e*step_per_epoch)\n",
    "        _ = tf.summary.scalar('val_acc', val_acc, step=step+e*step_per_epoch)\n",
    "    print(f'[e]:{e} [step]:{step} [loss]:{loss:.4f} [acc]:{acc:.4f} [val_loss]:{val_loss:.4f} [val_acc]:{val_acc:.4f}')\n",
    "    if val_acc > best_valid_acc:\n",
    "        best_valid_acc = val_acc\n",
    "        save_path = ckpt_manager.save()\n",
    "        print(f\"acc improved [from]:{best_valid_acc:.4f} [to]:{val_acc:.4f}.\\n[ckpt-path]: {save_path}\")\n",
    "    else:\n",
    "        print(f\"acc NOT improved [from]:{best_valid_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用Keras的 fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T08:48:31.066884Z",
     "start_time": "2019-12-13T08:48:31.056649Z"
    },
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(checkpoint_dir,\"ckpt_{epoch}\")\n",
    "ckpt_cb=tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, \n",
    "                                           save_weights_only=True, \n",
    "                                           verbose=1, save_best_only=True)\n",
    "\n",
    "# 使用Adam就用不上这个cb了\n",
    "def decay(epoch):\n",
    "    if  epoch <= 4:\n",
    "        return 0.045\n",
    "    elif 4 < epoch and epoch <= 10:\n",
    "        return 1e-3\n",
    "    else:\n",
    "        return 1e-5\n",
    "lr_cb = tf.keras.callbacks.LearningRateScheduler(decay)\n",
    "\n",
    "tbd_cb=tf.keras.callbacks.TensorBoard(log_dir='./tmp/CV_clf/ethnicity/tensorboard',\n",
    "                                      histogram_freq=1,write_graph=False,update_freq='batch',\n",
    "                                      profile_batch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T08:50:15.997552Z",
     "start_time": "2019-12-13T08:48:34.525765Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss=\"categorical_crossentropy\", metrics=['acc'])\n",
    "history = model.fit_generator(normal_flow_train, epochs=20,\n",
    "                              steps_per_epoch = normal_flow_train.samples // normal_flow_train.batch_size,\n",
    "                              validation_data = normal_flow_valid,\n",
    "#                               validation_steps = normal_flow_valid.samples,\n",
    "                              verbose=1,\n",
    "                              callbacks=[ckpt_cb,tbd_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T01:29:01.116773Z",
     "start_time": "2019-12-12T01:29:00.724593Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "fig,axes_list = plt.subplots(2,1, figsize=(8,8))\n",
    "axe1=axes_list.flatten()[0]\n",
    "axe2=axes_list.flatten()[1]\n",
    "\n",
    "_ = axe1.plot(acc, label='Training Accuracy')\n",
    "_ = axe1.plot(val_acc, label='Validation Accuracy')\n",
    "_ = axe1.legend(loc='lower right')\n",
    "_ = axe1.set_ylabel('Accuracy')\n",
    "_ = axe1.set_ylim([min(plt.ylim()),1])\n",
    "_ = axe1.set_title('Training and Validation Accuracy')\n",
    "\n",
    "\n",
    "_ = axe2.plot(loss, label='Training Loss')\n",
    "_ = axe2.plot(val_loss, label='Validation Loss')\n",
    "_ = axe2.legend(loc='upper right')\n",
    "_ = axe2.set_ylabel('Cross Entropy')\n",
    "_ = axe2.set_ylim([0,2.0])\n",
    "_ = axe2.set_title('Training and Validation Loss')\n",
    "_ = axe2.set_xlabel('epoch')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-11T20:08:05.661470Z",
     "start_time": "2019-12-11T20:08:05.177738Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.save(\"./tmp/CV_clf/ethnicity/saved_models/sequential_mobilenetv2_acc0.5895_loss1.02758.h5\")\n",
    "model.save(\"./tmp/CV_clf/ethnicity/saved_models/sequential_inceptionresnetv2_acc0.5895_loss1.02758.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型 加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-11T14:00:33.298528Z",
     "start_time": "2019-12-11T14:00:27.644692Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "M = get_sequential_model()\n",
    "# M = EthnicityM_Hub(normal_flow_train.num_classes)\n",
    "print(f\"loading from ckpt: {checkpoint_dir}\")\n",
    "_ = M.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "M.count_params()\n",
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T01:30:02.914326Z",
     "start_time": "2019-12-12T01:29:40.358235Z"
    }
   },
   "outputs": [],
   "source": [
    "M = tf.keras.models.load_model(\"./tmp/CV_clf/ethnicity/saved_models/sequential_inceptionresnetv2_acc0.5895_loss1.02758.h5\",custom_objects={\"KerasLayer\":hub.KerasLayer})\n",
    "M.count_params()\n",
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 示例测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T01:30:09.194239Z",
     "start_time": "2019-12-12T01:30:03.654580Z"
    }
   },
   "outputs": [],
   "source": [
    "# 注意 flow 默认是会shuffle的，要么手动把shuffle关掉( flow.shuffle=False ) 要么读一次通用\n",
    "sample_paths = normal_flow_valid.filepaths\n",
    "print(\">>> sample distribution:\")\n",
    "print(np.vstack(np.unique([i.split(\"/\")[-2] for i in sample_paths],return_counts=True)).T)\n",
    "\n",
    "imgArr_list_all=np.array([np.array(Image.open(p).resize((96,96)))/255 for p in sample_paths])\n",
    "pred = M.predict(imgArr_list_all)\n",
    "print(\">>> prediction distribution:\")\n",
    "print(np.vstack(np.unique([label[i] for i in np.argmax(pred,axis=1)],return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试整体分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T01:35:26.865725Z",
     "start_time": "2019-12-12T01:35:26.835084Z"
    }
   },
   "outputs": [],
   "source": [
    "df.sort_values('prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T01:36:10.613108Z",
     "start_time": "2019-12-12T01:36:10.468382Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([{\"label\":sample_paths[idx].split(\"/\")[-2],\n",
    "                    \"pred\":label[int(np.argmax(i))],\n",
    "                    \"prob\":np.max(i),\n",
    "                    \"pic\":sample_paths[idx]} for idx,i in enumerate(pred)])\n",
    "print(\">>> 原始预测结果信息 head(3) 如下：\")\n",
    "df.head(3)\n",
    "def wrap_stat(df):\n",
    "    def func(dfg):\n",
    "        item_list,cnt_list=np.unique(dfg['label'],return_counts=True)\n",
    "        return {i:j for i,j in zip(item_list,cnt_list)}\n",
    "    dfg = df.groupby(\"pred\").apply(func).apply(pd.Series).fillna(0) # 这里的 pd.Series 不能写到func里\n",
    "    dfg['pred_sum'] = sum([dfg[i] for i in dfg.columns])\n",
    "    dfg=dfg.append(pd.Series({i:dfg[i].sum() for i in dfg.columns}, name=\"label_sum\"), sort=False).fillna(0)\n",
    "    # 注意：P和R不能直接复制（dfg[\"p\"]=[...]） 例如先给dfg赋值了P，再计算R时取iteritems会多算一个P列导致KeyError\n",
    "    P = [round(row[idx]/row['pred_sum'],4) if idx!='label_sum' else None for idx,row in dfg.iterrows()]\n",
    "    R = pd.Series({idx: round(row[idx]/row['label_sum'],4) if idx!='pred_sum' else None for idx,row in dfg.iteritems()}, name=\"R\")\n",
    "    dfg['P'] = P\n",
    "    dfg = dfg.append(R)\n",
    "    dfg.columns=dfg.columns.set_names(\"label\")\n",
    "    return dfg\n",
    "print(\">>> 各类别预测结果分布如下：\")\n",
    "wrap_stat(df)\n",
    "print(\">>> 各类别预测结果（置信度>0.5）分布如下：\")\n",
    "wrap_stat(df.query(\"prob > 0.5\"))\n",
    "print(\">>> 各类别预测结果（置信度>0.8）分布如下：\")\n",
    "wrap_stat(df.query(\"prob > 0.8\"))\n",
    "print(\">>> 各类里预测结果的置信度分布？\")\n",
    "# imgArr_list = [np.array(Image.open(i)) for i in df.query(\"label=='Mongoloid' and pred != 'Mongoloid'\")['pic']]\n",
    "# fig,axes_list = plt.subplots(int(len(imgArr_list)**0.5), int(len(imgArr_list)**0.5)+1)\n",
    "# for idx,img in enumerate(imgArr_list):\n",
    "#     _ = axes_list.flatten()[idx].imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 带图测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取pred和label不同但置信度很高的样本看看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T02:44:05.991170Z",
     "start_time": "2019-12-13T02:44:04.650389Z"
    }
   },
   "outputs": [],
   "source": [
    "check=\"Negroid\"\n",
    "df_f = df.query(f\"label=='{check}' and pred!='{check}'\")\n",
    "\n",
    "_ = df_f['prob'].plot.hist()\n",
    "# bw_method 越小越拟合（可能会过拟合）\n",
    "_ = df_f['prob'].plot.kde(bw_method=0.1)\n",
    "print(f\">>> label=={check} & pred!={check} 的prob分布及分位数如下:\")\n",
    "plt.show()\n",
    "print(df_f['prob'].describe())\n",
    "\n",
    "hold = df_f['prob'].quantile(0.85)\n",
    "print(f\">>> 概率大于'{hold:.4f}' 总计有'{df_f[df_f['prob']>=hold].shape[0]}'个 show20如下\")\n",
    "\n",
    "to_show=20\n",
    "fig, axes = plt.subplots(int(to_show**0.5),int(to_show**0.5)+1, figsize=(15,15))\n",
    "# for idx,(df_idx, row) in enumerate(df_f.query(f\"prob >={hold}\").head(to_show).iterrows()):\n",
    "for idx,(df_idx, row) in enumerate(df_f.query(f\"prob <0.5\").head(to_show).iterrows()):\n",
    "    img = np.array(Image.open(row['pic']).resize((96,96)))\n",
    "    axe = axes.flatten()[idx]\n",
    "    axe.set_axis_off()\n",
    "    _ = axe.imshow(img)\n",
    "    info=\"[y]:{}\\n[p]:{}={:.4f}\".format(row['label'], row['pred'],row['prob'])\n",
    "    _ = axe.set_title(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机抽30张图预测看看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-11T14:08:41.302861Z",
     "start_time": "2019-12-11T14:08:39.508717Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample = np.random.choice(sample_paths,30)\n",
    "sample.shape\n",
    "imgArr_list=np.array([np.array(Image.open(p).resize((96,96)))/255 for p in sample])\n",
    "pred_raw = M.predict(imgArr_list)\n",
    "pred = [label[int(np.argmax(i))] for i in pred_raw]\n",
    "pred_prob = [np.max(i) for i in pred_raw]\n",
    "fig,axe_list = plt.subplots(6,5, figsize=(15,20))\n",
    "for idx,img in enumerate(imgArr_list):\n",
    "    axe = axe_list.flatten()[idx]\n",
    "    axe.set_axis_off()\n",
    "    _ = axe.imshow(img)\n",
    "    y,p,prob = sample[idx].split(\"/\")[-2], pred[idx],pred_prob[idx]\n",
    "    _ = axe.text(x=0, y=axe.get_ylim()[0]+10, s=\"y:{} p:{}={:.4f}\".format(y,p,prob), color=\"green\" if y==p else \"red\")\n",
    "    _ = axe.set_title(sample[idx].split(\"/\")[-1],fontsize=7,color=\"green\" if y==p else \"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python3.6(tf2)",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "293.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

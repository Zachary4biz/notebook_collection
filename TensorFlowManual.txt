
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
%matplotlib inline
from tqdm.auto import tqdm
import concurrent.futures
from multiprocessing import Pool
import copy, os, sys, psutil
from collections import Counter
import itertools
from zac_pyutils.ExqUtils import zprint

import tensorflow as tf

import tensorflow as tf
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
%matplotlib inline

import os
os.environ["CUDA_VISIBLE_DEVICES"]="-1"  # 禁用GPU

# 允许GPU渐进占用
sess_conf = tf.ConfigProto()
sess_conf.gpu_options.allow_growth = True  # 允许GPU渐进占用
sess_conf.allow_soft_placement = True  # 把不适合GPU的放到CPU上跑
with tf.Session(config=sess_conf) as sess:
    print(sess)

# sess.run(.. options=run_opt)可以在OOM的时候提供当前已经声明了的变量
run_opt = tf.RunOptions()
run_opt.report_tensor_allocations_upon_oom = True

tf.reset_default_graph()
np.random.seed(10)
# batch_size:2  timesteps:4 inputs:5
# 在NLP任务可以理解为：2段语料，每个语料4个词（索引），每个词5维向量
X = np.random.randn(2,4,5).astype(np.float32)
X[1, 2:] = 0  # 指定索引位置的元素全置为0
print(">>X:{}\n".format(X.shape),X)
X_lengths = [4,2]  # 手动指定各batch里有效数据（非0数据）的步长


def make_cell(hidden_size:int, is_training:bool=True, keep_prob:float=0.8):
    cell = tf.nn.rnn_cell.LSTMCell(hidden_size, forget_bias=0.0)
    if is_training and keep_prob < 1:
        cell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=keep_prob)
    return cell
layer_num = 2
hidden_size = 3
mlstm_cell = tf.nn.rnn_cell.MultiRNNCell([make_cell(hidden_size) for _ in range(layer_num)], state_is_tuple=True)
print(f">>> 在执行之前就取 variable 是空的list:\n{mlstm_cell.variables}")
init_state = mlstm_cell.zero_state(X.shape[0], dtype=tf.float32)
outputs, last_states = tf.nn.dynamic_rnn(cell=mlstm_cell, 
                                         inputs=X, 
                                         initial_state=init_state,
                                         sequence_length=X_lengths)
print(f">>> 在执行dynamic_rnn之后获取才有用variable:\n{mlstm_cell.variables}")
for idx,tensor in enumerate(mlstm_cell.variables):
    if idx % 2 == 0:
        print(f"  ++偶数索引下为kernel:{tensor}")
        _ = tf.summary.histogram(f"lstm_kernel_{idx}",tensor)
    else:
        print(f"  --奇数索引下为bias:{tensor}")
        _ = tf.summary.histogram(f"lstm_bias_{idx}",tensor)
        
# 在sess里跑出结果看看
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    vars_ = sess.run(mlstm_cell.variables)  # 直接init还不行，还得run才有结果

    print("\n","*****在sess里跑出结果观察*****")
    for idx,tensor in enumerate(vars_):
        if idx % 2 == 0:
            print(f"  ++偶数索引下为kernel:{tensor.shape}\n",tensor)
        else:
            print(f"  --奇数索引下为bias:{tensor.shape}\n",tensor)

a_ = [[[1,1],[2,2]],
      [[3,3],[4,4]]]
a_ = np.array(a_)
"a_",a_.shape

a = tf.Variable(a_,dtype=tf.float32)
"a",a.shape

a_tfreshape = tf.reshape(a,[2,2,2,-1])
"a_tfreshape",a_tfreshape.shape
a_tfexpand = tf.expand_dims(a,-1)
"a_tfexpand",a_tfexpand.shape

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    print("原始shape为")
    sess.run(tf.shape(a))
    print("-1 就是在最后一维上扩展一个")
    sess.run(tf.shape(tf.expand_dims(a,-1)))
    print("0 就是在第0维上扩展一个")
    sess.run(tf.shape(tf.expand_dims(a,0)))
    print("1 就是在第1维上扩展一个")
    sess.run(tf.shape(tf.expand_dims(a,1)))

a = np.random.randint(10,size=[2,3,8])
a_reshape = tf.reshape(a,[6,8])
a_reshape_strange = tf.reshape(a,[2,24])
with tf.Session() as sess:
    a_reshape_,a_reshape_strange_ = sess.run([a_reshape,a_reshape_strange])
    print("a: {}\n".format(a.shape),a)
    print("a_reshape_: {}\n".format(a_reshape_.shape),a_reshape_)
    print("a_reshape_strange_: {}\n".format(a_reshape_strange_.shape),a_reshape_strange_)

a = np.random.randint(10,size=[1,3,6])
b = np.random.randint(10,size=[1,4,6])
print("a: {}\n".format(a.shape),a)
print("b: {}\n".format(b.shape),b)
print("a,b 除了要concat的维度，其他维度必须一样才行")
c = tf.concat([a,b],axis=1)
with tf.Session() as sess:
    c_res = sess.run(c)
    print("c: {}\n".format(c_res.shape),c_res)

lstm_size = 6
a = np.array([[[i]*lstm_size for i in range(3)] for _ in range(2)])
a_1 = a[:,:1,:]
a_2 = a[:,1:,:]
print(f">>> a:{a.shape}\n",a)
print(f">>> a的上半部分a_1: [shape]:{a_1.shape}\n",a_1)
print(f">>> a的下半部分a_2: [shape]:{a_2.shape}\n",a_2)

with tf.Session() as sess:
    a_tfconcat = sess.run(tf.concat(a,axis=1))
    print(f">>> tf.concat(a,axis=1): [shape]:{a_tfconcat.shape}\n",a_tfconcat)
    a_tfreshape = sess.run(tf.reshape(a,[-1,lstm_size]))
    print(f">>> tf.reshape(a,[-1,lstm_size]): [shape]:{a_tfreshape.shape}\n",a_tfreshape)
    a_concat2part = sess.run(tf.concat([a_1,a_2], axis=1))
    print(f">>> tf.concat([a_1,a_2],axis=1): [shape]:{a_concat2part.shape}\n",a_concat2part)

    print(f">>> concat参数传一个tensor是不会发生任何变化的, tf.concat(a,axis=1)==a: {(a_tfconcat==a).all()}")
    print(f">>> 把这个tensor拆成两部分再来concat得到原变量, （然后在做reshape）")
    print(f">>>   tf.concat([a_1,a_2],axis=1)==a:{(a_concat2part==a).all()}")
    
    a_np_concatenate = np.concatenate(a,axis=1)
    print(f"numpy的concatenate是可以做到对一个多维数组在某一维度做concate的:shape变化是{a.shape}==>{a_np_concatenate.shape}\n",a_np_concatenate)

a = np.random.random([3,4,5])
b = np.random.random([3,4,5])
e = np.random.random([3,4,5])
c = tf.stack([a,b,e], axis=3)
a.shape
b.shape
c.shape

m = np.random.random([3,4,5,2])
m.shape
tf.unstack(m)
tf.unstack(m,axis=0)
tf.unstack(m,axis=1)
tf.unstack(m,axis=2)
tf.unstack(m,axis=3)

# ?tf.unstack

np.random.seed(2019)
a = np.random.randint(0,10,size=[2,3])
print(">>> a: {}\n".format(a.shape),a)
a_var = tf.Variable(a)

sum_on_none = tf.reduce_sum(a,axis=None)
sum_on_0 = tf.reduce_sum(a,axis=0)
mean_on_none = tf.reduce_mean(a,axis=None)
mean_on_0 = tf.reduce_mean(a,axis=0)
with tf.Session() as sess:
    sum_res_none, sum_res_0, res_none, res_0 = sess.run([sum_on_none, sum_on_0,mean_on_none,mean_on_0])
    print(">>> axis=None 上做reduce_sum: {}\n".format(sum_res_none.shape), sum_res_none)
    print(">>> axis=0 上做reduce_sum: {}\n".format(sum_res_0.shape), sum_res_0)
    print(">>> axis=None 上做reduce_mean: {}\n".format(res_none.shape), res_none)
    print(">>> axis=0 上做reduce_mean: {}\n".format(res_0.shape), res_0)

a = np.random.randint(0,10,size=[10])
print(">>> a: {}\n".format(a.shape),a)
sum_on_none = tf.reduce_sum(a,axis=None)
sum_on_0 = tf.reduce_sum(a,axis=0)
mean_on_none = tf.reduce_mean(a,axis=None)
mean_on_0 = tf.reduce_mean(a,axis=0)
with tf.Session() as sess:
    sum_res_none, sum_res_0, res_none, res_0 = sess.run([sum_on_none, sum_on_0,mean_on_none,mean_on_0])
    print(">>> axis=None 上做reduce_sum: {}\n".format(sum_res_none.shape), sum_res_none)
    print(">>> axis=0 上做reduce_sum: {}\n".format(sum_res_0.shape), sum_res_0)
    print(">>> axis=None 上做reduce_mean: {}\n".format(res_none.shape), res_none)
    print(">>> axis=0 上做reduce_mean: {}\n".format(res_0.shape), res_0)

a = np.random.random([3,4,5,6])
a.shape
tf.transpose(a)
tf.transpose(a,[2,1,0,3])

# truncated_normal 按正态分布生成数据，并且做标准差截断
with tf.Session() as sess:
    random_op = tf.truncated_normal([3,4],stddev=0.1,seed=2019)
    # random_op在一段程序里跑了三次，seed只控制程序每次相同位置生成时结果是一样的，而这三次则都不一样
    sess.run(random_op)
    sess.run(tf.cast(random_op,tf.int32))
    sess.run(tf.to_float(random_op,tf.int32))

i  = 0
n =10 

def cond(i, n):
    return i < n

def body(i, n):
    i = i + 1
    return i, n
i, n = tf.while_loop(cond, body, [i, n])

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    sess.run([i,n])

input = np.array([[[1, 1, 1], [2, 2, 2]],
                 [[3, 3, 3], [4, 4, 4]],
                 [[5, 5, 5], [6, 6, 6]]])
input.shape
print("如下两个是一样的，因为第三维总共就三个元素，取0:3就是所有的都取了")
input[1:2,0:1]
input[1:2,0:1,0:3]
print(">>> sess res as follow:")
with tf.Session() as sess:
    sess.run(tf.slice(input, [1, 0, 0], [1, 1, 3])) # 等价于 input[1:2,0:1,0:3]
    # [[[3, 3, 3]]]

    sess.run(tf.gather(input, [0, 2]))
    # 
    # [[[1, 1, 1], [2, 2, 2]],
    #  [[5, 5, 5], [6, 6, 6]]]

wordEmbedding = np.array([[0.8,0.9,0.6,0.5],[0.1,0.2,0.3,0.4]])
wordEmbedding
tensor = tf.cast(wordEmbedding,dtype=tf.float32,name='word2vec')
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    sess.run(tensor)

a = [1,2,3,4]
a = [float(i) for i in a]
with tf.Session() as sess:
    tf.argmax(a).eval()
    tf.nn.softmax(a).eval()

sigmoid(1)
sigmoid(0)

indices = [-1,0,3,5,7]
depth = 8
with tf.Session() as sess:
    print(sess.run(tf.one_hot(indices,depth)))

a = tf.constant(0.)
b = 2 * a
g = tf.gradients(ys=a + b, xs=[a, b], stop_gradients=[a, b]) 
g_nonstop = tf.gradients(ys=a + b, xs=[a, b])
with tf.Session() as sess:
    a_,b_,g_,g_nonstop_ = sess.run([a,b,g,g_nonstop])
    print(f"a: {a_}, b: {b_}")
    print("情况是：ys=a+b;b=2a")
    print(f"g是对a,b都做stop_gradients的导数结果:\n{g_}")
    print(f"g_nonstop是没有对a,b做stop_gradients的结果:\n{g_nonstop_}")

a = tf.stop_gradient(tf.constant(0.))
b = tf.stop_gradient(2 * a)
g = tf.gradients(a + b, [a, b])

with tf.Session() as sess:
    tf.nn.zero_fraction([1,1,1,0]).eval()
    tf.nn.zero_fraction([1,1,0,0]).eval()

emb = np.array([[1,2,3,4],[0.1,0.2,0.3,0.4],[10,20,30,40],[100,200,300,400]])
emb.shape
word_idx = [[0,1,2,1],[0,2,2,2]]

with tf.Session() as sess:
    sess.run(tf.nn.embedding_lookup(emb,word_idx))

emb = np.array([[1,2,3,4],
                [0.1,0.2,0.3,0.4],
                [10,20,30,40],
                [100,200,300,400],
                [1000,2000,3000,4000]
               ])

word_idx = [[0,1,2,1],
            [0,2,2,2]]

word_idx_sp = tf.sparse.SparseTensor(indices=[[0, 0], [1, 0], [2, 0]],
                              values=[2,3,4],
                              dense_shape=[10, 1])
word_idx_w = tf.sparse.SparseTensor(indices=word_idx_sp.indices,
                                    values=tf.ones_like(word_idx_sp.values),
                                    dense_shape=word_idx_sp.dense_shape)
with tf.Session() as sess:
    sess.run(word_idx_sp)
    sess.run(tf.sparse.to_dense(word_idx_sp))
    sess.run(tf.nn.embedding_lookup_sparse(emb,sp_ids=word_idx_sp,sp_weights=None,combiner='mean'))
    sess.run(tf.nn.embedding_lookup_sparse(emb,sp_ids=word_idx_sp,sp_weights=word_idx_w,combiner='mean'))


class Data():
    # 每一行可有多个1,如一张图既有 label_桌子 又有 label_椅子
    multi_hot_labels=np.array([[1,0,0],
                               [0,1,0],
                               [0,0,1],
                               [1,1,0],
                               [0,1,0]],dtype=np.float32)
    
    # 每一行只有一个1,如一张图只能有 label_桌子 不能有 label_椅子
    one_hot_labels=np.array([[1,0,0],
                             [0,1,0],
                             [0,0,1],
                             [1,0,0],
                             [0,1,0]],dtype=np.float32)
    

    logits=np.array([[12,3,2],
                     [3,10,1],
                     [1,2,5],
                     [4,6.5,1.2],
                     [3,6,1]],dtype=np.float32)
    
    
Data.multi_hot_labels
Data.one_hot_labels
Data.logits

from math import log,exp
def sigmoid(x):
    return 1/(1+np.exp(-x))

# 完全直接的CE，输入的是label和外部做好sigmoid的prediction
def exact_ce(pred,label):
    return -label*np.log(y_pred)-(1-label)*np.log(1-y_pred)

# tf化简公式（内部做了sigmoid，已化简掉了）
def ce_as_tf(pred,label):
    return max(pred, 0) - pred * label + log(1 + exp(-abs(pred)))

# 按计算公式计算（内部做了sigmoid）
def manual_formula(pred,label):
    y_pred = sigmoid(pred)
    E1 = -label*np.log(y_pred)-(1-label)*np.log(1-y_pred)
    return E1

ce_as_tf(1,1)
manual_formula(0.7,0.7) == ce_as_tf(0.7,0.7)

# 5个样本三分类问题，且一个样本可以同时拥有多类
print(manual_formula(pred=Data.logits,label=Data.multi_hot_labels))     # 按计算公式计算的结果

with tf.Session() as sess:
    tf.nn.sigmoid_cross_entropy_with_logits(logits=Data.logits,labels=Data.multi_hot_labels).eval()
    tf.nn.sigmoid_cross_entropy_with_logits(logits=Data.logits,labels=Data.one_hot_labels).eval()

# pos_weight = np.ones_like(logits.shape[0])
pos_weight = np.zeros_like(Data.logits.shape[0]) # 权重统一为0
with tf.Session() as sess:
    tf.nn.weighted_cross_entropy_with_logits(Data.multi_hot_labels,Data.logits, pos_weight, name=None).eval()
    tf.nn.weighted_cross_entropy_with_logits(Data.one_hot_labels,Data.logits, pos_weight, name=None).eval()

with tf.Session() as sess:
    tf.nn.softmax_cross_entropy_with_logits_v2(labels=Data.multi_hot_labels,logits=Data.logits).eval()
    tf.nn.softmax_cross_entropy_with_logits_v2(labels=Data.one_hot_labels,logits=Data.logits).eval()

# Data.multi_hot_labels
# tf.argmax(Data.multi_hot_labels,axis=-1).eval() # multi_hot（支持一图多类）的label做aargmax也没有意义
Data.one_hot_labels
Data.logits
label_rank1 = tf.argmax(Data.one_hot_labels,axis=-1)
logits_rank1 = tf.argmax(Data.logits,axis=-1)
with tf.Session() as sess:
    label_rank1.eval()
    logits_rank1.eval()
    tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label_rank1,logits=Data.logits).eval()
#     tf.nn.sparse_softmax_cross_entropy_with_logits(labels=,logits=Data.logits).eval()

with tf.Session() as sess:
    # softmax
    label_rank1=tf.argmax(Data.one_hot_labels,axis=-1)
    tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label_rank1,logits=Data.logits).eval()
    
    tf.nn.softmax_cross_entropy_with_logits_v2(labels=Data.one_hot_labels,logits=Data.logits).eval()
    
    # sigmoid
    tf.nn.sigmoid_cross_entropy_with_logits(logits=Data.logits,labels=Data.one_hot_labels).eval()

    pos_weight=np.ones_like(Data.logits.shape[0]) # 权重统一为1
    tf.nn.weighted_cross_entropy_with_logits(Data.one_hot_labels,Data.logits, pos_weight, name=None).eval()

emb = np.array([[1,2,3,4,5,6],
                [0.1,0.2,0.3,0.4,0.5,0.6],
                [10,20,30,40,50,60],
                [100,200,300,400,500,600]])
# word_idx = [[0,1,2,1],[0,2,2,2]]
word_idx = [[0,1,2]]
embeddedWords = tf.cast(tf.nn.embedding_lookup(emb,word_idx),dtype=tf.float32)
embeddedWordsExpanded = tf.expand_dims(embeddedWords, -1)

embeddedWordsExpanded.shape
filterSize = 2 # 卷积核大小
embeddingSize = 6 # 词向量维度
in_channels =1 # 输入的通道
numFilters = 4 # 卷积核的个数
sequenceLength = len(word_idx[0]) # 句子长度，一般要padding
filterShape = [filterSize, embeddingSize, in_channels, numFilters] # 构建conv2d使用的filter参数
# W = tf.Variable(tf.truncated_normal(filterShape, stddev=0.1,dtype=tf.float64), name="W",dtype=tf.float64)
# b = tf.Variable(tf.constant(0.1, shape=[numFilters],dtype=tf.float64), name="b",dtype=tf.float64)
# W = tf.convert_to_tensor(tf.truncated_normal(filterShape, stddev=0.1), name="W") # 正态分布随机初始化
W = tf.convert_to_tensor(tf.ones(filterShape), name="W") #
b = tf.convert_to_tensor(tf.constant(0.1,shape=[numFilters]),name="b")
conv = tf.nn.conv2d(input=embeddedWordsExpanded,
                    filter=W,
                    strides=[1, 1, 1, 1],
                    padding="VALID",
                    name="conv")
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
#     embeddedWords.eval()
    tf.shape(embeddedWordsExpanded).eval()
    tf.shape(W).eval()
    tf.shape(conv).eval()
    embeddedWordsExpanded.eval()
#     tf.shape(W).eval()
    print(">>> 每个卷积核都初始化为相同的权重W，目前按1填充")
    W.eval()
    print(">>> 偏置 b:")
    b.eval()
    print(">>> 1+2+3+4+5+6=21,0.1+..0.6=2.1,每个卷积的结果为23.1")
    conv.eval()
    

############################################
# 如下示例：
# BasicRNNCell: state_size=128 
# 输入：         batch_size=32
#               step_size=100
# 
#############################################
import tensorflow as tf
import numpy as np

cell = tf.contrib.rnn.BasicRNNCell(num_units=128) # state_size = 128
print(cell.state_size) # 128

inputs = tf.placeholder(np.float32, shape=(32, 100)) # 32 是 batch_size
h0 = cell.zero_state(32, np.float32) # 通过zero_state得到一个全0的初始状态，形状为(batch_size, state_size)
output, h1 = cell.call(inputs, h0) #调用call函数

print(h1.shape) # (32, 128)





def make_cell(hidden_size:int, is_training:bool=True, keep_prob:float=0.8):
    cell = tf.contrib.rnn.LSTMBlockCell(hidden_size, forget_bias=0.0)
    if is_training and keep_prob < 1:
        cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)
    return cell

#mlstm_cell = tf.contrib.rnn.MultiRNNCell([make_cell(hidden_size)] * layer_num, state_is_tuple=True)
# 会导致WARNING:tensorflow:At least two cells provided to MultiRNNCell are the same object and will share weights.
mlstm_cell = tf.contrib.rnn.MultiRNNCell([make_cell(hidden_size) for _ in range(layer_num)], state_is_tuple=True)
init_state = mlstm_cell.zero_state(batch_size, dtype=tf.float32)

tf.reset_default_graph()
np.random.seed(10)
# batch_size:2  timesteps:4 inputs:5
# 在NLP任务可以理解为：2段语料，每个语料4个词（索引），每个词5维向量
X = np.random.randn(2,4,5).astype(np.float32)
X[1, 2:] = 0  # 指定索引位置的元素全置为0
print(">>X:{}\n".format(X.shape),X)
X_lengths = [4, 2]  # 手动指定各batch里有效数据（非0数据）的步长

lstm_size = 3
lstm_cell = tf.contrib.rnn.BasicLSTMCell(num_units=lstm_size)
init_state = lstm_cell.zero_state(X.shape[0], dtype=tf.float64)  # 按batch_size全0初始化state(c_state和h_state)
outputs, last_states = tf.nn.dynamic_rnn(cell=lstm_cell, 
                                         inputs=X, 
                                         initial_state=init_state,
                                         sequence_length=X_lengths)

# 不告诉rnn各batch里非0数据的长度（真实步长）
outputs_, last_states_ = tf.nn.dynamic_rnn(cell=lstm_cell, 
                                         inputs=X, 
                                         initial_state=init_state)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    i = sess.run(init_state)
    print(">>init_state:\n")
    print("  >>c_state:\n", i.c)
    print("  >>h_state:\n", i.h)
    print("\n"," "*2,"*****指定sequence_length参数时的结果*****")
    o,s = sess.run([outputs,last_states])
    print(">>outputs: {}\n".format(o.shape), o)
    print(">>last_states:")
    print("  >>c_state:\n", s.c)
    print("  >>h_state:\n", s.h)

    print("\n"," "*2,"*****不指定sequence_length参数时的结果*****")
    o_,s_ = sess.run([outputs_,last_states_])
    print(">>outputs_: {}\n".format(o_.shape), o_)
    print(">>last_states:")
    print("  >>c_state:\n", s_.c)
    print("  >>h_state:\n", s_.h)
    
    print("不指定时内部会自动填充，对结果有一定影响")

tf.reset_default_graph()
np.random.seed(10)
# batch_size:2  timesteps:4 inputs:5
# 在NLP任务可以理解为：2段语料，每个语料4个词（索引），每个词5维向量
X = np.random.randn(2,4,5).astype(np.float32)
X[1, 2:] = 0  # 指定索引位置的元素全置为0
print(">>X:{}\n".format(X.shape),X)
X_lengths = [4, 2]  # 手动指定各batch里有效数据（非0数据）的步长

def make_cell(hidden_size:int, is_training:bool=True, keep_prob:float=0.8):
    cell = tf.contrib.rnn.LSTMBlockCell(hidden_size, forget_bias=0.0)
    if is_training and keep_prob < 1:
        cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)
    return cell
layer_num = 2
hidden_size = 3
mlstm_cell = tf.contrib.rnn.MultiRNNCell([make_cell(hidden_size) for _ in range(layer_num)], state_is_tuple=True)
init_state = mlstm_cell.zero_state(X.shape[0], dtype=tf.float32)

outputs, last_states = tf.nn.dynamic_rnn(cell=mlstm_cell, 
                                         inputs=X, 
                                         initial_state=init_state,
                                         sequence_length=X_lengths)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    i = sess.run(init_state)
    for j in range(layer_num):
        print(">>layer_{} init_state:".format(j))
        print("  >>c_state:\n", i[j].c)
        print("  >>h_state:\n", i[j].h)
    print("\n"," "*2,"*****指定sequence_length参数时的结果*****")
    o,s = sess.run([outputs,last_states])
    print(">>outputs: {}\n".format(o.shape), o)
    print(">>last_state: \n")
    s
    for j in range(layer_num):
        print(">>layer_{} last_state:".format(j))
        print("  >>c_state:\n", s[j].c)
        print("  >>h_state:\n", s[j].h)
    print("最后一层LSTMCell-layer的最后的h_state:\n", s[-1][1])
    print("outputs取结果:\n", o[:,-1,:])
    print("******【多层LSTM为什么outputs和last_states的结果不一致？】*****")
    

num_inp = 10  # 输入的两个加和数有10种取值
num_class = 2*(num_inp-1)  # 和的结果有19种
def get_one_sample():
    a = np.random.randint(num_inp)
    b = np.random.randint(num_inp)
    c = a + b
    return np.array([a,b,c])

data_ = np.array([get_one_sample() for _ in range(50*10000)])#.astype(np.float32)

data_verify = data_[[row[0] in [2,5,9] for row in data_]]  # 保留2+n,5+n,9+n的样本作为verify
data_train = data_[[row[0] not in [2,5,9] for row in data_]]  # 训练数据只用非2+n、5+n、9+n的数据
dataX = data_train[:,:2]
dataY = data_train[:,-1]

print(">>> data 前三个示例: {}\n".format(data.shape),data[:3])
print(">>> dataX 前三个示例: {}\n".format(dataX.shape),dataX[:3])
print(">>> dataY 前三个示例: {}\n".format(dataY.shape),dataY[:3])
print(">>> dataY 目前有{}种取值, 理论上应有{}种取值".format(np.unique(dataY.flatten()).shape[0], num_class))

tf.reset_default_graph()
# batch_size在全零初始化时用到了，所以必须指定（不能由shape的None自动推理得到）
# 为了保证灵活性，用placeholder传进来
inpBS = tf.placeholder(tf.int32, [], name="batch_size")
inpX = tf.placeholder(tf.int32, shape=(None, 2), name="inpX")
inpY = tf.placeholder(tf.int32, shape=(None), name="inpY")
default_feed_dict = {inpBS:200,inpX:dataX[:200], inpY:dataY[:200]}
X = tf.one_hot(inpX,depth=num_inp)
Y = tf.one_hot(inpY,depth=num_class)
lstm_size = 10
lstm_cell = tf.contrib.rnn.BasicLSTMCell(num_units=lstm_size)
init_state = lstm_cell.zero_state(inpBS, dtype=tf.float32)  # 按batch_size全0初始化state(c_state和h_state)
outputs_, last_states_ = tf.nn.dynamic_rnn(cell=lstm_cell, 
                                         inputs=X, 
                                         initial_state=init_state)

# 输出示例验证下
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    x,y = sess.run([X,Y], feed_dict=default_feed_dict)
    print(">>> tf.one_hot(X)的效果:{}\n".format(x.shape),x[:4])
    print(">>> tf.one_hot(Y)的效果:{}\n".format(y.shape),y[:4])
    i = sess.run(init_state, feed_dict=default_feed_dict)
    print(">>init_state:\n")
    print("  >>c_state:\n", i.c.shape)
    print("  >>h_state:\n", i.h.shape)
    o_,s_ = sess.run([outputs_,last_states_], feed_dict=default_feed_dict)
    print(">>outputs_: {}\n".format(o_.shape), o_[:3])
    print(">>last_states:")
    print("  >>c_state: {}\n".format(s_.c.shape),s_.c[:3])
    print("  >>h_state: {}\n".format(s_.h.shape),s_.h[:3])
    print("本次(全零初始化)LSTM计算结果即上述 h_state")

# 取出LSTM的最后一个 h_state 做softmax将LSTM维度(lstm_size)的输出归一化到最终分类数(num_class)维度
softmax_w = tf.Variable(tf.truncated_normal([lstm_size, num_class], stddev=0.1))
softmax_b = tf.Variable(tf.zeros(num_class))
logits = tf.matmul(last_states_.h, softmax_w) + softmax_b  # 这里单独拿一下logits目的是为了后面使用tf的API计算CE
pred = tf.nn.softmax(logits, name='predictions')
print(">>> 构造softmax: [inp.shape]:{}, [w.shape]:{}, [b.shape]:{}".format(last_states_.h.shape, softmax_w.shape,softmax_b.shape))
print(">>> softmax logits结果:{}, softmax最后结果: {}".format(logits.shape,pred.shape))

# 计算CE
loss_ = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels=Y)
loss = tf.reduce_mean(loss_)  # 一个标量数
print(">>> 各样本loss_: {}, reduce_mean后的loss: {} loss_type: {}".format(loss_.shape, loss.shape, type(loss)))

# 优化loss
grad_clip=5  # 梯度裁剪避免爆炸
tvars = tf.trainable_variables()
grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), grad_clip)
train_op = tf.train.AdamOptimizer(0.01)
optimizer = train_op.apply_gradients(zip(grads, tvars))

saver = tf.train.Saver(max_to_keep=4)
batch_size = 400
epochs = 2
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    global_cnt = 0
    for e in range(epochs):
        dataX_iter = iter(dataX)
        dataY_iter = iter(dataY)
        cnt=0
        while True:
            X_batch = np.array(list(itertools.islice(dataX_iter, batch_size)))
            Y_batch = np.array(list(itertools.islice(dataY_iter, batch_size)))
            if len(X_batch)>0 and len(Y_batch)>0:
                feed = {inpBS:X_batch.shape[0], inpX:X_batch, inpY:Y_batch}
                b_loss,b_state,_ = sess.run([loss,last_states_,optimizer], feed_dict = feed)
                if cnt % 100 == 0:
                    zprint("[e-b]: {:0>2}-{:0>4} [loss]: {}".format(e,cnt,b_loss))
                    _ = saver.save(sess, "./tmp/lstmModel/predict_add.ckpt", global_step=global_cnt)
                cnt += 1
                global_cnt += 1
            else:
                break
    _ = saver.save(sess, "./tmp/lstmModel/predict_add.ckpt", global_step=global_cnt)
    X_infer = np.array([[j, i] for j in [2,5,9] for i in range(num_inp)])
    pred_res, Y_inferred = sess.run([pred, tf.argmax(pred,1)],feed_dict={inpBS:X_infer.shape[0],inpX:X_infer})
#     print(">>> 加法测试数据X_infer: {}\n".format(X_infer.shape), X_infer)
#     print(">>> LSTM预测加法结果 argmax(softmax): {}\n".format(Y_inferred.shape), Y_inferred)
    print(">>> 加法测试结果的直观展示:\n",np.array(list(zip(X_infer,Y_inferred))))
    print(
        """这里注意到，9+9是样本中完全没有出现过的（其他如5+4虽没出现过但是4+5是出现过的）
        实验发现增加样本量&降低学习率能够让9+9更接近真实值。
        10w样本&lr=0.1  ==> 9+9=8
        50w样本&lr=0.01 ==> 9+9=17
        """)
    print("\n其他非重要信息:")
    print(">>> 预测结果 softmax的top5: {}\n".format(pred_res.shape), pred_res[:5])

# **步骤6：方法一，调用 dynamic_rnn() 来让我们构建好的网络运行起来
# ** 当 time_major==False 时， outputs.shape = [batch_size, timestep_size, hidden_size] 
# ** 所以，可以取 h_state = outputs[:, -1, :] 作为最后输出
# ** state.shape = [layer_num, 2, batch_size, hidden_size], 
# ** 或者，可以取 h_state = state[-1][1] 作为最后输出
# ** 最后输出维度是 [batch_size, hidden_size]
# outputs, state = tf.nn.dynamic_rnn(mlstm_cell, inputs=X, initial_state=init_state, time_major=False)
# h_state = outputs[:, -1, :]  # 或者 h_state = state[-1][1]

# *************** 为了更好的理解 LSTM 工作原理，我们把上面 步骤6 中的函数自己来实现 ***************
# 通过查看文档你会发现， RNNCell 都提供了一个 __call__()函数（见最后附），我们可以用它来展开实现LSTM按时间步迭代。
# **步骤6：方法二，按时间步展开计算
outputs = list()
state = init_state
with tf.variable_scope('RNN'):
    for timestep in range(timestep_size):
        if timestep > 0:
            tf.get_variable_scope().reuse_variables()
        # 这里的state保存了每一层 LSTM 的状态
        (cell_output, state) = mlstm_cell(X[:, timestep, :], state)
        outputs.append(cell_output)
h_state = outputs[-1]
tf.summary.histogram("h_state",h_state)

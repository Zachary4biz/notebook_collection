{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T04:44:34.829336Z",
     "start_time": "2019-06-06T04:44:34.822401Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook\n",
    "import concurrent.futures\n",
    "from multiprocessing import Pool\n",
    "import copy,os,sys,psutil\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T05:52:48.340057Z",
     "start_time": "2019-06-06T05:52:48.336439Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-05T08:57:07.168946Z",
     "start_time": "2019-06-05T08:51:07.102Z"
    }
   },
   "source": [
    "# PyTorch AllenNLP\n",
    "AllenNLP 的 pyTorch 版本需要配置文件，暂时没有搞清楚配置文件怎么写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-05T08:41:26.371928Z",
     "start_time": "2019-06-05T08:41:24.917577Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "from allennlp.modules.elmo import Elmo, batch_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-05T08:50:23.191319Z",
     "start_time": "2019-06-05T08:50:22.965626Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "file options.json not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fa8fb145921f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 这里的1表示产生一组线性加权的词向量。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 如果改成2 即产生两组不同的线性加权的词向量。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0melmo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElmo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# use batch_to_ids to convert sentences to character ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msentence_lists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"I have a dog\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"How are you , today is Monday\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"I am fine thanks\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3/lib/python3.6/site-packages/allennlp/modules/elmo.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, options_file, weight_file, num_output_representations, requires_grad, do_layer_norm, dropout, vocab_to_cache, keep_sentence_boundaries, scalar_mix_parameters, module)\u001b[0m\n\u001b[1;32m    108\u001b[0m                                         \u001b[0mweight_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                                         \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                                         vocab_to_cache=vocab_to_cache)\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_cached_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab_to_cache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keep_sentence_boundaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeep_sentence_boundaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3/lib/python3.6/site-packages/allennlp/modules/elmo.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, options_file, weight_file, requires_grad, vocab_to_cache)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ElmoBiLm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_token_embedder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ElmoCharacterEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_requires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3/lib/python3.6/site-packages/allennlp/modules/elmo.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, options_file, weight_file, requires_grad)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ElmoCharacterEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weight_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3/lib/python3.6/site-packages/allennlp/common/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;31m# File, but it doesn't exist.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file {} not found\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# Something unknown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: file options.json not found"
     ]
    }
   ],
   "source": [
    "options_file = \"options.json\"  # 配置文件地址 \n",
    "weight_file = \"weights.hdf5\" # 权重文件地址\n",
    "# 这里的1表示产生一组线性加权的词向量。\n",
    "# 如果改成2 即产生两组不同的线性加权的词向量。\n",
    "elmo = Elmo(options_file, weight_file, 1, dropout=0)\n",
    "# use batch_to_ids to convert sentences to character ids\n",
    "sentence_lists = [\"I have a dog\", \"How are you , today is Monday\",\"I am fine thanks\"]\n",
    "character_ids = batch_to_ids(sentences_lists)\n",
    "embeddings = elmo(character_ids)['elmo_representations']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow_hub AllenNLP\n",
    "- [Introduction to TensorflowHub: Simple Text Embedding(Using ELMo)](https://medium.com/@joeyism/embedding-with-tensorflow-hub-in-a-simple-way-using-elmo-d1bfe0ada45c)\n",
    "- [Tensorflow+Keras做ELMo（中文翻译）](https://ai.yanxishe.com/page/TextTranslation/1597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-05T08:57:46.711640Z",
     "start_time": "2019-06-05T08:57:46.707699Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考自[TensorflowHub的官网](https://tfhub.dev/google/elmo/2)\n",
    "\n",
    "### 输入\n",
    "#### 参数\n",
    "- `signature`\n",
    "    - default | 默认是分句子输入，batch_size等于句子的个数\n",
    "        > the module takes untokenized sentences as input. The input tensor is a string tensor with shape [batch_size]. The module tokenizes each string by splitting on spaces.\n",
    "    - tokens  | 使用分过词的句子作为输入\n",
    "        > With the tokens signature, the module takes tokenized sentences as input. The input tensor is a string tensor with shape [batch_size, max_length] and an int32 tensor with shape [batch_size] corresponding to the sentence length. The length input is necessary to exclude padding in the case of sentences with varying length.\n",
    "    - 上述两种方式的结果是完全一致的\n",
    "- `as_dict`\n",
    "    - 不提供参数 `as_dict`时（默认为 `False`），会使用`default`。即 `elmo(tokens, as_dict=True)['default']` = `elmo(tokens)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T06:04:42.171431Z",
     "start_time": "2019-06-06T06:04:39.388181Z"
    },
    "code_folding": [
     5,
     12
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0606 14:04:40.684383 140165026932544 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0606 14:04:41.996367 140165026932544 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# 使用 signature = default， 输入是句子\n",
    "sentences = [\"the cat is on the mat\", \"dogs are in the fog\"]\n",
    "emb_opt_sentence = elmo(inputs=sentences, as_dict=True)\n",
    "\n",
    "# 使用 signature = tokens, 输入是字典，包含 tokens 和 sequence_len 注意需要padding\n",
    "def padding(tokens_inp):\n",
    "    pad_len = max([len(i) for i in tokens_inp])\n",
    "    return [(i+[\"\"]*pad_len)[:pad_len] for i in tokens_inp]\n",
    "\n",
    "tokens_list = [\"the cat is on the mat\".split(\" \"),\"dogs are in the fog\".split(\" \")]\n",
    "tokens_list = padding(tokens_list)\n",
    "tokens_len = [len(i) for i in tokens_list]\n",
    "input_dict = {\n",
    "    'tokens': tokens_list,\n",
    "    'sequence_len' : tokens_len\n",
    "}\n",
    "emb_opt_tokens = elmo(inputs=input_dict, signature='tokens', as_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出\n",
    "> The output dictionary contains:\n",
    ">- <u>word_emb</u>: \n",
    ">    - the character-based word representations \n",
    ">    - `elmo(tokens, as_dict=True)['word_emb']`\n",
    ">    - *[batch_size, max_length, 512]*\n",
    ">- <u>lstm_outputs1</u>: \n",
    ">    - the first LSTM hidden state \n",
    ">    - `elmo(tokens, as_dict=True)['lstm_outputs1']`\n",
    ">    - *[batch_size, max_length, 1024].*\n",
    ">- <u>lstm_outputs2</u>: t\n",
    ">    - he second LSTM hidden state \n",
    ">    - `elmo(tokens, as_dict=True)['lstm_outputs2']`\n",
    ">    - *[batch_size, max_length, 1024].*\n",
    ">- <u>elmo</u>: \n",
    ">    - the weighted sum of the 3 layers, where the weights are trainable. \n",
    ">    - `elmo(tokens, as_dict=True)['elmo']`\n",
    ">    - *[batch_size, max_length, 1024]*\n",
    ">- <u>default</u>: \n",
    ">    - a fixed mean-pooling of all contextualized word representations \n",
    ">    - `elmo(tokens, as_dict=True)['default']`\n",
    ">    - *[batch_size, 1024].*\n",
    "\n",
    "当输入采用不同方式tokens/sentences时，只有word_emb能确保五种输出结果是一致的；\n",
    "\n",
    "不一致的原因实际上是因为句子分词后长度不同，需要用空串padding；\n",
    "\n",
    "如果句子分词后长度都一直，则五种输出结果都一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T06:05:17.684652Z",
     "start_time": "2019-06-06T06:04:47.436068Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature不同的输入方式(tokens,sentences)，'word_emb' 结果是一致的:  True\n",
      "signature不同的输入方式(tokens,sentences)，'lstm_outputs1' 结果是一致的:  False\n",
      "signature不同的输入方式(tokens,sentences)，'lstm_outputs2' 结果是一致的:  False\n",
      "signature不同的输入方式(tokens,sentences)，'elmo' 结果是一致的:  False\n",
      "signature不同的输入方式(tokens,sentences)，'default' 结果是一致的:  False\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    for output in ['word_emb','lstm_outputs1','lstm_outputs2','elmo','default']:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        emb = sess.run(emb_opt_sentence[output])\n",
    "        emb2 = sess.run(emb_opt_tokens[output])\n",
    "        print(f\"signature不同的输入方式(tokens,sentences)，'{output}' 结果是一致的: \",np.all(emb == emb2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T06:59:02.482889Z",
     "start_time": "2019-06-06T06:58:55.876206Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 计算好emb\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    emb_tokens = sess.run(emb_opt_tokens['elmo'])\n",
    "    emb_sentence = sess.run(emb_opt_sentence['elmo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T02:16:50.454136Z",
     "start_time": "2019-06-10T02:16:50.438742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences:  ['the cat is on the mat', 'dogs are in the fog']\n",
      "\n",
      ">>> 使用tokens_list:  ['the', 'cat', 'is', 'on', 'the', 'mat']\n",
      "两种输入方式下 elmo 的一致性： True\n",
      "\n",
      ">>> 使用tokens_list:  ['dogs', 'are', 'in', 'the', 'fog', '']\n",
      "两种输入方式下 elmo 的一致性： False\n",
      "不一致时，tokens和sentence两种方式的tensor值示例：\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5.4578573e-02, -2.6427570e-01,  4.6843779e-01, ...,\n",
       "        -1.2844735e-01, -1.8192245e-01,  4.2113167e-01],\n",
       "       [ 8.0942936e-02,  1.1583884e-01, -1.5670620e-01, ...,\n",
       "        -1.5915328e-01,  3.8296425e-01, -7.7638179e-02],\n",
       "       [-7.8964919e-02,  9.4927496e-01, -6.1804903e-01, ...,\n",
       "        -3.9802760e-01,  2.7152354e-01,  1.0895334e-01],\n",
       "       [-6.7809001e-02,  9.7187646e-02, -3.6225441e-01, ...,\n",
       "         1.4475808e-01,  1.7962448e-01, -1.2800075e-02],\n",
       "       [-2.6190025e-04, -1.2609786e-01, -5.3394711e-01, ...,\n",
       "         4.9814320e-01,  6.2343001e-01,  5.1778430e-01],\n",
       "       [ 2.8496963e-01, -7.0748515e-02, -2.2847629e-01, ...,\n",
       "         1.2616637e-01, -2.6158541e-02,  3.9751023e-01]], dtype=float32)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5.4578573e-02, -2.6427570e-01,  4.6843779e-01, ...,\n",
       "        -1.4077103e-01, -2.6568228e-01,  4.5211977e-01],\n",
       "       [ 8.0942936e-02,  1.1583884e-01, -1.5670620e-01, ...,\n",
       "        -2.6896167e-01,  3.3871961e-01,  1.1577174e-02],\n",
       "       [-7.8964919e-02,  9.4927496e-01, -6.1804903e-01, ...,\n",
       "        -6.3055909e-01,  3.0943012e-01,  1.5378729e-01],\n",
       "       [-6.7809001e-02,  9.7187646e-02, -3.6225441e-01, ...,\n",
       "         7.7499896e-02, -6.1661024e-02,  6.0047179e-02],\n",
       "       [-2.6190025e-04, -1.2609786e-01, -5.3394711e-01, ...,\n",
       "         4.2921820e-01,  1.2804650e-01,  5.3191912e-01],\n",
       "       [-2.8408393e-02, -4.3532155e-02,  4.1301616e-02, ...,\n",
       "         2.5831670e-02, -1.4298330e-02, -1.6504213e-02]], dtype=float32)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"sentences: \", sentences)\n",
    "for sen_idx in [0,1]:\n",
    "    print(\"\\n>>> 使用tokens_list: \", tokens_list[sen_idx])\n",
    "    consistent = np.all(emb_tokens[sen_idx] == emb_sentence[sen_idx])\n",
    "    print(\"两种输入方式下 elmo 的一致性：\",consistent)\n",
    "    if not consistent:\n",
    "        print(\"不一致时，tokens和sentence两种方式的tensor值示例：\")\n",
    "        emb_tokens[sen_idx]\n",
    "        emb_sentence[sen_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "291px",
    "left": "1299px",
    "right": "20px",
    "top": "10px",
    "width": "319px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

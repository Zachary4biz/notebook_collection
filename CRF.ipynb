{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T10:07:48.638994Z",
     "start_time": "2020-03-03T10:07:48.379268Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook\n",
    "import concurrent.futures\n",
    "from multiprocessing import Pool\n",
    "import copy,os,sys,psutil\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T08:41:38.068425Z",
     "start_time": "2019-07-24T08:41:37.820456Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模拟数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T08:41:38.490465Z",
     "start_time": "2019-07-24T08:41:38.484344Z"
    }
   },
   "outputs": [],
   "source": [
    "# ########### log_likelihood ##############\n",
    "# 表示不同骰子投掷出不同点数的概率的log\n",
    "#  - 第一列是无偏骰子，第二列是有偏骰子\n",
    "# array([[-1.79175947, -3.21887582],\n",
    "#        [-1.79175947, -3.21887582],\n",
    "#        [-1.79175947, -3.21887582],\n",
    "#        [-1.79175947, -3.21887582],\n",
    "#        [-1.79175947, -3.21887582],\n",
    "#        [-1.79175947, -0.22314355]])\n",
    "# #########################################\n",
    "probabilities = {\n",
    "    'fair': np.array([1 / 6] * 6),  # 无偏骰子，6个点数都是一样的概率\n",
    "    'loaded': np.array([0.04, 0.04, 0.04, 0.04, 0.04, 0.8]),  # 有偏骰子\n",
    "}\n",
    "log_likelihood = np.hstack([np.log(probabilities['fair']).reshape(-1, 1),\n",
    "                            np.log(probabilities['loaded']).reshape(-1, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T08:41:38.827291Z",
     "start_time": "2019-07-24T08:41:38.821644Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# ########## 预设转移概率矩阵 #########################\n",
    "# 后面会根据这个矩阵构造样本，CRF可以认为是在\"拟合这个矩阵\"\n",
    "# 如0.6表示当前是fair时下次还是fair的概率\n",
    "# 即：P(Y_{i}=Fair|Y_{i-1}=Fair)=0.6\n",
    "#          2fair   2loaded    2start\n",
    "# fair      0.6      0.4        0.0\n",
    "# loaded    0.3      0.7        0.0\n",
    "# start     0.5      0.5        0.0\n",
    "# ###################################################\n",
    "transition_mat = {'fair': np.array([0.6, 0.4, 0.0]),\n",
    "                  'loaded': np.array([0.3, 0.7, 0.0]),\n",
    "                  'start': np.array([0.5, 0.5, 0.0])}\n",
    "states = list(transition_mat.keys())\n",
    "state2ix = {'fair': 0,\n",
    "            'loaded': 1,\n",
    "            'start': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T08:41:39.545150Z",
     "start_time": "2019-07-24T08:41:39.496298Z"
    },
    "code_folding": [
     7,
     22
    ]
   },
   "outputs": [],
   "source": [
    "# ########################## 生成样本 ###################################\n",
    "# 初始化为全零矩阵，然后填充，模拟出：sample_size 个序列 x 投掷 n_obs 次/序列\n",
    "# rolls：5000个序列 x 每个序列投掷15次 x 每次是六选一[0,5]\n",
    "#        六选一的概率由log_likelihood判断\n",
    "# dices：5000个序列 x 每个序列投掷15次 x 每次是二选一{有偏、无偏}\n",
    "#        依赖状态转移概率矩阵\n",
    "# #####################################################################\n",
    "def simulate_data(n_timesteps):\n",
    "    data_list = np.zeros(n_timesteps)\n",
    "    prev_state = 'start'\n",
    "    state_list = np.zeros(n_timesteps)\n",
    "    for n in range(n_timesteps):\n",
    "        next_state = np.random.choice(states, p=transition_mat[prev_state])\n",
    "        prev_state = next_state\n",
    "        data_list[n] = np.random.choice([0, 1, 2, 3, 4, 5], p=probabilities[next_state])\n",
    "        state_list[n] = state2ix[next_state]\n",
    "    return data_list, state_list\n",
    "\n",
    "sample_size = 10#5000  # 样本个数（或者说训练次数）\n",
    "n_obs = 15  # 投掷次数\n",
    "rolls_list = np.zeros((sample_size, n_obs)).astype(int) # 点数\n",
    "status_list = np.zeros((sample_size, n_obs)).astype(int) # 骰子 {有偏、无偏}\n",
    "for i in range(sample_size):\n",
    "    rolls, dices = simulate_data(n_obs)\n",
    "    rolls_list[i] = rolls.reshape(1, -1).astype(int)\n",
    "    status_list[i] = dices.reshape(1, -1).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T13:17:23.288062Z",
     "start_time": "2019-07-24T13:17:23.282800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 15)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10, 15)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolls_list.shape\n",
    "status_list.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRF_module模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def crf_train_loop(model, rolls, targets, n_epochs, learning_rate=0.01):\n",
    "    '''\n",
    "    doc\n",
    "    :param model: CRF\n",
    "    :param rolls: 序列样本 | 骰子掷出的点数 5000x15， 或者句子里的词\n",
    "    :param targets:  序列样本的标注 | 骰子的状态{有偏、无偏} 5000x15，或者词的BIOE标注\n",
    "    :param n_epochs: 迭代轮数\n",
    "    :param learning_rate:  学习率\n",
    "    '''\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate,\n",
    "                     weight_decay=1e-4)\n",
    "    for epoch in range(n_epochs):\n",
    "        batch_loss = []\n",
    "        N = rolls.shape[0]\n",
    "        model.zero_grad()\n",
    "        for index, (roll, labels) in enumerate(zip(rolls, targets)):\n",
    "            # Forward Pass\n",
    "            neg_log_likelihood = model.neg_log_likelihood(roll, labels)\n",
    "            batch_loss.append(neg_log_likelihood)\n",
    "\n",
    "            if index % 50 == 0: # batch_size=50\n",
    "                ll = torch.cat(batch_loss).mean()\n",
    "                ll.backward()\n",
    "                optimizer.step()\n",
    "                print(\"Epoch {}: Batch {}/{} loss is {:.4f}\".format(epoch, index // 50, N // 50, ll.data.numpy()[0]))\n",
    "                batch_loss = []\n",
    "    return model\n",
    "\n",
    "class CRF(torch.nn.Module):\n",
    "    def __init__(self, n_dice, log_likelihood):\n",
    "        super().__init__()\n",
    "        self.n_states = n_dice\n",
    "        self.loglikelihood = log_likelihood\n",
    "        self.transition = torch.nn.init.normal(torch.nn.Parameter(torch.randn(n_dice, n_dice+1)), -1, 0.1)\n",
    "        \n",
    "    def to_scalar(self,var):\n",
    "        return var.view(-1).data.tolist()[0]\n",
    "    \n",
    "    def argmax(self,vec):\n",
    "        _, idx = torch.max(vec,1)\n",
    "        return self.to_scalar(idx)\n",
    "    \n",
    "    def log_sum_exp(self,vec):\n",
    "        max_score = vec[0, self.argmax(vec)]\n",
    "        max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "        return max_score + torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
    "    \n",
    "     def _data_to_likelihood(self, rolls):\n",
    "        return Variable(torch.FloatTensor(self.loglikelihood[rolls]), requires_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRF训练及持久化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "##\n",
    "crf = CRF(2, log_likelihood)\n",
    "model = crf_train_loop(crf, rolls, dices, 1, 0.001)\n",
    "torch.save(model.state_dict(), \"./checkpoint.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRF加载及使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "##\n",
    "model.load_state_dict(torch.load(\"./checkpoint.hdf5\"))\n",
    "roll_list, dice_list = simulate_data(15)\n",
    "test_rolls = roll_list.reshape(1, -1).astype(int)\n",
    "test_targets = dice_list.reshape(1, -1).astype(int)\n",
    "print(test_rolls[0])\n",
    "print(model.forward(test_rolls[0])[0])\n",
    "print(test_targets[0])\n",
    "print(list(model.parameters())[0].data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T04:04:25.604488Z",
     "start_time": "2019-07-19T04:04:25.600029Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 2)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_likelihood.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 说明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T08:47:54.057799Z",
     "start_time": "2019-07-24T08:47:54.037067Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.79175947, -3.21887582],\n",
       "       [-1.79175947, -3.21887582],\n",
       "       [-1.79175947, -3.21887582],\n",
       "       [-1.79175947, -3.21887582],\n",
       "       [-1.79175947, -3.21887582],\n",
       "       [-1.79175947, -0.22314355]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 5, 4, 2, 4, 3, 3, 3, 0, 5, 4, 5, 5, 5, 2],\n",
       "       [5, 5, 5, 5, 1, 0, 2, 3, 1, 4, 3, 5, 4, 0, 3],\n",
       "       [2, 4, 5, 5, 1, 3, 0, 4, 4, 5, 3, 3, 3, 2, 1],\n",
       "       [5, 5, 0, 0, 3, 0, 5, 5, 3, 5, 5, 5, 5, 5, 3],\n",
       "       [5, 5, 5, 5, 4, 5, 4, 5, 5, 5, 2, 1, 5, 5, 5],\n",
       "       [3, 3, 4, 5, 4, 0, 4, 3, 2, 4, 5, 4, 1, 2, 5],\n",
       "       [0, 3, 5, 5, 1, 5, 5, 1, 5, 5, 0, 5, 2, 0, 0],\n",
       "       [5, 2, 3, 0, 0, 5, 5, 1, 5, 5, 0, 5, 5, 1, 5],\n",
       "       [5, 5, 0, 5, 5, 0, 5, 5, 1, 1, 5, 1, 5, 5, 5],\n",
       "       [0, 2, 4, 3, 0, 3, 0, 3, 5, 2, 5, 4, 2, 5, 5]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0],\n",
       "       [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0],\n",
       "       [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhoutong/python3/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.9396, -0.9503, -1.0542],\n",
       "        [-1.0771, -0.9073, -1.0247]], requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7918, -3.2189],\n",
       "        [-1.7918, -0.2231],\n",
       "        [-1.7918, -3.2189],\n",
       "        [-1.7918, -3.2189],\n",
       "        [-1.7918, -3.2189],\n",
       "        [-1.7918, -3.2189],\n",
       "        [-1.7918, -3.2189],\n",
       "        [-1.7918, -3.2189],\n",
       "        [-1.7918, -3.2189],\n",
       "        [-1.7918, -0.2231],\n",
       "        [-1.7918, -3.2189],\n",
       "        [-1.7918, -0.2231],\n",
       "        [-1.7918, -0.2231],\n",
       "        [-1.7918, -0.2231],\n",
       "        [-1.7918, -3.2189]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_likelihood\n",
    "rolls_list\n",
    "status_list\n",
    "n_dice = 2\n",
    "n_states = n_dice\n",
    "transition = torch.nn.init.normal(nn.Parameter(torch.randn(n_dice, n_dice + 1)), -1, 0.1)\n",
    "transition\n",
    "loglikelihoods = torch.FloatTensor(log_likelihood[rolls_list[0]])\n",
    "loglikelihoods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## neg_log_likelihood(self, rolls, states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T07:34:44.769910Z",
     "start_time": "2019-07-24T07:34:44.740738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 5, 0, 1, 5, 5, 3, 4, 5, 5, 5, 2, 1, 5])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(15, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([15])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, (rolls, states) in enumerate(zip(rolls_list, status_list)):\n",
    "    if index==0:\n",
    "        rolls\n",
    "        states\n",
    "        loglikelihoods = log_likelihood[rolls]\n",
    "        states_ = torch.LongTensor(states)\n",
    "        loglikelihoods.shape\n",
    "        states_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\_compute\\_likelihood_numerator(self,loglikelihoods,states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T08:31:11.285574Z",
     "start_time": "2019-07-24T08:31:11.265598Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.1362, -1.0021, -1.0091],\n",
       "        [-0.9801, -0.9396, -0.8924]], requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- at 0:\n",
      "state:1 prev_state:2 index:0 state:1 \n",
      "transition[..]+loglikelihoods[..]=-0.8923904895782471+-0.2231435513142097=-1.1155340671539307\n",
      "---- at 1:\n",
      "state:0 prev_state:1 index:1 state:0 \n",
      "transition[..]+loglikelihoods[..]=-1.00210702419281+-1.791759469228055=-2.7938666343688965\n",
      "---- at 2:\n",
      "state:0 prev_state:0 index:2 state:0 \n",
      "transition[..]+loglikelihoods[..]=-1.1362054347991943+-1.791759469228055=-2.927964925765991\n",
      "---- at 3:\n",
      "state:0 prev_state:0 index:3 state:0 \n",
      "transition[..]+loglikelihoods[..]=-1.1362054347991943+-1.791759469228055=-2.927964925765991\n",
      "---- at 4:\n",
      "state:0 prev_state:0 index:4 state:0 \n",
      "transition[..]+loglikelihoods[..]=-1.1362054347991943+-1.791759469228055=-2.927964925765991\n",
      "---- at 5:\n",
      "state:1 prev_state:0 index:5 state:1 \n",
      "transition[..]+loglikelihoods[..]=-0.9800864458084106+-0.2231435513142097=-1.2032300233840942\n",
      "---- at 6:\n",
      "state:1 prev_state:1 index:6 state:1 \n",
      "transition[..]+loglikelihoods[..]=-0.939555823802948+-0.2231435513142097=-1.1626993417739868\n",
      "---- at 7:\n",
      "state:0 prev_state:1 index:7 state:0 \n",
      "transition[..]+loglikelihoods[..]=-1.00210702419281+-1.791759469228055=-2.7938666343688965\n",
      "---- at 8:\n",
      "state:0 prev_state:0 index:8 state:0 \n",
      "transition[..]+loglikelihoods[..]=-1.1362054347991943+-1.791759469228055=-2.927964925765991\n",
      "---- at 9:\n",
      "state:1 prev_state:0 index:9 state:1 \n",
      "transition[..]+loglikelihoods[..]=-0.9800864458084106+-0.2231435513142097=-1.2032300233840942\n",
      "---- at 10:\n",
      "state:1 prev_state:1 index:10 state:1 \n",
      "transition[..]+loglikelihoods[..]=-0.939555823802948+-0.2231435513142097=-1.1626993417739868\n",
      "---- at 11:\n",
      "state:1 prev_state:1 index:11 state:1 \n",
      "transition[..]+loglikelihoods[..]=-0.939555823802948+-0.2231435513142097=-1.1626993417739868\n",
      "---- at 12:\n",
      "state:0 prev_state:1 index:12 state:0 \n",
      "transition[..]+loglikelihoods[..]=-1.00210702419281+-1.791759469228055=-2.7938666343688965\n",
      "---- at 13:\n",
      "state:1 prev_state:0 index:13 state:1 \n",
      "transition[..]+loglikelihoods[..]=-0.9800864458084106+-3.2188758248682006=-4.198962211608887\n",
      "---- at 14:\n",
      "state:0 prev_state:1 index:14 state:0 \n",
      "transition[..]+loglikelihoods[..]=-1.00210702419281+-1.791759469228055=-2.7938666343688965\n"
     ]
    }
   ],
   "source": [
    "prev_state = 2\n",
    "score = Variable(torch.Tensor([0]))\n",
    "states_\n",
    "transition\n",
    "for index, state in enumerate(states_):\n",
    "    print(\"---- at {}:\".format(index))\n",
    "    if index >= 0:\n",
    "        print(\"state:{} prev_state:{} index:{} state:{} \".format(state, prev_state, index, state))\n",
    "        print(\"transition[..]+loglikelihoods[..]={}+{}={}\".format(transition[state, prev_state],loglikelihoods[index, state],transition[state, prev_state] + loglikelihoods[index, state]))\n",
    "        score += transition[state, prev_state] + loglikelihoods[index, state]\n",
    "        prev_state = state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\_compute\\_likelihood_denominator(self,loglikelihoods)\n",
    "$$alpha_t(j) = \\sum_i alpha_{t-1}(i) * L(x_t | y_t) * C(y_t | y_{t-1} = i)$$\n",
    "\n",
    "这个描述的是在状态$y_t$下如何遍历地取所有可能的转移过来的概率\n",
    "\n",
    "所以这里三个乘法的前两项对当前状态来说是不变的，遍历$i$是更改的$C(..)$即转移概率\n",
    "\n",
    "$alpha_{t-1}(i)$： 之前累乘（log下其实就是累加了）到当前的概率\n",
    "\n",
    "$L(x_t | y_t)$：投掷到这个点数的概率\n",
    "\n",
    "$C(y_t | y_{t-1} = i)$： 从状态$i$转移到当前状态$y_t$的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T12:27:47.035975Z",
     "start_time": "2019-07-24T12:27:47.030362Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_idx_of_dim1_max(vec):\n",
    "    # torch.max 根据维度返回（该维度下最大值组成的tensor，索引）； |\n",
    "    _, idx = torch.max(vec, dim=1)\n",
    "    return idx.view(-1).data.tolist()[0]\n",
    "\n",
    "def log_sum_exp(vec):\n",
    "    a = vec[0, get_idx_of_dim1_max(vec)] # vec的 0行，max列（最大元素所在索引）\n",
    "    a_broadcast = a.view(1, -1).expand(1, vec.size()[1])\n",
    "    return a + torch.log(torch.sum(torch.exp(vec - a_broadcast)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T12:25:46.206739Z",
     "start_time": "2019-07-24T12:25:46.190874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.9396, -0.9503, -1.0542],\n",
       "        [-1.0771, -0.9073, -1.0247]], requires_grad=True)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7918, -3.2189],\n",
       "        [-1.7918, -0.2231],\n",
       "        [-1.7918, -3.2189],\n",
       "        [-1.7918, -3.2189],\n",
       "        [-1.7918, -3.2189],\n",
       "        [-1.7918, -3.2189],\n",
       "        [-1.7918, -3.2189],\n",
       "        [-1.7918, -3.2189],\n",
       "        [-1.7918, -3.2189],\n",
       "        [-1.7918, -0.2231],\n",
       "        [-1.7918, -3.2189],\n",
       "        [-1.7918, -0.2231],\n",
       "        [-1.7918, -0.2231],\n",
       "        [-1.7918, -0.2231],\n",
       "        [-1.7918, -3.2189]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([-1.0542, -1.0247], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-2.8460, -4.2435]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_states\n",
    "transition\n",
    "loglikelihoods\n",
    "transition[:, n_states]\n",
    "prev_alpha = transition[:, n_states] + loglikelihoods[0].view(1, -1)\n",
    "prev_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T12:25:15.531435Z",
     "start_time": "2019-07-24T12:25:15.524850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.7314, -2.7421]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roll = loglikelihoods[1]\n",
    "next_state = 0\n",
    "# next_state = 1\n",
    "\n",
    "feature_function = transition[next_state, :n_states].view(1, -1) + roll[next_state].view(1,-1).expand(1,n_states)\n",
    "feature_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T12:26:18.230556Z",
     "start_time": "2019-07-24T12:26:18.216679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.8460, -4.2435]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-2.7314, -2.7421]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-5.5774, -6.9856]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_alpha\n",
    "feature_function\n",
    "alpha_t_next_state = prev_alpha + feature_function\n",
    "alpha_t_next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T12:39:58.915104Z",
     "start_time": "2019-07-24T12:39:58.906739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.5774, -6.9856]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(-5.3586, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_t_next_state\n",
    "get_idx_of_dim1_max(alpha_t_next_state)\n",
    "a = alpha_t_next_state[0, get_idx_of_dim1_max(alpha_t_next_state)] \n",
    "\n",
    "log_sum_exp(alpha_t_next_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T12:31:27.385148Z",
     "start_time": "2019-07-24T12:31:27.376903Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([4.]),\n",
       "indices=tensor([0]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(torch.Tensor([[4,2]]), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T04:06:40.109307Z",
     "start_time": "2019-07-19T04:06:40.104730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function normal_ in module torch.nn.init:\n",
      "\n",
      "normal_(tensor, mean=0.0, std=1.0)\n",
      "    Fills the input Tensor with values drawn from the normal\n",
      "    distribution :math:`\\mathcal{N}(\\text{mean}, \\text{std})`.\n",
      "    \n",
      "    Args:\n",
      "        tensor: an n-dimensional `torch.Tensor`\n",
      "        mean: the mean of the normal distribution\n",
      "        std: the standard deviation of the normal distribution\n",
      "    \n",
      "    Examples:\n",
      "        >>> w = torch.empty(3, 5)\n",
      "        >>> nn.init.normal_(w)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.nn.init.normal_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化\n",
    "### torch.nn.init.normal\n",
    "按指定的正态分布填充tensor\n",
    "```\n",
    ">>> w = torch.empty(3, 5)\n",
    ">>> nn.init.normal_(w)\n",
    "```\n",
    "### torch.nn.Parameter\n",
    "Parameter会自动加入到Module的 .parameter 结果中，并且默认requires_grad=True\n",
    "\n",
    "### torch.randn\n",
    "从标准正态分布(均值为0，方差为1）中生成随机数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T09:06:12.762091Z",
     "start_time": "2019-07-24T09:06:12.758560Z"
    }
   },
   "outputs": [],
   "source": [
    "###### 先定住随机数种子 #####\n",
    "_ = torch.manual_seed(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T09:06:13.603167Z",
     "start_time": "2019-07-24T09:06:13.596764Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1187,  0.2110,  0.7463],\n",
       "        [-0.6136, -0.1186,  1.5565]], requires_grad=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class testA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "#         # init.normal deprecated，改用init.normal_\n",
    "#         self.transition2 = nn.init.normal(nn.Parameter(torch.randn(2,3)), -1, 0.1)\n",
    "        self.transition = nn.Parameter(torch.Tensor(2,3))\n",
    "        nn.init.normal_(self.transition)\n",
    "        \n",
    "testObj = testA()\n",
    "testObj.transition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.cat() 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T09:06:29.236272Z",
     "start_time": "2019-07-24T09:06:29.225555Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cat(): argument 'tensors' (position 1) must be tuple of Tensors, not Parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-503cd185a119>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: cat(): argument 'tensors' (position 1) must be tuple of Tensors, not Parameter"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .view() 方法 和 .expand()方法\n",
    "### .view()\n",
    "- 类似resize，按view里给的n个参数表示shape\n",
    "- 特殊的： `.view(-1)` 就是展平的一维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T09:31:15.449832Z",
     "start_time": "2019-07-24T09:31:15.424850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1187,  0.2110,  0.7463],\n",
       "        [-0.6136, -0.1186,  1.5565]], requires_grad=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "view(-1):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.1187,  0.2110,  0.7463, -0.6136, -0.1186,  1.5565],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "view(1,-1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1187,  0.2110,  0.7463, -0.6136, -0.1186,  1.5565]],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "view(1,-1).expand(1,2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1187,  0.2110,  0.7463, -0.6136, -0.1186,  1.5565],\n",
       "        [-0.1187,  0.2110,  0.7463, -0.6136, -0.1186,  1.5565]],\n",
       "       grad_fn=<ExpandBackward>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testObj.transition\n",
    "print(\"view(-1):\")\n",
    "testObj.transition.view(-1)\n",
    "print(\"view(1,-1)\")\n",
    "testObj.transition.view(1,-1)\n",
    "print(\"view(1,-1).expand(1,2)\")\n",
    "testObj.transition.view(1,-1).shape\n",
    "testObj.transition.view(1,-1).expand(2,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .contiguous() 方法\n",
    "这个方法就是重新拷贝一个tensor出来\n",
    "- 有这个的原因是因为，有些操作仅相当于改变了tensor的演示形状，比如 `narrow()，view()，expand()，transpose()`\n",
    "- 这些操作得到的tensor和原tensor是共享内存即共享data的\n",
    "- 比如把tensorA从(3,4)通过各种变换变成了(2,2,2)，此时修改shape(2,2,2)这个tensor中的某个值4变成-4，那么原tensor（shape(3,4)）中的4也变成了-4，这类操作有一定好处，比如变换成更容易理解的维度再修改某个值，这样可能带来一定的物理意义之类的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .data 属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T04:29:30.223906Z",
     "start_time": "2019-07-19T04:29:30.212323Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5466469526290894,\n",
       " 1.1683026552200317,\n",
       " 0.9098569750785828,\n",
       " 0.8260310888290405,\n",
       " 0.011779947206377983,\n",
       " 0.011028517037630081]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.5466, 1.1683, 0.9099, 0.8260, 0.0118, 0.0110])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[0.5466469526290894,\n",
       " 1.1683026552200317,\n",
       " 0.9098569750785828,\n",
       " 0.8260310888290405,\n",
       " 0.011779947206377983,\n",
       " 0.011028517037630081]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testObj.transition.view(-1).data\n",
    "testObj.transition.view(-1).data.tolist()\n",
    "testObj.transition.view(-1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T06:44:10.924219Z",
     "start_time": "2019-07-19T06:44:10.919675Z"
    }
   },
   "outputs": [],
   "source": [
    "?torch.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T08:16:06.676993Z",
     "start_time": "2019-07-19T08:16:06.659920Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 2., 4.],\n",
       "        [9., 3., 1.]])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(tensor(3.), tensor(9.))"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([9., 3., 4.]),\n",
       "indices=tensor([1, 1, 0]))"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.Tensor([[3,2,4],\n",
    "                [9,3,1]])\n",
    "a\n",
    "a[0][0],a[1][0]\n",
    "res = a.tolist()\n",
    "res1 = [res[0],res[1]]\n",
    "res2 = [res1[0],res[1]]\n",
    "torch.max(a,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T12:32:38.187441Z",
     "start_time": "2019-07-24T12:32:38.140389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[10., 20.],\n",
       "         [ 3.,  4.],\n",
       "         [ 5.,  6.]],\n",
       "\n",
       "        [[ 1., 40.],\n",
       "         [60., 40.],\n",
       "         [50., 60.]]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'---dim=1---'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[10., 20.],\n",
       "        [60., 60.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(tensor(10.), tensor(3.), tensor(5.)), (tensor(20.), tensor(4.), tensor(6.))]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(tensor(1.), tensor(60.), tensor(50.)),\n",
       " (tensor(40.), tensor(40.), tensor(60.))]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'---dim=0---'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[10., 40.],\n",
       "        [60., 40.],\n",
       "        [50., 60.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(tensor(10.), tensor(1.)), (tensor(20.), tensor(40.))]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(tensor(3.), tensor(60.)), (tensor(4.), tensor(40.))]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(tensor(5.), tensor(50.)), (tensor(6.), tensor(60.))]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([[[10,20],[3,4],[5,6]],[[1,40],[60,40],[50,60]]])\n",
    "a\n",
    "a.shape\n",
    "\n",
    "\"---dim=1---\"\n",
    "torch.max(a,dim=1)[0]\n",
    "[(a[0,0,0],a[0,1,0],a[0,2,0]),(a[0,0,1],a[0,1,1],a[0,2,1])]\n",
    "[(a[1,0,0],a[1,1,0],a[1,2,0]),(a[1,0,1],a[1,1,1],a[1,2,1])]\n",
    "\n",
    "\"---dim=0---\"\n",
    "torch.max(a,dim=0)[0]\n",
    "[(a[0,0,0],a[1,0,0]),(a[0,0,1],a[1,0,1])]\n",
    "[(a[0,1,0],a[1,1,0]),(a[0,1,1],a[1,1,1])]\n",
    "[(a[0,2,0],a[1,2,0]),(a[0,2,1],a[1,2,1])]\n",
    "# a[0,0,0],a[1,0,0]\n",
    "# a[0,0,1],a[1,0,1]\n",
    "\n",
    "# a[0,0],a[1,0]\n",
    "# a[0,1],a[1,1]\n",
    "# a[0,2],a[1,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.FloatTensor(xxxx, requires_grad=False)\n",
    "`requires_grad` 默认是`False`，如果被设置为`True`则该节点（tensor）以及所有依赖该节点（tensor）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T11:09:47.172715Z",
     "start_time": "2019-07-18T11:09:47.152455Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.79175947, -3.21887582],\n",
       "       [-1.79175947, -3.21887582],\n",
       "       [-1.79175947, -3.21887582],\n",
       "       [-1.79175947, -3.21887582],\n",
       "       [-1.79175947, -3.21887582],\n",
       "       [-1.79175947, -0.22314355]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 5, 5, 5, 0, 1, 1, 0, 2, 5, 5, 5, 5, 3, 5],\n",
       "       [4, 2, 1, 3, 5, 5, 3, 2, 1, 5, 3, 5, 0, 5, 3],\n",
       "       [5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 0, 4, 0, 5, 5],\n",
       "       [3, 5, 1, 5, 5, 5, 5, 0, 1, 5, 5, 1, 5, 3, 3],\n",
       "       [5, 5, 2, 1, 5, 5, 5, 5, 3, 5, 1, 4, 3, 2, 5],\n",
       "       [5, 1, 2, 2, 5, 5, 5, 5, 0, 1, 5, 2, 3, 2, 4],\n",
       "       [3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 0, 5, 4, 2],\n",
       "       [5, 5, 5, 5, 5, 5, 5, 3, 0, 2, 3, 5, 5, 5, 2],\n",
       "       [2, 0, 5, 5, 5, 4, 4, 3, 5, 5, 4, 3, 0, 5, 3],\n",
       "       [5, 5, 5, 5, 3, 5, 5, 5, 2, 5, 5, 5, 3, 5, 5]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6, 2)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10, 15)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10, 15, 2)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([-1.7918, -3.2189])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_likelihood\n",
    "rolls\n",
    "log_likelihood.shape\n",
    "rolls.shape\n",
    "log_likelihood[rolls].shape\n",
    "\n",
    "ft = torch.FloatTensor(log_likelihood[rolls])\n",
    "ft[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.cat(loss).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.cat(loss).mean().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## var.view(-1).data.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于Incepiton的迁移学习，用 tf、keras、tfhub 实现\n",
    "\n",
    "参照 [官网tutorials](https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub#download_the_headless_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-07T12:12:03.136148Z",
     "start_time": "2020-01-07T12:12:02.871427Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "from tqdm.auto import tqdm\n",
    "import concurrent.futures\n",
    "from multiprocessing import Pool\n",
    "import copy,os,sys\n",
    "from collections import Counter,deque\n",
    "import itertools\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-07T12:12:04.745906Z",
     "start_time": "2020-01-07T12:12:03.137691Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "只能检测到\"XLA_GPU\"，但是不能使用，<font style=\"color:red\">CUDA 和 cuDNN 需要升级</font>\n",
    "- 参考这个issue：https://github.com/tensorflow/tensorflow/issues/30388\n",
    "> Finally, you can get rid of this issue by uninstalling / reinstalling (tested on Ubuntu 18.04):\n",
    ">\n",
    "> Tensorflow 2.0\n",
    ">\n",
    "> CUDA 10.0\n",
    ">\n",
    "> cuDNN 7.6.4 (described as dedicated for CUDA 10.0)\n",
    ">\n",
    "> https://www.tensorflow.org/install/source#tested_build_configurations. You will get xla devices with corresponding non xla devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-07T12:12:05.698516Z",
     "start_time": "2020-01-07T12:12:04.748098Z"
    },
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:1', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:2', device_type='XLA_GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T09:58:52.114614Z",
     "start_time": "2019-12-16T09:58:50.181097Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# 【注意】这里 set_log_device_placement 打开了自后后面加载模型都会有很多log\n",
    "tf.config.experimental.list_physical_devices()\n",
    "tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\">>> 验证是否能在GPU上计算\")\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf1.x 里通过session控制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T09:24:23.307152Z",
     "start_time": "2019-12-06T09:24:23.294200Z"
    }
   },
   "outputs": [],
   "source": [
    "sess_conf = tf.ConfigProto()\n",
    "sess_conf.gpu_options.allow_growth = True  # 允许GPU渐进占用\n",
    "sess_conf.allow_soft_placement = True  # 把不适合GPU的放到CPU上跑\n",
    "\n",
    "g_graph = tf.Graph()\n",
    "g_sess = tf.Session(graph=g_graph, config=sess_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf2.x 用新的方式控制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T06:21:31.008856Z",
     "start_time": "2019-12-31T06:21:30.734777Z"
    },
    "deletable": false,
    "editable": false,
    "init_cell": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.gpu.set_per_process_memory_fraction(0.75)\n",
    "tf.config.gpu.set_per_process_memory_growth(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-07T12:12:05.803285Z",
     "start_time": "2020-01-07T12:12:05.700257Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "        tf.config.experimental.set_memory_growth(gpus[1], True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正式流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
    "image_data = image_generator.flow_from_directory(root_path, classes=['Taj_Mahal','Qutb_Minar'], target_size=IMAGE_SHAPE)\n",
    "for image_batch, label_batch in image_data:\n",
    "    print(\"Image batch shape: \", image_batch.shape)\n",
    "    print(\"Label batch shape: \", label_batch.shape)\n",
    "    break\n",
    "\n",
    "# 重新加载一下iter\n",
    "image_data = image_generator.flow_from_directory(root_path, classes=['Taj_Mahal','Qutb_Minar'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并多个generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用tf封装的`ImageDataGenerator`从目录里直接读取数据，按子目录来分类别\n",
    "\n",
    "这里尝试了合并多个 generator | 参考 [SO的回答](https://stackoverflow.com/questions/49404993/keras-how-to-use-fit-generator-with-multiple-inputs)\n",
    "- 注意测试了`itertools.chain`是不行的，会一直循环第一个`generator`的结果\n",
    "- `concat` 方法可行但是没有保留`flow_from_directory`得到的类`DirectoryIterator`，一些方法如`next()`, `num_class`不能用了，`batch_size`也需要更新为`n倍`，这些都只能用新的变量单独保存\n",
    "\n",
    "```python\n",
    "def concat(*iterables):\n",
    "    while True:\n",
    "        data = [i.next() for i in iterables]\n",
    "        yield np.concatenate([i[0] for i in data], axis=0), np.concatenate([i[1] for i in data], axis=0)\n",
    "\n",
    "to_merge = [image_data_aug1,image_data_aug2,image_data_normal]\n",
    "train_data = concat(*to_merge)\n",
    "num_classes = image_data_aug1.num_classes\n",
    "batch_size = len(to_merge) * batch_size\n",
    "```\n",
    "- 还有一种方法是继承Keras的`Sequence`类，但是这方法似乎也没有保留`DirectoryIterator`的那些属性，没有尝试 上述的 [SO回答](https://stackoverflow.com/questions/49404993/keras-how-to-use-fit-generator-with-multiple-inputs) 中有这种方案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并三个 generator，各自代表不同的augmentaion —— 水平翻转&缩放、旋转&明暗、正常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T05:31:20.606236Z",
     "start_time": "2019-11-20T05:30:45.518975Z"
    },
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datagen_args1 = dict(horizontal_flip=True,zoom_range=[0.1,0.2])\n",
    "datagen_args2 = dict(rotation_range=90, brightness_range=[0.3,0.5])\n",
    "batch_size = 90\n",
    "image_generator_aug1 = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255,**datagen_args1)\n",
    "image_generator_aug2 = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255,**datagen_args2)\n",
    "image_generator_normal = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
    "image_data_aug1 = image_generator_aug1.flow_from_directory(root_path, classes=['Taj_Mahal','Qutb_Minar'], target_size=IMAGE_SHAPE, batch_size=batch_size)\n",
    "image_data_aug2 = image_generator_aug2.flow_from_directory(root_path, classes=['Taj_Mahal','Qutb_Minar'], target_size=IMAGE_SHAPE, batch_size=batch_size)\n",
    "image_data_normal = image_generator_normal.flow_from_directory(root_path, classes=['Taj_Mahal','Qutb_Minar'], target_size=IMAGE_SHAPE, batch_size=batch_size)\n",
    "\n",
    "def concat(*iterables):\n",
    "    while True:\n",
    "        data = [i.next() for i in iterables]\n",
    "        yield np.concatenate([i[0] for i in data], axis=0), np.concatenate([i[1] for i in data], axis=0)\n",
    "\n",
    "to_merge = [image_data_aug1,image_data_aug2,image_data_normal]\n",
    "train_data = concat(*to_merge)\n",
    "num_classes = image_data_aug1.num_classes\n",
    "batch_size = len(to_merge) * batch_size\n",
    "print(f\">>> merge {len(to_merge)} 个iter后的batch_size为: {batch_size}\")\n",
    "print(\">>> 如下显示加了 [旋转、反转] 等augmentation的训练集（合并了多个generator）\")\n",
    "for i in range(199*3//batch_size+1+1):\n",
    "    pics, label_batch = train_data.__next__()\n",
    "    if i == 0:\n",
    "        print(\" 独立演示train_data里的第一项\")\n",
    "        print(\" Image batch shape: \", pics.shape)\n",
    "        print(\" Label batch shape: \", label_batch.shape)\n",
    "        print(\"~~\"*15)\n",
    "    print(pics.shape)\n",
    "    if i == 199*3//batch_size:\n",
    "        print(\">>> 已经消费完所有数据，后面从头开始从generator里获取数据\")\n",
    "    r = int(len(pics) ** 0.5)\n",
    "    c = len(pics) // r + 1\n",
    "    fig,axes_arr = plt.subplots(r,c)\n",
    "    _ = [ax.set_axis_off() for ax in axes_arr.ravel()]\n",
    "    for idx, pic in enumerate(pics):\n",
    "        axes = axes_arr[idx//c, idx % c]\n",
    "        axes.set_axis_off()\n",
    "        _ = axes.imshow(pic)\n",
    "\n",
    "image_batch, label_batch = train_data.__next__()  # 随便拿一个出来当image_batch给后面测试用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 带有train test/validation 的Generator\n",
    "基本流程是\n",
    "- 初始化`ImageDataGenerator`时提供`validation_split`参数\n",
    "- 然后获取flow时（例如`flow_from_directory`）使用`subset`来标记是取训练集还是测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T10:37:08.780460Z",
     "start_time": "2019-11-20T10:36:23.477781Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 90\n",
    "validation_ratio=0.2\n",
    "ig_aug1 = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255,horizontal_flip=True,zoom_range=[0.1,0.2])\n",
    "ig_aug2 = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255,rotation_range=90, brightness_range=[0.3,0.5])\n",
    "generic_params = dict(directory=root_path, classes=['Taj_Mahal','Qutb_Minar'], target_size=IMAGE_SHAPE, batch_size=batch_size)\n",
    "augflow1 = ig_aug1.flow_from_directory(**generic_params)\n",
    "augflow2 = ig_aug2.flow_from_directory(**generic_params)\n",
    "# 一般用没有augmentation的数据做验证集\n",
    "generic_params = dict(directory=root_path, classes=['Taj_Mahal','Qutb_Minar'], target_size=IMAGE_SHAPE, batch_size=batch_size)\n",
    "ig_normal = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=validation_ratio,rescale=1/255)\n",
    "normal_flow_train = ig_normal.flow_from_directory(subset='training', **generic_params)\n",
    "normal_flow_valid = ig_normal.flow_from_directory(subset='validation', **generic_params)\n",
    "\n",
    "\n",
    "def concat(*iterables):\n",
    "    while True:\n",
    "        data = [i.next() for i in iterables]\n",
    "        yield np.concatenate([i[0] for i in data], axis=0), np.concatenate([i[1] for i in data], axis=0)\n",
    "\n",
    "to_merge = [augflow1,augflow2,normal_flow_train]\n",
    "train_data = concat(*to_merge)\n",
    "num_classes = augflow1.num_classes\n",
    "samples = sum(i.samples for i in to_merge)\n",
    "batch_size = len(to_merge) * batch_size\n",
    "print(f\">>> merge {len(to_merge)} 个iter后的batch_size为: {batch_size}\")\n",
    "print(\">>> 如下显示加了 [旋转、反转] 等augmentation的训练集（合并了多个generator）\")\n",
    "for i in range(samples//batch_size+1+2): # 多循环两轮\n",
    "    pics, label_batch = train_data.__next__()\n",
    "    if i == 0:\n",
    "        print(\" 独立演示train_data里的第一项\")\n",
    "        print(\" 注意后续的shape会比较特别是因为，ig_normal分了20%做验证集，所以会比另外两个没有分validation的提前消耗完\")\n",
    "        print(\" 假设batch_size=90,它在第二次取90个时就消耗完了,只取到了160-90=70个,而另外两个数据集还能取到90个,总计就是70+90*2=250个\")\n",
    "        print(\" Image batch shape: \", pics.shape)\n",
    "        print(\" Label batch shape: \", label_batch.shape)\n",
    "        print(\"~~\"*15)\n",
    "    print(pics.shape)\n",
    "    if i == samples//batch_size:\n",
    "        print(\">>> 已经消费完所有数据，下一次会从头开始从generator里获取数据\")\n",
    "    r = int(len(pics) ** 0.5)\n",
    "    c = len(pics) // r + 1\n",
    "    fig,axes_arr = plt.subplots(r,c)\n",
    "    _ = [ax.set_axis_off() for ax in axes_arr.ravel()]\n",
    "    for idx, pic in enumerate(pics):\n",
    "        axes = axes_arr[idx//c, idx % c]\n",
    "        axes.set_axis_off()\n",
    "        _ = axes.imshow(pic)\n",
    "\n",
    "image_batch, label_batch = train_data.__next__()  # 随便拿一个出来当image_batch给后面测试用\n",
    "print(f\">>> 消费完后从头拿到的数据shape是: {image_batch.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载classification model预测分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T10:37:42.213014Z",
     "start_time": "2019-11-20T10:37:36.315825Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier_url =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2\" #@param {type:\"string\"}\n",
    "clf = tf.keras.Sequential([hub.KerasLayer(classifier_url, input_shape=IMAGE_SHAPE+(3,))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载headless model预测feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T10:37:45.282654Z",
     "start_time": "2019-11-20T10:37:42.336471Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_extractor_url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2\" #@param {type:\"string\"}\n",
    "feat_layer = hub.KerasLayer(feature_extractor_url, input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意:\n",
    "- clf是 `tf.keras.Sequential` 搭起来的\n",
    "- feat_layer是`hub.KerasLayer`直接做的一个`Layer`，所以得到的结果是一个`Tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T10:37:45.410986Z",
     "start_time": "2019-11-20T10:37:45.408141Z"
    }
   },
   "outputs": [],
   "source": [
    "image_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T10:37:50.234170Z",
     "start_time": "2019-11-20T10:37:45.608774Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_batch_part = image_batch[:16]\n",
    "pred_res = clf.predict(image_batch_part)\n",
    "print(f\"clf的结果,shape: {pred_res.shape}, argmax: {np.argmax(pred_res, axis=1)}\\n\",pred_res)\n",
    "feat_layer(image_batch_part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T08:28:05.314495Z",
     "start_time": "2019-11-29T08:28:05.283636Z"
    }
   },
   "outputs": [],
   "source": [
    "feat_layer.trainable = False  # feature_vector的生成就不用训练了\n",
    "model = tf.keras.Sequential([\n",
    "  feat_layer,\n",
    "  tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model.summary()\n",
    "pred = model(image_batch)\n",
    "pred\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=\"categorical_crossentropy\", metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CallBack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T10:37:57.197938Z",
     "start_time": "2019-11-20T10:37:57.191363Z"
    }
   },
   "outputs": [],
   "source": [
    "class CollectBatchStats(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.batch_losses = []\n",
    "        self.batch_acc = []\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.batch_losses.append(logs['loss'])\n",
    "        self.batch_acc.append(logs['acc'])\n",
    "        self.model.reset_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面用`concat`方式的结果，要注意`validation_step`\n",
    "- 如果用`normal_flow_valid.samples // batch_size`注意是否为0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T10:44:30.149874Z",
     "start_time": "2019-11-20T10:43:05.401536Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "steps_per_epoch = np.ceil(samples//batch_size)\n",
    "batch_stats_callback = CollectBatchStats()\n",
    "history = model.fit_generator(normal_flow_train, epochs=4,\n",
    "                              steps_per_epoch = normal_flow_train.samples//40,\n",
    "                              validation_data = normal_flow_valid,\n",
    "                              validation_steps = normal_flow_valid.samples ,\n",
    "                              callbacks = [batch_stats_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "img_width, img_height = 256, 256\n",
    "train_data_dir = \"tf_files/codoon_photos\"\n",
    "validation_data_dir = \"tf_files/codoon_photos\"\n",
    "nb_train_samples = 4125\n",
    "nb_validation_samples = 466 \n",
    "batch_size = 16\n",
    "epochs = 50\n",
    "\n",
    "model = applications.ResNet50(include_top=False, weights='imagenet', input_shape=(img_width, img_height, 3))\n",
    "\n",
    "# Freeze the layers which you don't want to train. Here I am freezing the all layers.\n",
    "for layer in model.layers[:]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Adding custom Layer\n",
    "# We only add\n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "# Adding even more custom layers\n",
    "# x = Dense(1024, activation=\"relu\")(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "# Initiate the train and test generators with data Augumentation \n",
    "train_datagen = ImageDataGenerator(\n",
    "  rescale = 1./255,\n",
    "  horizontal_flip = True,\n",
    "  fill_mode = \"nearest\",\n",
    "  zoom_range = 0.3,\n",
    "  width_shift_range = 0.3,\n",
    "  height_shift_range=0.3,\n",
    "  rotation_range=30)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "  rescale = 1./255,\n",
    "  horizontal_flip = True,\n",
    "  fill_mode = \"nearest\",\n",
    "  zoom_range = 0.3,\n",
    "  width_shift_range = 0.3,\n",
    "  height_shift_range=0.3,\n",
    "  rotation_range=30)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "  train_data_dir,\n",
    "  target_size = (img_height, img_width),\n",
    "  batch_size = batch_size,\n",
    "  class_mode = \"categorical\")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "  validation_data_dir,\n",
    "  target_size = (img_height, img_width),\n",
    "  class_mode = \"categorical\")\n",
    "\n",
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint(\"resnet50_retrain.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "\n",
    "# Train the model \n",
    "model_final.fit_generator(\n",
    "  train_generator,\n",
    "  samples_per_epoch = nb_train_samples,\n",
    "  epochs = epochs,\n",
    "  validation_data = validation_generator,\n",
    "  nb_val_samples = nb_validation_samples,\n",
    "  callbacks = [checkpoint, early])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器打分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:04:43.173876Z",
     "start_time": "2019-12-02T03:04:43.168406Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **准备「train」「validation」数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T05:22:23.464469Z",
     "start_time": "2019-12-02T05:22:22.629390Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"\\n\",\"--\"*15,\"原始数据准备\",\"--\"*15,\"\\n\")\n",
    "df = pd.read_csv(\"/home/zhoutong/res.csv\")\n",
    "df['id'] = df['id'].astype(int)\n",
    "df.count()\n",
    "print(\"去掉na\")\n",
    "df = df.dropna()\n",
    "df.count()\n",
    "df.head(3)\n",
    "\n",
    "print(\"\\n\",\"--\"*15,\"取样本\",\"--\"*15,\"\\n\")\n",
    "ctr = df['ctr'].to_numpy()\n",
    "print(\"各百分位对应的ctr:\")\n",
    "[(i,np.percentile(ctr,i)) for i in [5,15,25,50,75,95]]\n",
    "print(\"取上四分位为正样本，下四分位为负样本\")\n",
    "neg,pos = df.query(\"ctr<0.022\"),df.query(\"ctr>0.068\")\n",
    "print(f\"正样本计数: {pos.shape}, 负样本计数: {neg.shape}\")\n",
    "_ = plt.hist(ctr[np.logical_and(ctr<0.13, ctr>0)],bins=300)\n",
    "plt.show()\n",
    "print(\"去掉极端值后分布如上，中位数:\",np.percentile(ctr[np.logical_and(ctr<0.13, ctr>0)], 50))\n",
    "print(\"均值:\",np.mean(ctr[np.logical_and(ctr<0.13, ctr>0)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **获取「verify」数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T05:22:26.951212Z",
     "start_time": "2019-12-02T05:22:26.868266Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\",\"--\"*15,\"原始数据准备\",\"--\"*15,\"\\n\")\n",
    "df_v = pd.read_csv(\"/home/zhoutong/res_11_25.csv\")\n",
    "df_v['id'] = df_v['id'].astype(int)\n",
    "df_v.count()\n",
    "print(\"去掉na\")\n",
    "df_v = df_v.dropna()\n",
    "df_v.count()\n",
    "df_v['fileName'] = df_v['banner_url'].apply(lambda url:url.split(\"/\")[-1].split(\"?\")[0])\n",
    "df_v.head(3)\n",
    "\n",
    "# print(\"\\n\",\"--\"*15,\"取样本\",\"--\"*15,\"\\n\")\n",
    "# ctr = df['ctr'].to_numpy()\n",
    "# print(\"各百分位对应的ctr:\")\n",
    "# [(i,np.percentile(ctr,i)) for i in [5,15,25,50,75,95]]\n",
    "# print(\"取上四分位为正样本，下四分位为负样本\")\n",
    "# neg,pos = df.query(\"ctr<0.022\"),df.query(\"ctr>0.068\")\n",
    "# print(f\"正样本计数: {pos.shape}, 负样本计数: {neg.shape}\")\n",
    "# _ = plt.hist(ctr[np.logical_and(ctr<0.13, ctr>0)],bins=300)\n",
    "# plt.show()\n",
    "# print(\"去掉极端值后分布如上，中位数:\",np.percentile(ctr[np.logical_and(ctr<0.13, ctr>0)], 50))\n",
    "# print(\"均值:\",np.mean(ctr[np.logical_and(ctr<0.13, ctr>0)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:36:18.813967Z",
     "start_time": "2019-12-02T03:31:30.972472Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_dir=\"./tmp/auto_score\"\n",
    "print(\"下载图片至本地: \", sample_dir)\n",
    "\n",
    "def download(url, subdir):\n",
    "    path = os.path.join(sample_dir, subdir, url.split(\"/\")[-1].split(\"?\")[0])\n",
    "    urllib.request.urlretrieve(url, path)\n",
    "\n",
    "    \n",
    "from functools import partial\n",
    "download_pos = partial(download, subdir=\"pos\")\n",
    "download_neg = partial(download, subdir=\"neg\")\n",
    "download_verify = partial(download, subdir=\"verify\")\n",
    "from multiprocessing import Pool\n",
    "p = Pool(12)\n",
    "iter_to_run = p.imap(download_verify, df_v['banner_url'])\n",
    "_ = list(tqdm(iter_to_run, total=df_v['banner_url'].shape[0], desc=\"download verify_pics:\"))\n",
    "\n",
    "# iter_to_run = p.imap(download_neg, neg['banner_url'])\n",
    "# _ = list(tqdm(iter_to_run,total=neg['banner_url'].size,desc=\"download neg:\"))\n",
    "\n",
    "# iter_to_run = p.imap(download_pos, pos['banner_url'])\n",
    "# _ = list(tqdm(iter_to_run,total=pos['banner_url'].size,desc=\"download pos:\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T09:43:26.189546Z",
     "start_time": "2019-12-27T09:43:25.875468Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (224,224)\n",
    "batch_size = 32\n",
    "validation_ratio=0.1\n",
    "sample_dir=\"./tmp/auto_score\"\n",
    "generic_params = dict(directory=sample_dir, classes=['pos','neg'], target_size=IMAGE_SHAPE, batch_size=batch_size)\n",
    "ig_normal = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=validation_ratio,rescale=1/255)\n",
    "normal_flow_train = ig_normal.flow_from_directory(subset='training', **generic_params)\n",
    "normal_flow_valid = ig_normal.flow_from_directory(subset='validation', **generic_params)\n",
    "\n",
    "for image_batch, label_batch in normal_flow_train:\n",
    "    print(\"Image batch shape: \", image_batch.shape)\n",
    "    print(\"Label batch shape: \", label_batch.shape)\n",
    "    break\n",
    "\n",
    "# 重新加载一下iter\n",
    "normal_flow_train = ig_normal.flow_from_directory(subset='training', **generic_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T09:43:44.433707Z",
     "start_time": "2019-12-27T09:43:44.430177Z"
    }
   },
   "outputs": [],
   "source": [
    "normal_flow_valid.filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T02:07:15.962360Z",
     "start_time": "2019-12-02T02:06:44.929978Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_extractor_url = \"https://tfhub.dev/google/imagenet/inception_resnet_v2/feature_vector/4\" #@param {type:\"string\"}\n",
    "feat_layer = hub.KerasLayer(feature_extractor_url, input_shape=(224,224,3))\n",
    "feat_layer.trainable = False  # feature_vector的生成就不用训练了\n",
    "model = tf.keras.Sequential([\n",
    "  feat_layer,\n",
    "  tf.keras.layers.Dense(normal_flow_train.num_classes, activation='softmax')\n",
    "])\n",
    "model.summary()\n",
    "# pred = model(image_batch)\n",
    "# pred\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=\"categorical_crossentropy\", metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T10:29:48.598999Z",
     "start_time": "2019-11-29T10:29:48.592700Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class HistoryCB(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.batch_losses = []\n",
    "        self.batch_acc = []\n",
    "        self.logs_dict={}\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        print(\"cococococco at \",batch)\n",
    "        self.logs_dict.update({batch:logs})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:04:18.966962Z",
     "start_time": "2019-12-02T02:15:44.000229Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tbd_cb=tf.keras.callbacks.TensorBoard(log_dir='./tmp/auto_score/tensorboard_logs',\n",
    "                                      histogram_freq=0,write_graph=False,update_freq='batch',\n",
    "                                      profile_batch=0)\n",
    "\n",
    "checkpoint_path = \"./tmp/auto_score/ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "ckpt_cb=tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, verbose=1, save_best_only=True)\n",
    "\n",
    "es_db = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "# progress_db = tf.keras.callbacks.ProgbarLogger(count_mode='steps')\n",
    "\n",
    "custom_db = HistoryCB()\n",
    "\n",
    "history = model.fit_generator(normal_flow_train, epochs=15,\n",
    "                              steps_per_epoch = normal_flow_train.samples // normal_flow_train.batch_size,\n",
    "                              validation_data = normal_flow_valid,\n",
    "#                               validation_steps = normal_flow_valid.samples,\n",
    "                              verbose=1,\n",
    "                              callbacks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:39:24.142406Z",
     "start_time": "2019-12-02T03:39:24.126511Z"
    }
   },
   "outputs": [],
   "source": [
    "history.params\n",
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 `checkpoint_path` 格式保存权重\n",
    "# checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
    "# model.save_weights(checkpoint_path.format(epoch=0))\n",
    "# model.save(\"mymodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:36:55.421829Z",
     "start_time": "2019-12-02T03:36:38.790142Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"./tmp/auto_score/models/model_bysave.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T07:09:51.584935Z",
     "start_time": "2019-11-29T07:09:46.679591Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(\n",
    "    model=model,\n",
    "    filepath=\"./tmp/auto_score/models/model_1\",\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=\"h5\",\n",
    "    signatures=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T12:00:06.548528Z",
     "start_time": "2019-12-02T12:00:06.539409Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "?requests.get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T12:08:41.645023Z",
     "start_time": "2019-12-02T12:07:26.593524Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pos_path=\"/home/zhoutong/notebook_collection/tmp/CV_auto_score/pos/{}\"\n",
    "neg_path=\"/home/zhoutong/notebook_collection/tmp/CV_auto_score/neg/{}\"\n",
    "verify_path = \"/home/zhoutong/notebook_collection/tmp/CV_auto_score/verify/{}\"\n",
    "r=16\n",
    "total = pd.concat([df_v.head(r),df_v[190:190+r],df_v[500:500+r],df_v.tail(r)])\n",
    "total.head(10)\n",
    "\n",
    "total_res =[]\n",
    "for idx,row in total.iterrows():\n",
    "    total_res.append((row['banner_url'],row['ctr'],np.array(Image.open(verify_path.format(row['fileName'])).resize((224,224)))))\n",
    "fig, axe_list=plt.subplots(8,8,figsize=(15,16))\n",
    "\n",
    "for idx,(url,ctr,img) in enumerate(total_res):\n",
    "    axe = axe_list.flatten()[idx]\n",
    "    axe.set_axis_off()\n",
    "    obj_text=\",\".join([i['obj']+\":\"+str(i['cnt']) for i in json.loads(requests.get(\"http://10.65.34.65:8004/obj\",params={\"img_url\":url,\"id\":-1}).text)['result']])\n",
    "#     obj_text=\"asdf\"\n",
    "    _ = axe.imshow(img)\n",
    "    _ = axe.text(x=0, y=axe.get_ylim()[0]+50, s=\"{:4f}\\n{}\".format(ctr,obj_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:39:24.085823Z",
     "start_time": "2019-12-02T03:38:17.633182Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bysave = tf.keras.models.load_model(\"./tmp/auto_score/models/model_bysave.h5\", custom_objects={'KerasLayer':hub.KerasLayer})\n",
    "bysave.build((None,224,224,3))\n",
    "type(bysave)\n",
    "print(\">>> test: \")\n",
    "type(bysave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:50:19.147848Z",
     "start_time": "2019-12-02T03:49:54.812842Z"
    }
   },
   "outputs": [],
   "source": [
    "bysave.predict(np.array([np.array(img) for img in img_pos]))\n",
    "bysave.predict(np.array([np.array(img) for img in img_neg]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T07:51:26.884212Z",
     "start_time": "2019-11-29T07:50:14.616655Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "bytfkeras = tf.keras.models.load_model(\"./tmp/auto_score/models/model_1\", custom_objects={'KerasLayer':hub.KerasLayer})\n",
    "bytfkeras.build((None,224,224,3))\n",
    "print(\">>> test: \")\n",
    "type(bytfkeras)\n",
    "bytfkeras.predict(np.expand_dims(np.array(img),0))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python3.6(tf2)",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "202.528px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

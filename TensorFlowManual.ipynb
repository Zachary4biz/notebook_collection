{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T02:29:48.690551Z",
     "start_time": "2019-08-21T02:29:48.427107Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "from tqdm.auto import tqdm\n",
    "import concurrent.futures\n",
    "from multiprocessing import Pool\n",
    "import copy,os,sys,psutil\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T02:29:43.674801Z",
     "start_time": "2019-08-21T02:29:41.766572Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow API解释"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T10:07:37.621348Z",
     "start_time": "2019-07-12T10:07:37.452020Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.add & tf.nn.bias_add\n",
    "- [StackOverflow](https://stackoverflow.com/questions/43131606/whats-the-difference-of-add-methods-in-tensorflow)\n",
    ">tf.add is a general addition operation, while tf.nn.bias_add is to be used specifically for adding bias to the weights, which **raises an exception if the dtypes aren't same.**\n",
    ">\n",
    ">Unlike **tf.add**, the **type of bias is allowed to differ from value** in the case where both types are quantized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.expand_dims & tf.reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T07:26:53.290712Z",
     "start_time": "2019-08-21T07:26:53.078379Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a_', (2, 2, 2))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('a', TensorShape([Dimension(2), Dimension(2), Dimension(2)]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('a_tfreshape',\n",
       " TensorShape([Dimension(2), Dimension(2), Dimension(2), Dimension(1)]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('a_tfexpand',\n",
       " TensorShape([Dimension(2), Dimension(2), Dimension(2), Dimension(1)]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始shape为\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2], dtype=int32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 就是在最后一维上扩展一个\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 1], dtype=int32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 就是在第0维上扩展一个\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 2], dtype=int32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 就是在第1维上扩展一个\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 2], dtype=int32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ = [[[1,1],[2,2]],\n",
    "      [[3,3],[4,4]]]\n",
    "a_ = np.array(a_)\n",
    "\"a_\",a_.shape\n",
    "\n",
    "a = tf.Variable(a_,dtype=tf.float32)\n",
    "\"a\",a.shape\n",
    "\n",
    "a_tfreshape = tf.reshape(a,[2,2,2,-1])\n",
    "\"a_tfreshape\",a_tfreshape.shape\n",
    "a_tfexpand = tf.expand_dims(a,-1)\n",
    "\"a_tfexpand\",a_tfexpand.shape\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"原始shape为\")\n",
    "    sess.run(tf.shape(a))\n",
    "    print(\"-1 就是在最后一维上扩展一个\")\n",
    "    sess.run(tf.shape(tf.expand_dims(a,-1)))\n",
    "    print(\"0 就是在第0维上扩展一个\")\n",
    "    sess.run(tf.shape(tf.expand_dims(a,0)))\n",
    "    print(\"1 就是在第1维上扩展一个\")\n",
    "    sess.run(tf.shape(tf.expand_dims(a,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.stack\n",
    "- stack要求两个tensor维度必须是相同的，本来是 $[D_1,D_2,..D_n]$ 的共n个维度的俩tensor，stack后变成n+1个维度，多+1的那个维度为`2`，具体这个+1的维度`2`放在哪就由`axis=`决定，`axis=0`那这个`2`就放在索引0上\n",
    "\n",
    "shape为(3,4,5)的两个tensor在不同axis上做stack\n",
    "- axis=0: (**2**,3,4,5)\n",
    "- axis=1: (3,**2**,4,5)\n",
    "- axis=2: (3,4,**2**,5)\n",
    "- axis=3: (3,4,5,**2**)\n",
    "\n",
    "stack三个维度相同的tensor那就是把`3`添加在`axis`指定的索引位置上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T12:56:14.885274Z",
     "start_time": "2019-06-13T12:56:14.860137Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 5)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(3, 4, 5)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(4), Dimension(5), Dimension(3)])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.random([3,4,5])\n",
    "b = np.random.random([3,4,5])\n",
    "e = np.random.random([3,4,5])\n",
    "c = tf.stack([a,b,e], axis=3)\n",
    "a.shape\n",
    "b.shape\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.unstack\n",
    "按`axis`指定的维度拆开，该维度取值是多少就拆成多少个tensor\n",
    "\n",
    "shape为(3,4,5,2)的一个tensor在不同axis上做unstack\n",
    "- axis=0: [(4,5,2)]*3\n",
    "- axis=1: [(3,5,2)]*4\n",
    "- axis=2: [(3,4,2)]*5\n",
    "- axis=3: [(3,4,5)]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T13:01:42.456998Z",
     "start_time": "2019-06-13T13:01:42.411907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 5, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'unstack_10:0' shape=(4, 5, 2) dtype=float64>,\n",
       " <tf.Tensor 'unstack_10:1' shape=(4, 5, 2) dtype=float64>,\n",
       " <tf.Tensor 'unstack_10:2' shape=(4, 5, 2) dtype=float64>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'unstack_11:0' shape=(4, 5, 2) dtype=float64>,\n",
       " <tf.Tensor 'unstack_11:1' shape=(4, 5, 2) dtype=float64>,\n",
       " <tf.Tensor 'unstack_11:2' shape=(4, 5, 2) dtype=float64>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'unstack_12:0' shape=(3, 5, 2) dtype=float64>,\n",
       " <tf.Tensor 'unstack_12:1' shape=(3, 5, 2) dtype=float64>,\n",
       " <tf.Tensor 'unstack_12:2' shape=(3, 5, 2) dtype=float64>,\n",
       " <tf.Tensor 'unstack_12:3' shape=(3, 5, 2) dtype=float64>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'unstack_13:0' shape=(3, 4, 2) dtype=float64>,\n",
       " <tf.Tensor 'unstack_13:1' shape=(3, 4, 2) dtype=float64>,\n",
       " <tf.Tensor 'unstack_13:2' shape=(3, 4, 2) dtype=float64>,\n",
       " <tf.Tensor 'unstack_13:3' shape=(3, 4, 2) dtype=float64>,\n",
       " <tf.Tensor 'unstack_13:4' shape=(3, 4, 2) dtype=float64>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'unstack_14:0' shape=(3, 4, 5) dtype=float64>,\n",
       " <tf.Tensor 'unstack_14:1' shape=(3, 4, 5) dtype=float64>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = np.random.random([3,4,5,2])\n",
    "m.shape\n",
    "tf.unstack(m)\n",
    "tf.unstack(m,axis=0)\n",
    "tf.unstack(m,axis=1)\n",
    "tf.unstack(m,axis=2)\n",
    "tf.unstack(m,axis=3)\n",
    "\n",
    "# ?tf.unstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.reduce_mean\n",
    "tf.reduce_mean, reduce_sum, reduce_max就是计算某一个维度上的均值、加和、最值\n",
    ">tf.reduce_mean(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
    "- axis：\n",
    "    - axis=None, 求全部元素的平均值；\n",
    "    - axis=0, 列平均值；\n",
    "    - axis=1，行平均值。 \n",
    "- keep_dims：若值为True，可多行输出平均值。 \n",
    "- name：自定义操作名。 \n",
    "- ~~reduction_indices：axis的旧名，已停用。~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T12:16:59.148829Z",
     "start_time": "2019-07-17T12:16:59.052478Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1bbe52383df7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0ma_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0ma_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "np.random.seed(2019)\n",
    "a = np.random.randint(0,10,size=[2,3])\n",
    "\"a\",a\n",
    "a_var = tf.Variable(a)\n",
    "a_var.shape\n",
    "a.shape\n",
    "tf.reduce_mean(a,axis=None).shape\n",
    "tf.reduce_mean(a,axis=0).shape\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.reduce_sum(a,axis=None))\n",
    "    sess.run(tf.reduce_mean(a,axis=None))\n",
    "    sess.run(tf.reduce_mean(a,axis=None)).shape\n",
    "    sess.run(tf.reduce_mean(a,axis=0))\n",
    "    sess.run(tf.reduce_mean(a,axis=0)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.transpose\n",
    "> tf.transpose(a, perm=None, name='transpose', conjugate=False)\n",
    "- a 需要转置的tensor\n",
    "- perm （permute）转置的形式\n",
    "    - `None` 表示把shape倒转过来，如[3,4]变成[4,3]，[1,2,3,4]变成[4,3,2,1]\n",
    "    - `list[int]类型` 里面的int表示原始维度的索引按list里的顺序来排列\n",
    "        - 如`[0,3,2,1]`表示原始的维度`3`放到第二个,`1`放到第四个（二、四维互换了）\n",
    "        - 如`[1,3,2,0]`表示转置后的，按数字作为索引把原始的维度按当前list里的顺序重新排列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T12:09:14.064183Z",
     "start_time": "2019-06-13T12:09:14.028003Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 5, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'transpose_8:0' shape=(6, 5, 4, 3) dtype=float64>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'transpose_9:0' shape=(5, 4, 3, 6) dtype=float64>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.random([3,4,5,6])\n",
    "a.shape\n",
    "tf.transpose(a)\n",
    "tf.transpose(a,[2,1,0,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.truncated_normal\n",
    "按指定均值、标准差生成正态分布的数据，并且做两倍标准差截断\n",
    "> tf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None) :\n",
    "- shape表示生成张量的维度\n",
    "- mean是均值 | 默认为0\n",
    "- stddev是标准差。 | 默认为1.0\n",
    "- seed随机数种子\n",
    ">\n",
    ">这个函数产生正太分布，均值和标准差自己设定。这是一个截断的产生正太分布的函数，就是说产生正太分布的值如果与均值的差值大于两倍的标准差，那就重新生成。和一般的正太分布的产生随机数据比起来，这个函数产生的随机数与均值的差距不会超过两倍的标准差，但是一般的别的函数是可能的。\n",
    "\n",
    "tf里的随机数种子，可以设置到图级别也可以设置为op级别\n",
    "- 图级别：\n",
    "```\n",
    "# at some graph\n",
    "tf.set_random_seed(2019)\n",
    "tf.truncated_normal([3,4],stddev=0.1)\n",
    "```\n",
    "- op级别：\n",
    "```\n",
    "tf.truncated_normal([3,4],stddev=0.1,seed=2019)\n",
    "```\n",
    "\n",
    "类似的随机函数还有 `tf.random_uniform([3,4], -1, 1)` 生成-1到1的均匀分布的随机数\n",
    ">tf.random_uniform(shape, minval=0, maxval=None, dtype=tf.float32, seed=None, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T08:41:50.844102Z",
     "start_time": "2019-06-13T08:41:50.721527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01135067,  0.05639387, -0.04778707,  0.04571497],\n",
       "       [ 0.1153388 ,  0.07203745,  0.15631334, -0.16913354],\n",
       "       [ 0.124575  , -0.04655875,  0.0504917 ,  0.06605241]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.04278614,  0.16716555, -0.01701541, -0.00202826],\n",
       "       [ 0.11125483,  0.07280847, -0.07696502, -0.1261591 ],\n",
       "       [-0.01496598, -0.01382563, -0.05033821, -0.02851957]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# truncated_normal 按正态分布生成数据，并且做标准差截断\n",
    "with tf.Session() as sess:\n",
    "    random_op = tf.truncated_normal([3,4],stddev=0.1,seed=2019)\n",
    "    # random_op在一段程序里跑了三次，seed只控制程序每次相同位置生成时结果是一样的，而这三次则都不一样\n",
    "    sess.run(random_op)\n",
    "    sess.run(tf.cast(random_op,tf.int32))\n",
    "    sess.run(tf.to_float(random_op,tf.int32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.while_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T12:41:34.414290Z",
     "start_time": "2019-06-18T12:41:34.063546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 10]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i  = 0\n",
    "n =10 \n",
    "\n",
    "def cond(i, n):\n",
    "    return i < n\n",
    "\n",
    "def body(i, n):\n",
    "    i = i + 1\n",
    "    return i, n\n",
    "i, n = tf.while_loop(cond, body, [i, n])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run([i,n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.slice & tf.gather\n",
    "- `tf.slice`: 按照指定的下标范围抽取连续区域的子集\n",
    "    - 用得少，一般直接用索引 `[a:b,c:d,:-5]` 这种方式直接取（更pythonic）\n",
    "- `tf.gather`: 按照指定的下标集合从axis=0中抽取子集，适合抽取不连续区域的子集\n",
    "\n",
    "### tf.slice\n",
    "> Note that tf.Tensor.getitem is typically a more pythonic way to perform slices, as it allows you to write foo[3:7, :-2] instead of tf.slice(foo, [3, 0], [4, foo.get_shape()[1]-2]).\n",
    "\n",
    "即`tf.slice(tensor,[3,0],[4,tensor.get_shape()[1]-2])`等价于`tensor[3:7,-2]`\n",
    "\n",
    "### tf.gather\n",
    "```python\n",
    "tf.gather(\n",
    "    params,\n",
    "    indices,\n",
    "    validate_indices=None,\n",
    "    name=None,\n",
    "    axis=None,\n",
    "    batch_dims=0\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T03:16:39.165961Z",
     "start_time": "2019-08-21T03:16:39.125832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如下两个是一样的，因为第三维总共就三个元素，取0:3就是所有的都取了\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[3, 3, 3]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[[3, 3, 3]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> sess res as follow:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[3, 3, 3]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[[1, 1, 1],\n",
       "        [2, 2, 2]],\n",
       "\n",
       "       [[5, 5, 5],\n",
       "        [6, 6, 6]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = np.array([[[1, 1, 1], [2, 2, 2]],\n",
    "                 [[3, 3, 3], [4, 4, 4]],\n",
    "                 [[5, 5, 5], [6, 6, 6]]])\n",
    "input.shape\n",
    "print(\"如下两个是一样的，因为第三维总共就三个元素，取0:3就是所有的都取了\")\n",
    "input[1:2,0:1]\n",
    "input[1:2,0:1,0:3]\n",
    "print(\">>> sess res as follow:\")\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.slice(input, [1, 0, 0], [1, 1, 3])) # 等价于 input[1:2,0:1,0:3]\n",
    "    # [[[3, 3, 3]]]\n",
    "\n",
    "    sess.run(tf.gather(input, [0, 2]))\n",
    "    # \n",
    "    # [[[1, 1, 1], [2, 2, 2]],\n",
    "    #  [[5, 5, 5], [6, 6, 6]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.cast\n",
    "类型转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T02:56:20.787203Z",
     "start_time": "2019-08-21T02:56:20.734400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8, 0.9, 0.6, 0.5],\n",
       "       [0.1, 0.2, 0.3, 0.4]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.8, 0.9, 0.6, 0.5],\n",
       "       [0.1, 0.2, 0.3, 0.4]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordEmbedding = np.array([[0.8,0.9,0.6,0.5],[0.1,0.2,0.3,0.4]])\n",
    "wordEmbedding\n",
    "tensor = tf.cast(wordEmbedding,dtype=tf.float32,name='word2vec')\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.nn.zero_fraction\n",
    "计算为0的比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T02:45:31.694161Z",
     "start_time": "2019-08-23T02:45:31.489592Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.nn.zero_fraction([1,1,1,0]).eval()\n",
    "    tf.nn.zero_fraction([1,1,0,0]).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.nn.embedding_lookup\n",
    "```python\n",
    "tf.nn.embedding_lookup(\n",
    "    params,\n",
    "    ids,\n",
    "    partition_strategy='mod',\n",
    "    name=None,\n",
    "    validate_indices=True,\n",
    "    max_norm=None\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T02:57:34.679406Z",
     "start_time": "2019-08-21T02:57:34.648356Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 1. ,  2. ,  3. ,  4. ],\n",
       "        [ 0.1,  0.2,  0.3,  0.4],\n",
       "        [10. , 20. , 30. , 40. ],\n",
       "        [ 0.1,  0.2,  0.3,  0.4]],\n",
       "\n",
       "       [[ 1. ,  2. ,  3. ,  4. ],\n",
       "        [10. , 20. , 30. , 40. ],\n",
       "        [10. , 20. , 30. , 40. ],\n",
       "        [10. , 20. , 30. , 40. ]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = np.array([[1,2,3,4],[0.1,0.2,0.3,0.4],[10,20,30,40],[100,200,300,400]])\n",
    "emb.shape\n",
    "word_idx = [[0,1,2,1],[0,2,2,2]]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.nn.embedding_lookup(emb,word_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.nn.embedding_lookup_sparse\n",
    "- 可以参考下[这篇简书的文章](https://www.jianshu.com/p/f54eb9715609)\n",
    "```python\n",
    "tf.nn.embedding_lookup_sparse(\n",
    "    params,\n",
    "    sp_ids,\n",
    "    sp_weights,\n",
    "    partition_strategy='mod',\n",
    "    name=None,\n",
    "    combiner=None,\n",
    "    max_norm=None\n",
    ")\n",
    "```\n",
    "- `sp_weights`可以直接填`None`\n",
    "- 实际“查表”的时候就是用的`sp_ids`这个`sparseTensor`的`values`作为索引去`params`里查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T07:05:08.522406Z",
     "start_time": "2019-08-21T07:05:08.362754Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTensorValue(indices=array([[0, 0],\n",
       "       [1, 0],\n",
       "       [2, 0]]), values=array([2, 3, 4], dtype=int32), dense_shape=array([10,  1]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[  10.,   20.,   30.,   40.],\n",
       "       [ 100.,  200.,  300.,  400.],\n",
       "       [1000., 2000., 3000., 4000.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[  10.,   20.,   30.,   40.],\n",
       "       [ 100.,  200.,  300.,  400.],\n",
       "       [1000., 2000., 3000., 4000.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = np.array([[1,2,3,4],\n",
    "                [0.1,0.2,0.3,0.4],\n",
    "                [10,20,30,40],\n",
    "                [100,200,300,400],\n",
    "                [1000,2000,3000,4000]\n",
    "               ])\n",
    "\n",
    "word_idx = [[0,1,2,1],\n",
    "            [0,2,2,2]]\n",
    "\n",
    "word_idx_sp = tf.sparse.SparseTensor(indices=[[0, 0], [1, 0], [2, 0]],\n",
    "                              values=[2,3,4],\n",
    "                              dense_shape=[10, 1])\n",
    "word_idx_w = tf.sparse.SparseTensor(indices=word_idx_sp.indices,\n",
    "                                    values=tf.ones_like(word_idx_sp.values),\n",
    "                                    dense_shape=word_idx_sp.dense_shape)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(word_idx_sp)\n",
    "    sess.run(tf.sparse.to_dense(word_idx_sp))\n",
    "    sess.run(tf.nn.embedding_lookup_sparse(emb,sp_ids=word_idx_sp,sp_weights=None,combiner='mean'))\n",
    "    sess.run(tf.nn.embedding_lookup_sparse(emb,sp_ids=word_idx_sp,sp_weights=word_idx_w,combiner='mean'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.nn.conv2d\n",
    "```python\n",
    "tf.nn.conv2d(\n",
    "    input,\n",
    "    filter=None,\n",
    "    strides=None,\n",
    "    padding=None,\n",
    "    use_cudnn_on_gpu=True,\n",
    "    data_format='NHWC',\n",
    "    dilations=[1, 1, 1, 1],\n",
    "    name=None,\n",
    "    filters=None\n",
    ")\n",
    "```\n",
    "找到的解释：\n",
    "> tensorflow中的tf.nn.conv2d函数，实际上相当于用filter，以一定的步长stride在image上进行滑动，计算重叠部分的内积和，即为卷积结果\n",
    "\n",
    "官方文档：\n",
    "> input tensor of shape:  \n",
    "> - [`batch`, **in_height**, **in_width**, **in_channels**]\n",
    ">\n",
    "> filter / kernel tensor of shape:   \n",
    ">- [**filter_height**, **filter_width**, **in_channels**, `out_channels`]\n",
    ">\n",
    ">this op performs the following:\n",
    ">- Flattens the filter to a 2-D matrix with shape:\n",
    ">    - [**filter_height** * **filter_width** * **in_channels**, `output_channels`].\n",
    ">- Extracts image patches from the input tensor to form a virtual tensor of shape:\n",
    ">    - [`batch`, out_height, out_width, **filter_height** * **filter_width** * **in_channels**].\n",
    ">- For each patch, right-multiplies the filter matrix and the image patch vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T04:02:18.994680Z",
     "start_time": "2019-08-22T04:02:18.561158Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1), Dimension(3), Dimension(6), Dimension(1)])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 3, 6, 1], dtype=int32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([2, 6, 1, 4], dtype=int32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 4], dtype=int32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[[[ 1. ],\n",
       "         [ 2. ],\n",
       "         [ 3. ],\n",
       "         [ 4. ],\n",
       "         [ 5. ],\n",
       "         [ 6. ]],\n",
       "\n",
       "        [[ 0.1],\n",
       "         [ 0.2],\n",
       "         [ 0.3],\n",
       "         [ 0.4],\n",
       "         [ 0.5],\n",
       "         [ 0.6]],\n",
       "\n",
       "        [[10. ],\n",
       "         [20. ],\n",
       "         [30. ],\n",
       "         [40. ],\n",
       "         [50. ],\n",
       "         [60. ]]]], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 每个卷积核都初始化为相同的权重W，目前按1填充\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.]]]], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 偏置 b:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.1, 0.1, 0.1], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 1+2+3+4+5+6=21,0.1+..0.6=2.1,每个卷积的结果为23.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[ 23.1,  23.1,  23.1,  23.1]],\n",
       "\n",
       "        [[212.1, 212.1, 212.1, 212.1]]]], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = np.array([[1,2,3,4,5,6],\n",
    "                [0.1,0.2,0.3,0.4,0.5,0.6],\n",
    "                [10,20,30,40,50,60],\n",
    "                [100,200,300,400,500,600]])\n",
    "# word_idx = [[0,1,2,1],[0,2,2,2]]\n",
    "word_idx = [[0,1,2]]\n",
    "embeddedWords = tf.cast(tf.nn.embedding_lookup(emb,word_idx),dtype=tf.float32)\n",
    "embeddedWordsExpanded = tf.expand_dims(embeddedWords, -1)\n",
    "\n",
    "embeddedWordsExpanded.shape\n",
    "filterSize = 2 # 卷积核大小\n",
    "embeddingSize = 6 # 词向量维度\n",
    "in_channels =1 # 输入的通道\n",
    "numFilters = 4 # 卷积核的个数\n",
    "sequenceLength = len(word_idx[0]) # 句子长度，一般要padding\n",
    "filterShape = [filterSize, embeddingSize, in_channels, numFilters] # 构建conv2d使用的filter参数\n",
    "# W = tf.Variable(tf.truncated_normal(filterShape, stddev=0.1,dtype=tf.float64), name=\"W\",dtype=tf.float64)\n",
    "# b = tf.Variable(tf.constant(0.1, shape=[numFilters],dtype=tf.float64), name=\"b\",dtype=tf.float64)\n",
    "# W = tf.convert_to_tensor(tf.truncated_normal(filterShape, stddev=0.1), name=\"W\") # 正态分布随机初始化\n",
    "W = tf.convert_to_tensor(tf.ones(filterShape), name=\"W\") #\n",
    "b = tf.convert_to_tensor(tf.constant(0.1,shape=[numFilters]),name=\"b\")\n",
    "conv = tf.nn.conv2d(input=embeddedWordsExpanded,\n",
    "                    filter=W,\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding=\"VALID\",\n",
    "                    name=\"conv\")\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "#     embeddedWords.eval()\n",
    "    tf.shape(embeddedWordsExpanded).eval()\n",
    "    tf.shape(W).eval()\n",
    "    tf.shape(conv).eval()\n",
    "    embeddedWordsExpanded.eval()\n",
    "#     tf.shape(W).eval()\n",
    "    print(\">>> 每个卷积核都初始化为相同的权重W，目前按1填充\")\n",
    "    W.eval()\n",
    "    print(\">>> 偏置 b:\")\n",
    "    b.eval()\n",
    "    print(\">>> 1+2+3+4+5+6=21,0.1+..0.6=2.1,每个卷积的结果为23.1\")\n",
    "    conv.eval()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.argmax & tf.nn.softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T06:44:15.764629Z",
     "start_time": "2019-08-22T06:44:15.632349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.0320586 , 0.08714432, 0.23688284, 0.6439143 ], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4]\n",
    "a = [float(i) for i in a]\n",
    "with tf.Session() as sess:\n",
    "    tf.argmax(a).eval()\n",
    "    tf.nn.softmax(a).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T10:10:15.139907Z",
     "start_time": "2019-08-22T10:10:15.135618Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7310585786300049"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(1)\n",
    "sigmoid(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross_entropy\n",
    "**「注」：** tf的这批API，都是在内部做了sigmoid\n",
    "- 测试用例是 `labels=[1,1,0,1],logits=[1,1,0,1]`\n",
    "    - 内部是对`loigts`做了个`sigmoid`，即真正计算的是 `[1,1,0,1]` 和 `[0.731,0.731,0.5,0.731]`之间的CE**\n",
    "    - `sigmoid(1)=0.731, sigmoid(0)=0.5`\n",
    "    \n",
    "\n",
    "一些参考\n",
    "- 参考这篇[博客Tensorflow损失函数详解](https://sthsf.github.io/wiki/Algorithm/DeepLearning/Tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Tensorflow%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86---%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3.html)\n",
    "\n",
    "- 这篇[简书文章](https://www.jianshu.com/p/cf235861311b)结构更清晰\n",
    "\n",
    "- CE公式\n",
    "    - $H(X=x)=-\\sum_x p(x)logq(x)$\n",
    "\n",
    "- logloss\n",
    "    - $logloss = - \\sum_{i=1}^n(\\frac{\\hat{y_i}}{n}log(y_{pred})+\\frac{1-\\hat{y_i}}{n}log(1-y_{pred}))$\n",
    "\n",
    "- 单看一条样本的logloss\n",
    "    - $logloss = ylog(\\hat{y}) + (1-y)log(1-\\hat{y})$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T01:51:10.391135Z",
     "start_time": "2019-08-23T01:51:10.379105Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 1., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[12. ,  3. ,  2. ],\n",
       "       [ 3. , 10. ,  1. ],\n",
       "       [ 1. ,  2. ,  5. ],\n",
       "       [ 4. ,  6.5,  1.2],\n",
       "       [ 3. ,  6. ,  1. ]], dtype=float32)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Data():\n",
    "    # 每一行可有多个1,如一张图既有 label_桌子 又有 label_椅子\n",
    "    multi_hot_labels=np.array([[1,0,0],\n",
    "                               [0,1,0],\n",
    "                               [0,0,1],\n",
    "                               [1,1,0],\n",
    "                               [0,1,0]],dtype=np.float32)\n",
    "    \n",
    "    # 每一行只有一个1,如一张图只能有 label_桌子 不能有 label_椅子\n",
    "    one_hot_labels=np.array([[1,0,0],\n",
    "                             [0,1,0],\n",
    "                             [0,0,1],\n",
    "                             [1,0,0],\n",
    "                             [0,1,0]],dtype=np.float32)\n",
    "    \n",
    "\n",
    "    logits=np.array([[12,3,2],\n",
    "                     [3,10,1],\n",
    "                     [1,2,5],\n",
    "                     [4,6.5,1.2],\n",
    "                     [3,6,1]],dtype=np.float32)\n",
    "    \n",
    "    \n",
    "Data.multi_hot_labels\n",
    "Data.one_hot_labels\n",
    "Data.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如下是tensorflow计算CE的公式化简\n",
    "\n",
    "「注」：这里已经把`sigmoid`考虑进去了，所以输入的时候`pred`就不要进行`sigmoid`了\n",
    "- For brevity, let x = logits, z = labels. The logistic loss is\n",
    "```python\n",
    "z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))\n",
    "= z * -log(1 / (1 + exp(-x))) + (1 - z) * -log(exp(-x) / (1 + exp(-x)))\n",
    "= z * log(1 + exp(-x)) + (1 - z) * (-log(exp(-x)) + log(1 + exp(-x)))\n",
    "= z * log(1 + exp(-x)) + (1 - z) * (x + log(1 + exp(-x))\n",
    "= (1 - z) * x + log(1 + exp(-x))\n",
    "= x - x * z + log(1 + exp(-x))\n",
    "```\n",
    "- For x < 0, to avoid overflow in exp(-x), we reformulate the above\n",
    "```python\n",
    "x - x * z + log(1 + exp(-x))\n",
    "= log(exp(x)) - x * z + log(1 + exp(-x))\n",
    "= - x * z + log(1 + exp(x))              \n",
    "```\n",
    "- Hence, to ensure stability and avoid overflow, the implementation uses this equivalent formulation\n",
    "```python\n",
    "max(x, 0) - x * z + log(1 + exp(-abs(x)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T09:15:30.234095Z",
     "start_time": "2019-08-22T09:15:30.224267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31326168751822286"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log,exp\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# 完全直接的CE，输入的是label和外部做好sigmoid的prediction\n",
    "def exact_ce(pred,label):\n",
    "    return -label*np.log(y_pred)-(1-label)*np.log(1-y_pred)\n",
    "\n",
    "# tf化简公式（内部做了sigmoid，已化简掉了）\n",
    "def ce_as_tf(pred,label):\n",
    "    return max(pred, 0) - pred * label + log(1 + exp(-abs(pred)))\n",
    "\n",
    "# 按计算公式计算（内部做了sigmoid）\n",
    "def manual_formula(pred,label):\n",
    "    y_pred = sigmoid(pred)\n",
    "    E1 = -label*np.log(y_pred)-(1-label)*np.log(1-y_pred)\n",
    "    return E1\n",
    "\n",
    "ce_as_tf(1,1)\n",
    "manual_formula(0.7,0.7) == ce_as_tf(0.7,0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.nn.sigmoid_cross_entropy_with_logits\n",
    "- 这个函数的输入是logits和labels，logits就是神经网络模型中的 W * X矩阵，注意**不需要经过sigmoid**\n",
    "- 可用于各类别独立但不排斥的情况：如图片可以既有桌子又有凳子\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T09:58:51.010224Z",
     "start_time": "2019-08-22T09:58:50.883338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.1989022e-06 3.0485876e+00 2.1269276e+00]\n",
      " [3.0485876e+00 4.5419773e-05 1.3132617e+00]\n",
      " [1.3132617e+00 2.1269276e+00 6.7153242e-03]\n",
      " [1.8149957e-02 1.5023305e-03 1.4632827e+00]\n",
      " [3.0485876e+00 2.4756414e-03 1.3132617e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.1441933e-06, 3.0485873e+00, 2.1269281e+00],\n",
       "       [3.0485873e+00, 4.5398901e-05, 1.3132617e+00],\n",
       "       [1.3132617e+00, 2.1269281e+00, 6.7153485e-03],\n",
       "       [1.8149929e-02, 1.5023102e-03, 1.4632825e+00],\n",
       "       [3.0485873e+00, 2.4756852e-03, 1.3132617e+00]], dtype=float32)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[6.1441933e-06, 3.0485873e+00, 2.1269281e+00],\n",
       "       [3.0485873e+00, 4.5398901e-05, 1.3132617e+00],\n",
       "       [1.3132617e+00, 2.1269281e+00, 6.7153485e-03],\n",
       "       [1.8149929e-02, 6.5015025e+00, 1.4632825e+00],\n",
       "       [3.0485873e+00, 2.4756852e-03, 1.3132617e+00]], dtype=float32)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5个样本三分类问题，且一个样本可以同时拥有多类\n",
    "print(manual_formula(pred=Data.logits,label=Data.multi_hot_labels))     # 按计算公式计算的结果\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(logits=Data.logits,labels=Data.multi_hot_labels).eval()\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(logits=Data.logits,labels=Data.one_hot_labels).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.nn.weighted_cross_entropy_with_logits\n",
    "- 是`sigmoid_cross_entropy_with_logits`的拓展版，多支持一个`pos_weight`参数，在传统基于sigmoid的交叉熵算法上，**正样本算出的值乘以某个系数。**\n",
    "\n",
    "```python\n",
    "tf.nn.weighted_cross_entropy_with_logits(\n",
    "    labels=None,\n",
    "    logits=None,\n",
    "    pos_weight=None,\n",
    "    name=None,\n",
    "    targets=None\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T10:04:15.710169Z",
     "start_time": "2019-08-22T10:04:15.435623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.       , 3.0485873, 2.126928 ],\n",
       "       [3.0485873, 0.       , 1.3132617],\n",
       "       [1.3132617, 2.126928 , 0.       ],\n",
       "       [0.       , 0.       , 1.4632825],\n",
       "       [3.0485873, 0.       , 1.3132617]], dtype=float32)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.       , 3.0485873, 2.126928 ],\n",
       "       [3.0485873, 0.       , 1.3132617],\n",
       "       [1.3132617, 2.126928 , 0.       ],\n",
       "       [0.       , 6.5015025, 1.4632825],\n",
       "       [3.0485873, 0.       , 1.3132617]], dtype=float32)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pos_weight = np.ones_like(logits.shape[0])\n",
    "pos_weight = np.zeros_like(Data.logits.shape[0]) # 权重统一为0\n",
    "with tf.Session() as sess:\n",
    "    tf.nn.weighted_cross_entropy_with_logits(Data.multi_hot_labels,Data.logits, pos_weight, name=None).eval()\n",
    "    tf.nn.weighted_cross_entropy_with_logits(Data.one_hot_labels,Data.logits, pos_weight, name=None).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ~~tf.nn.softmax_cross_entropy_with_logits~~ (Deprecated)\n",
    "### tf.nn.softmax_cross_entropy_with_logits_v2\n",
    "- 为了效率此函数内部执行softmax，输入logits时不要计算softmax\n",
    "- While the **classes are mutually exclusive**, their probabilities need not be. All that is required is that **each row of labels is a valid probability distribution**\n",
    "- Note that to avoid confusion, it is required to pass only named arguments to this function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T01:50:39.249131Z",
     "start_time": "2019-08-23T01:50:39.050303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.6878611e-04, 1.0346780e-03, 6.5883912e-02, 2.6669841e+00,\n",
       "       5.4985214e-02], dtype=float32)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1.6878611e-04, 1.0346780e-03, 6.5883912e-02, 2.5834920e+00,\n",
       "       5.4985214e-02], dtype=float32)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(labels=Data.multi_hot_labels,logits=Data.logits).eval()\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(labels=Data.one_hot_labels,logits=Data.logits).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.nn.sparse_softmax_cross_entropy_with_logits\n",
    "注意labels和logits的shape\n",
    "- labels是第几类的索引\n",
    "```python\n",
    "   [2,\n",
    "    1,\n",
    "    1,\n",
    "    2]\n",
    "```\n",
    "- logits是\n",
    "```python\n",
    "    [[ 12, 4,   4, 22],\n",
    "     [6.5, 2, 3.3,  7],\n",
    "     [2.5, 9, 8.3,6.7],]\n",
    "```\n",
    ">如果两个都是Rank1会报错： Rank of labels (received 1) should equal rank of logits minus 1 (received 1)\n",
    "\n",
    "```python\n",
    "tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    _sentinel=None,\n",
    "    labels=None,\n",
    "    logits=None,\n",
    "    name=None\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T02:04:07.525526Z",
     "start_time": "2019-08-23T02:04:07.317830Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[12. ,  3. ,  2. ],\n",
       "       [ 3. , 10. ,  1. ],\n",
       "       [ 1. ,  2. ,  5. ],\n",
       "       [ 4. ,  6.5,  1.2],\n",
       "       [ 3. ,  6. ,  1. ]], dtype=float32)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 0, 1])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 1, 1])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1.6878611e-04, 1.0346780e-03, 6.5883912e-02, 2.5834920e+00,\n",
       "       5.4985214e-02], dtype=float32)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data.multi_hot_labels\n",
    "# tf.argmax(Data.multi_hot_labels,axis=-1).eval() # multi_hot（支持一图多类）的label做aargmax也没有意义\n",
    "Data.one_hot_labels\n",
    "Data.logits\n",
    "label_rank1 = tf.argmax(Data.one_hot_labels,axis=-1)\n",
    "logits_rank1 = tf.argmax(Data.logits,axis=-1)\n",
    "with tf.Session() as sess:\n",
    "    label_rank1.eval()\n",
    "    logits_rank1.eval()\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label_rank1,logits=Data.logits).eval()\n",
    "#     tf.nn.sparse_softmax_cross_entropy_with_logits(labels=,logits=Data.logits).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T02:12:11.562305Z",
     "start_time": "2019-08-23T02:12:11.258160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.6878611e-04, 1.0346780e-03, 6.5883912e-02, 2.5834920e+00,\n",
       "       5.4985214e-02], dtype=float32)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1.6878611e-04, 1.0346780e-03, 6.5883912e-02, 2.5834920e+00,\n",
       "       5.4985214e-02], dtype=float32)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[6.1441933e-06, 3.0485873e+00, 2.1269281e+00],\n",
       "       [3.0485873e+00, 4.5398901e-05, 1.3132617e+00],\n",
       "       [1.3132617e+00, 2.1269281e+00, 6.7153485e-03],\n",
       "       [1.8149929e-02, 6.5015025e+00, 1.4632825e+00],\n",
       "       [3.0485873e+00, 2.4756852e-03, 1.3132617e+00]], dtype=float32)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[6.1441933e-06, 3.0485873e+00, 2.1269281e+00],\n",
       "       [3.0485873e+00, 4.5398901e-05, 1.3132617e+00],\n",
       "       [1.3132617e+00, 2.1269281e+00, 6.7153485e-03],\n",
       "       [1.8149929e-02, 6.5015025e+00, 1.4632825e+00],\n",
       "       [3.0485873e+00, 2.4756852e-03, 1.3132617e+00]], dtype=float32)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # softmax\n",
    "    label_rank1=tf.argmax(Data.one_hot_labels,axis=-1)\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label_rank1,logits=Data.logits).eval()\n",
    "    \n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(labels=Data.one_hot_labels,logits=Data.logits).eval()\n",
    "    \n",
    "    # sigmoid\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(logits=Data.logits,labels=Data.one_hot_labels).eval()\n",
    "\n",
    "    pos_weight=np.ones_like(Data.logits.shape[0]) # 权重统一为1\n",
    "    tf.nn.weighted_cross_entropy_with_logits(Data.one_hot_labels,Data.logits, pos_weight, name=None).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "notebook_collection/TensorFlowManual.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "252.173px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
